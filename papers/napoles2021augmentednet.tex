% -----------------------------------------------
% Template for ISMIR Papers
% 2021 version, based on previous ISMIR templates

% Requirements :
% * 6+n page length maximum
% * 10MB maximum file size
% * Copyright note must appear in the bottom left corner of first page
% * Clearer statement about citing own work in anonymized submission
% (see conference website for additional details)
% -----------------------------------------------

\documentclass{article}
\usepackage[T1]{fontenc} % add special characters (e.g., umlaute)
\usepackage[utf8]{inputenc} % set utf-8 as default input encoding
\usepackage{ismir,amsmath,cite,url}
\usepackage{graphicx}
\usepackage{color}


\usepackage{lineno}
\linenumbers

% Title. Please use IEEE-compliant title case when specifying the title here,
% as it has implications for the copyright notice
% ------
\title{AugmentedNet: A Roman Numeral Analysis Network with Synthetic Training Examples and Additional Tonal Tasks}

% Note: Please do NOT use \thanks or a \footnote in any of the author markup

% Single address
% To use with only one author or several with the same address
% ---------------
%\oneauthor
% {Names should be omitted for double-blind reviewing}
% {Affiliations should be omitted for double-blind reviewing}

% Two addresses
% --------------
%\twoauthors
%  {First author} {School \\ Department}
%  {Second author} {Company \\ Address}

% Three addresses
% --------------\input{ISMIR2021_paper.tex}

\threeauthors
  {First Author} {Affiliation1 \\ {\tt author1@ismir.edu}}
  {Second Author} {\bf Retain these fake authors in\\\bf submission to preserve the formatting}
  {Third Author} {Affiliation3 \\ {\tt author3@ismir.edu}}

% Four or more addresses
% OR alternative format for large number of co-authors
% ------------
%\multauthor
%{First author$^1$ \hspace{1cm} Second author$^1$ \hspace{1cm} Third author$^2$} { \bfseries{Fourth author$^3$ \hspace{1cm} Fifth author$^2$ \hspace{1cm} Sixth author$^1$}\\
%  $^1$ Department of Computer Science, University , Country\\
%$^2$ International Laboratories, City, Country\\
%$^3$  Company, Address\\
%{\tt\small CorrespondenceAuthor@ismir.edu, PossibleOtherAuthor@ismir.edu}
%}

% For the author list in the Creative Common license, please enter author names. 
% Please abbreviate the first names of authors and add 'and' between the second to last and last authors.
\def\authorname{F. Author, S. Author, and T. Author}

% Optional: To use hyperref, uncomment the following.
%\usepackage[bookmarks=false,pdfauthor={\authorname},pdfsubject={\papersubject},hidelinks]{hyperref}
% Mind the bookmarks=false option; bookmarks are incompatible with ismir.sty.

\sloppy % please retain sloppy command for improved formatting

% \newcommand{\guide}[1]{\textbf{#1}}
\newcommand{\guide}[1]{}
\newcommand{\missing}[1]{\textcolor{red}{[A #1 will be inserted here]}}

\begin{document}

%
\maketitle
%
\begin{abstract}

\textit{AugmentedNet} is a new, convolutional recurrent neural network for the prediction of functional harmony annotation labels.
The methodology follows the emerging best practice of previous models in most respects, while the network and training workflow are enhanced using \textit{synthetic training examples} for data augmentation, and a \textit{greater number of tonal tasks} to solve simultaneously.

This paper demonstrates improved performance resulting applying these ideas in combination.
The \textit{additional tonal tasks} strengthen the regularization effect introduced by multi-task learning, allowing the network to train with less risk of overfitting. 
The \textit{synthetic examples}, in turn, complement key transposition which is the only technique commonly used for data augmentation in similar problems related to tonal music.
The name `AugmentedNet' speaks to the increased number of both training examples and tonal tasks.

We report on tests across all relevant and available datasets: the Beethoven Piano Sonatas, Well-Tempered Clavier, TAVERN, ABC, HaydnOp20, and When-in-Rome datasets.
In our tests, our model outperforms recent methods of functional harmony, such as other convolutional neural networks and Transformer-based models.
Finally, we show that an alternative method for reconstructing the Roman numeral label, based on one of our additional tasks, leads to better results in the final prediction of the Roman numeral.
\end{abstract}
%
\section{Introduction}\label{sec:introduction}

\guide{RNA versus chord recognition.}
Automatic Chord Recognition (ACR) has been explored thoroughly in the field of Music Information Retrieval (MIR). 
ACR systems typically seek to predict the root and quality of the chords throughout a piece of music via either an audio or a symbolic representation.
A more specific type of chordal analysis, particularly relevant for Western classical music, is functional harmony, or Roman numeral analysis. 
The main difference between ACR and functional harmony is that the latter requires other adjacent tasks to be solved simultaneously, notably including detection and identification of key changes (modulations \cite{feisthauer2020estimating, schreiber2020local} and tonicizations \cite{napoleslopez2020local}).

% Partly due to the repertoires typically targeted, Roman numeral analysis also involves handling of some additional `special chords' such as Neapolitan and Augmented sixth chords.

\guide{Roman Numeral Analysis.}
The analytical process of functional harmony is commonly described through Roman numeral annotations. 
This annotation system is particularly popular in Western music theory for the analysis of `common-practice' tonal music.
Roman numeral annotations encode a great deal of information about tonality, in a compact syntax.
For instance, an annotation like  \texttt{C:viio65/V} includes an account of the local key (here C), the quality of the chord (diminished seventh), the chord inversion (first), and nature of any tonicization (optional, here true: of the dominant). 

\guide{Problem.}
From a computational perspective, predicting such annotations is challenging given that the model has to predict multiple features correctly and simultaneously. 
In the past, MIR researchers have reconstructed Roman numeral annotations by predicting six sub-tasks: chord quality, chord root, local key, inversion, primary degree, and secondary degree \cite{chen2018functional, micchi2020not}. 
%
Thus, as a machine learning problem, functional harmony can be expressed as the task of correctly predicting enough features in order to reconstruct the original Roman numeral label. 

% I would cut this duplication of the above: In spite of their compactness, Roman numeral strings are sufficient to provide all of these features, and thus show to be convenient as an annotation system for creating functional harmony datasets.

Recent efforts in this area have seen a great standardization of the notation and conversion routines, \cite{gotham2019romantext} which in turn has facilitated the amassing of a relatively large meta-corpus of Roman numeral analyses \cite{gotham2019romantext}.
However, despite these developments and the wider resurgence of interest in the field, the performance of functional harmony models for predicting full Roman numeral labels remains relatively low.

\guide{Solution.}
In this paper, we propose a new neural network architecture that improves the prediction of functional harmony and its relevant features. 
Beside the architecture itself, our model benefits from increased data augmentation (beyond key transpositions), and an additional set of output tasks that enhance the effects of multi-task learning demonstrated by other researchers \cite{chen2018functional}.

To facilitate the work of other researchers, we release all of our preprocessed datasets, data splits, experiment logs, and the full source code of our network in [ANONYMIZED], under a permissive MIT license.


\section{Related work}

\guide{Chord recognition task.}
For a summary of general ACR strategies, see Pauwels et al. \cite{pauwels_20_2019}. 
Here we focus on prior work  in the specific area of automatic functional harmony analysis.

% \guide{The pioneers.}
% The first computational efforts around functional harmony can be traced back to Winograd \cite{winograd1968linguistics} and Maxwell \cite{maxwell1992expert}. Winograd's program required heavy preprocessing of the inputs (e.g., removing all non-chord tones beforehand), while Maxwell's expert system consisted of 55 handcrafted rules, designed to analyze short movements of French suites by Bach.

% maxwell was 1984 actually, in his thesis dissertation. 1992 is the book chapter

\guide{First end-to-end system.}
The first end-to-end system of automatic Roman numeral analysis can be attributed to the independent contributions of Temperley and Sleator \cite{temperley2004cognition}, and Sapp \cite{sapp2009tsroot}.
Temperley's preference rules were implemented by Sleator as part of a suite of programs called \emph{Melisma (version 1)}.\footnote{Although Melisma (version 2) exists, it does not provide Roman numeral analysis output.} 
The contributions of Sapp to the Humdrum toolkit \cite{huron2002music} made it possible to process any encoded musical score with Roman numeral annotations using \emph{Melisma}.

\guide{Before deep learning.}
Notable subsequent studies include Raphael and Stoddard \cite{raphael2004functional}, Illescas et al. \cite{illescas2007harmonic}, and Magalh\=aes and de Haas \cite{magalhaes2011functional}, who proposed Hidden Markov Models (HMMs), dynamic programming, and grammar-based approaches, respectively. 

\guide{Chen and Su (2018).}
More recently, deep neural networks have become the preferred tool for approaching this problem.
Chen and Su \cite{chen2018functional} were the first to introduce `multi-task learning' (MTL) \cite{ruder2017overview} to the problem as a suitable way for the neural network to share representations between related tonal tasks. 
Chen and Su's model consists of a bidirectional LSTM \cite{hochreiter1997long} followed by task-specific dense layers, which implement the MTL aspect.
In this work, the authors also introduced the `Beethoven Piano Sonata Functional Harmony' dataset for evaluating such models. 
The MTL layout outperformed single-task configurations and it has continued to prove the best-performing approach in subsequent deep learning studies. 
Recently, the same authors have adopted Transformer-based networks to deal with functional harmony and ACR \cite{chen2019harmony, chen2021attend}. 
The work with these networks has explored the capability of the attention mechanisms to improve the performance of ACR, paying special consideration to chord segmentation and its evaluation. 

\guide{Micchi et al (2020).}
Micchi et al. \cite{micchi2020not}, in turn, proposed a DenseNet-like \cite{huang2017densely} convolutional neural network, followed by a recurrent component.
The recurrent component consists of a bidirectional GRU \cite{cho2014learning} connected to task-specific dense layers, similar to those of Chen and Su \cite{chen2018functional}.
In their experiments, the DenseNet-like convolutions outperformed dilated convolutions and a GRU by itself (i.e., with pooling instead of the convolutional blocks).
Micchi et al.~also demonstrated the positive effect of using pitch \textit{spelling} in the inputs and outputs.
This confers at least two advantages: it provides a more informative output (e.g., not only the correct key, but the correct spelling between two enharmonic keys), and it increases the possible number of transpositions available for data augmentation.

\guide{Ours.}
Here, we propose improvements along the line of convolutional recurrent neural networks. Due to our emphasis on extended data augmentation and tonal tasks, we named our network \emph{AugmentedNet}.
 
\section{AugmentedNet}

The AugmentedNet is similar in size and design to the network proposed by Micchi et al. \cite{micchi2020not}. The network is characterized by a different design of the convolutional layers, the representation of pitch spelling, and the separation of bass and chroma features inputs into independent convolutional blocks.

\subsection{Inputs}

\textbf{Reference note per timestep.}
The input to the network consists of a sequence of timesteps, which are sampled from the score at symbolically regular note duration values.
In this study, we use the thirty-second note (`demisemiquaver') as this atomic value (i.e.~eight timesteps per quarter note in the score) in order to match the most fine-grained frame sampling seen in previous work. The length of the sequence is set by a fixed number of timesteps. Following Micchi et al., we set that number at 640 frames (or 80 quarter notes) per sequence example.
%Each timestep contains a vector of bass and chroma features.

\textbf{Bass and spelled chroma features.}
We also follow the Micchi et al.~input representation of pitch as a vector containing bass spelling and spelled `chroma features'\footnote{A chroma feature representation is typically a vector of 12 pitch classes, where the activation of each pitch class at a given timestep is indicated in a many-hot encoding fashion (symbolic data), or as continous values (audio data). 
Due to the similarity of this input representation to chroma features, except for the spelling aspect, we refer to them as \emph{spelled} chroma features.} at every timestep, however the details differ in subtle but important ways. 
In the Micchi et al. representation, each timestep has 70 features: 35 for the bass and 35 for the chroma features. 
We consolidate this information in 38 features: 19 for the bass, and 19 for the chroma features. The reduction in number of features is due to an alternative encoding of pitch spelling, described below.

\textbf{Encoding the pitch spelling.}
%In previous work, Micchi et al. \cite{micchi2020not} have encoded pitch spellings as a one-hot encoded vector with 35 features, which encodes pitch spellings up to two sharps or two flats of every note letter (7 * 5 = 35). 
We split the representation of a pitch spelling into two components: the pitch class (0--12) and the generic note letter (A--G).
Each spelled pitch thus leads to a two-hot encoded vector with 19 features (1 of 12 pitch classes, and 1 of 7 note names).
This reduces the number of parameters in the network without any observable compromise in performance.

\guide{Separating the inputs.}
Furthermore, the bass and spelled chroma features are connected to the network independently and concatenated only after they have passed through their own convolutional blocks. 
In preliminary experiments, we discovered that this separation of the inputs (bass and spelled chroma features) was beneficial to the learning process.
Thus, two parallel convolutional blocks are computed.

\subsection{Convolutional block}

\guide{Micchi and DenseNet-like convolutions.}
Using the feature maps of all previous layers as an input to a convolutional layer has proven beneficial, for instance by strengthening feature propagation and reducing the number of parameters \cite{huang2017densely}. 
Moreover, DenseNet-like architectures have shown to work well for the specific task of functional harmony \cite{micchi2020not}.

\begin{figure*}
 \centerline{
 \includegraphics[width=\textwidth]{figs/network.png}}
 \caption{\emph{AugmentedNet}. The bass and chroma inputs are processed through independent convolutional blocks and then concatenated. Both convolutional blocks are identical and expanded on the top of the figure. A convolutional block has six 1D convolutional layers. Each layer doubles the kernel size (number of timesteps covered) and halves the number of output filters, prioritizing short-term dependencies but providing long-term context that benefits the subsequent GRU layers.}
 \label{fig:network}
\end{figure*}

\guide{Convolutional layers.}
We follow similar methods, reusing the feature maps computed for a given timestep in subsequent convolutions. 
Figure \ref{fig:network} provides a schematic diagram of our network, with the convolutional block on the top left area of the figure. 
In our preliminary experiments, we noticed that different tonal tasks of functional harmony have different time dependencies. 
For example, losing information about a specific timestep often leads to poor performance in predicting the inversion, whereas losing long-term dependencies hinders performance in local key estimation. 
Our architecture implicitly prioritizes short-term dependencies in the initial convolutional layers, by having more filters and covering less timesteps. Going further, the convolutions provide more context about future timesteps, but output a smaller number of filters. These increments (in kernel size) and decrements (in filters) are done in powers of 2. With a configuration of 6 convolutional layers in each block (as shown in Figure \ref{fig:network}), the first layer convolves a single timestep (`demisemiquaver') and the sixth layer convolves 32 timesteps (`whole note'). The output shape of the block is the original length of the sequence with 82 features per timestep.

\subsection{Dense and recurrent layers}

Two time-distributed dense layers are applied to the concatenated outputs of the convolutional blocks. The dense layers help reducing the number of features before the GRU layers. These have 64 and 32 neurons, respectively. 
% All convolutional and dense layers have batch normalization \cite{ioffe2015batch} before the activation function. Similarly, all convolutional and dense layers use the rectified linear unit (ReLU) as their activation function.

Two bidirectional GRU \cite{cho2014learning} layers are applied after the second dense layer. 
Both GRU layers return outputs at every timestep. 
Throughout the entire network, the dimensionality of the timesteps axis remains constant. That is, our input and output sequences have the same length, and the model predicts one Roman numeral label per timestep. 

\subsection{Multi-outputs}

The output of the network follows a MTL approach with hard parameter sharing, similar to that proposed by Chen and Su \cite{chen2018functional}. For each of the output tasks, a time-distributed dense layer is attached to the second GRU, and used to predict its corresponding task. 
Six conventional tasks are learned (similar to Micchi et al. and Chen and Su \cite{micchi2020not, chen2021attend}), plus five additional ones. All the tasks (eleven in total) and their number of output classes are shown on the right side of Figure \ref{fig:network}.

\subsubsection{Six conventional functional harmony tasks}
All the conventional tasks, except for the local key, have the same number of output classes described by Micchi et al. \cite{micchi2020not}. The local key includes four additional keys: $\{F\flat, G\sharp, d\flat, e\sharp\}$. These were included because the data exploration process revealed modulations reaching $G\sharp$ major in the dataset.
Thus, the number of allowed key signatures was extended by one sharp and one flat, in both modes.
% This also introduced more training examples during the data augmentation process via key transposition. 

\subsubsection{Five Additional tasks.}\label{sec:additionaltasks}

It is argued that MTL helps improving the generalization of a model by preferring representations that are useful to related tasks, acting as an implicit form of data augmentation and regularization method \cite{ruder2017overview}.
Roman numeral labels can be decomposed into multiple different features, of which the six conventional tasks are known examples.
Motivated by the possibility of improving the performance of our network, we included five additional tasks with hard parameter sharing in our MTL approach.
We describe the five additional tasks, which have relevance to harmonic analysis. 
One of them, RomanNumeral75, was also used as an alternative task when reconstructing the final Roman numeral label, a process we explain below.

\begin{table}[]
\begin{tabular}{l|l|l|l|l}
1--15    & 16--30    & 31--45    & 46--60     & 61--75    \\
\hline
I       & V/V      & Ger     & viio7/v   & V+       \\
V7      & v        & N        & viio7/iii & viio/vi  \\
V       & V7/ii    & viio7/vi & IV/V      & III+     \\
i       & III      & V/ii     & I+        & V/iii    \\
IV      & iiø7     & viiø7    & I7        & ii/V     \\
ii      & iii      & V9       & viio/IV   & I/bVI    \\
vi      & iio      & viio/ii  & V/III     & viio7/IV \\
iv      & viio/V   & V/iv     & V7/iii    & V7/v     \\
viio7   & V7/vi    & Cad/V    & viio/iv   & i7       \\
viio    & VII      & iv7      & iio7      & iii7     \\
V7/V    & viio7/ii & viio7/iv & VI7       & Fr      \\
V7/IV   & I/V      & IV7      & I/III     & V/IV     \\
viio7/V & V7/iv    & V7/III   & V7/VI     & vii      \\
VI      & V/vi     & viiø7/V  & bVII      & V/v      \\
ii7     & vi7      & It       & bVI       & II      
\end{tabular}
\caption{The 75 most-common Roman numeral strings, where the inversion has been removed and learned independently. During data exploration, these classes spanned 98\% of the Roman numeral annotations across all the annotated data. Predicting these classes is an alternative to predicting the chord root, chord quality, primary degree, and secondary degree simultaneously.}
\label{tab:top75rn}
\end{table}

\textbf{RomanNumeral75}. During data exploration, we found that, when inversions were removed and synonyms (e.g., \texttt{bII6} and \texttt{N6}) were standardized, a set of 75 Roman numeral strings spanned approximately $98\%$ of all the annotations across all datasets. This was a motivation to predict the Roman numeral string itself. The correct prediction of this task is equivalent to predicting the chord root, chord quality, primary degree, and secondary degree simultaneously. As an additional experiment in our results section, we substituted the final reconstruction of the Roman numeral label in this fashion, using the local key, the inversion, and the RomanNumeral75 outputs. The performance with this method is always better than through the four conventional tasks. The 75 classes of common Roman numeral strings are shown in Table \ref{tab:top75rn}. 


\textbf{Harmonic Rhythm.} Whether a Roman numeral annotation label starts at the given timestep. A binary classification task that may be relevant for chord segmentation.

\textbf{Bass}. The bass note implied by the Roman numeral label. This is predicted with 35 output classes, similarly to the chord root. The 35 classes represent a spelled pitch. This task is related to predicting the chord inversion.

\textbf{Tonicization}. The tonicization is predicted from the key implied by a secondary degree (if any). 
% When not present, the tonicization encodes the local key instead, to reduce the sparsity of classes. 
% This idea is adapted from N\'apoles L\'opez et al. \cite{napoleslopez2020local}. 
The output classes are identical to the ones of the local key and is an alternative approach to learn the secondary degrees.

\textbf{Pitch Class Sets}. The set of pitch classes implied by the chord. The number of classes (93) results from computing all pitch class sets in all diatonic triad and seventh chords, plus all augmented sixth chords in all keys. This task is related to the chord quality, primary degree, and to non-chord tones \cite{ju2017nonchord}.
All additional tasks except for the RomanNumeral75 are computed solely for their contributions to the shared representation of the MTL approach.

\subsection{Data augmentation}

\subsubsection{Transposition}

As in most automatic tonal music analysis research, we transpose each piece to different keys as a means for data augmentation. 
Particularly, we transpose to all the keys that lie within a range of key signatures in both modes.
When we transpose a piece, we verify that all the modulations within the piece fall in the target range of key signatures.
This process of transposition and data augmentation was introduced and described by Micchi et al. \cite{micchi2020not}.
In our data exploration, we found G$\sharp$ major to be the furthest key to the center of the \emph{line-of-fifths} \cite{temperley2000line} in the dataset. 
Thus, we transposed in the range of keys within 8 flats to 8 sharps in their key signature.
% Due to modulations, two pieces of music may be transposed a different number of times. 
% Generally, chromatic pieces (passing through many different keys) can be transposed to fewer new keys, while more diatonic pieces (which remain in one or few key/s) can be transposed more.

\subsubsection{Synthetic examples}

\guide{Additional data augmentation.}
In addition to transposition, we implemented a variation of a recent data-augmentation technique proposed by N\'apoles L\'opez and Fujinaga \cite{napoleslopez2020harmonic}.
Starting with the Roman numeral analyses of our dataset, we synthesized `new' training examples by realizing the chords implied by each Roman numeral annotation.
The synthesis was done using the music21 Python library \cite{cuthbert_music21_2010}, which converts RomanText \cite{gotham2019romantext} files into scores of \emph{block chord} realizations.

\begin{figure}
 \centerline{
 \includegraphics[width=\columnwidth]{figs/texturization.png}}
 \caption{Example of texturization. The \emph{block chord} texture (b) was synthesized using music21 \cite{cuthbert_music21_2010} from an input RomanText file \cite{gotham2019romantext}. The texturized output (c) was generated by recursively applying musical patterns to the \emph{block chord} scores. The three musical patterns of \emph{bass-split}, \emph{Alberti bass}, and \emph{syncopation} are indicated in measures 1--3, respectively. The original music score (a) is shown for reference: mm. 1--4 of Beethoven's Piano Sonata Op.2 No.1.}
 \label{fig:texturization}
\end{figure}

We found the default \emph{block chord} texture of the synthetic examples to be only slightly beneficial for the model, possibly because it did not capture the complex texture of real keyboard music, for example.
In order to account for this difference, we artificially ``texturized'' the generated training examples, departing from the default \emph{block chords}.
The texturization process involved applying three simple note patterns recursively.
Figure \ref{fig:texturization} shows an example of the texturization patterns, alongside the original score and the default \emph{block chords} provided by music21. We describe the texturization patterns below.

\textbf{Bass-split (measure 1).} The original chord duration is divided by half, playing
the bass note in isolation during the first half, followed by the remaining upper notes.

\textbf{Alberti bass (measure 2).} A 4-note melodic pattern with the contour lowest, highest, middle, highest.

\textbf{Syncopation (measure 3).} The highest note is played in isolation, followed by the remaining lower notes, played in syncopation.

\textbf{Mixture (measure 4).} We applied these patterns randomly and recursively. For example, the \emph{mixture} in measure 4 displays a \emph{bass-split} pattern over the whole-note chord, followed by a \emph{syncopation} pattern applied over the three upper notes, in the second half of the measure. 

As part of the randomization, some chords were left unaltered (e.g., the anacrusis of Figure \ref{fig:texturization}), and the patterns were applied across different duration values. 
To constraint the depth of the recursion, we applied these patterns only to the slices of the score that contained 3--4 simultaneous notes.  
This process resulted in the generation of `new' pieces that showed improvements in the learning process of the model, further the than \emph{block chord} synthetic scores.

\section{Experiments}

%We describe the data, training process, and results of our experiments.

\subsection{Datasets}

In the past, the models by Micchi et al. \cite{micchi2020not} and Chen and Su \cite{chen2021attend} have been evaluated using the Beethoven Piano Sonatas (BPS) and the Well-Tempered Clavier (WTC) datasets. We too provide direct comparisons in these two datasets, however, we also share the results of our model across the Annotated Beethoven Corpus (ABC) \cite{neuwirth2018annotated}, annotated Haydn string quartets Op.20 (HaydnOp20) \cite{napoleslopez2017automatic}, Theme and Variation Encodings with Roman Numerals (TAVERN) \cite{devaney2015theme}, and When-in-Rome (WiR) \cite{gotham2019romantext} datasets. 

For all datasets, the same procedure was followed regarding data splits. 
 Training, validation, and test splits were produced randomly (except in BPS, where they were provided by Chen and Su \cite{chen2018functional}).
 %\footnote{In the original splits of BPS, there is a duplicated example in the validation and test sets. We noticed that Micchi et al. \cite{micchi2020not} corrected the splits to remove the data leakage. Thus, we follow the splits by Micchi et al. \cite{micchi2020not}}  
A summary of all datasets is shown in Table \ref{tab:datasets}. The summary indicates the number of files in each split and the number of sequences (each of 640 frames) that were collected from that split.


Preliminary experiments were conducted in the training set, using the validation set to assess the generalization, adjust the hyper parameters, and inform the design of the network architecture.
The best-performing version of our model was run once in the test set, this time including the validation portion as part of the training.
The results obtained for all the rows labeled \emph{Full dataset} in Table \ref{tab:results} report the results obtained on the corresponding test split. 
To support reproduction of this work, we provide the exact data splits at [ANONYMIZED].

\textbf{Data augmentation} For every training example, we synthesized and texturized an additional one, using only the Roman numeral annotations (and ignoring the original score). The original and texturized training examples were transposed to different keys for further data augmentation. Both forms of data augmentation were only applied to the training set of a particular experiment, leaving the validation/test set intact to prevent any data leakage.

\begin{table}
 \begin{center}
 \begin{tabular}{l|lll}
  & & Files (Seqs) & \\
  Dataset & Training & Validation & Test \\
  \hline
  ABC \cite{neuwirth2018annotated} & 50 (448) & 10 (97) & 10 (99) \\
  BPS \cite{chen2018functional} & 18 (155) & 7 (75) & 7 (75) \\
  HaydnOp20 \cite{napoleslopez2017automatic} & 16 (91) & 4 (19) & 4 (19) \\
  TAVERN \cite{devaney2015theme} & 38 (404) & 8 (68) & 8 (64) \\
  WiR \cite{gotham2019romantext} & 107 (301) & 21 (61) & 21 (51) \\
  WTC \cite{gotham2019romantext} & 12 (25) & 6 (13) & 6 (14) \\
  \hline
  Total & 241 (1424) & 56 (333) & 56 (329) \\
%   +Transposition & XX & - & - \\
%   +Synthetic & XX & - & - \\
%   Grand total & XX & - & - \\ 
 \end{tabular}
\end{center}
 \caption{The functional harmony datasets used in our experiments. The splits were generated randomly (except for BPS). For each split, the number of files and the number of sequences (in parenthesis) are indicated.}
 \label{tab:datasets}
\end{table}

\begin{table*}
\begin{center}
\begin{tabular}{lll|lllll|l}
Dataset & Trained with & Model & Key & Degree & Quality & Inversion & 75RN & RN[, AltRN] \\ [1.5ex]
\hline \hline
WiR & Full dataset & AugNet & 81.6 & 70.0 & 87.1 & 90.9 & 70.1 & 55.8, \textbf{61.6} \\ [1ex]
\hline\hline
HaydnOp20 & Full dataset & AugNet & 79.5 & 61.8 & 78.2 & 80.9 & 56.9 & 45.7, \textbf{48.4}\\ [1ex]
\hline\hline
ABC & Full dataset & AugNet & 82.3 & 65.5 & 78.2 & 75.8 & 63.9 & 43.8, \textbf{47.4} \\ [1ex]
\hline\hline
TAVERN & Full dataset & AugNet & 91.0 & 60.3 & 78.1 & 77.2 & 67.3 & 43.9, \textbf{53.5} \\ [1ex]
\hline\hline
WTC & Full dataset & AugNet & 75.2 & 66.1 & 74.5 & 75.2 & 60.2 & 45.0, \textbf{47.7} \\
\hline
% WTC & BPS+WTC & AugmentedNet & \textbf{87.1} & 69.9 & 72.4 & 73.3 & & 47.5, \textbf{49.9} \\
WTC & BPS+WTC & AugNet & \textbf{85.1}$_{\pm4.0}$ & 62.9$_{\pm5.5}$ & 69.1$_{\pm1.9}$ & 70.1$_{\pm3.7}$ & 59.9$_{\pm3.4}$ & 42.9$_{\pm4.2}$, \textbf{46.9}$_{\pm4.7}$ \\
WTC & BPS+WTC & CS21 & 56.3$_{\pm2.5}$ & - & - & - & - & 26.0$_{\pm1.7}$ \\ [1ex]
\hline\hline
BPS & Full dataset & AugNet & \textbf{83.5} & \textbf{71.8} & \textbf{79.8} & \textbf{72.7} & 69.1 & 44.6, \textbf{48.4} \\
BPS & Full dataset & Mi20 & 82.9 & 68.3 & 76.6 & 72.0 & - & 42.8 \\
\hline
BPS & BPS+WTC & AugNet & \textbf{84} & 70.4 & 79.4 & 70.2 & 67.5 & 43.4, \textbf{46.2} \\
BPS & BPS+WTC & CS21 & 79.0 & - & - & - & - & 41.7 \\
\hline
BPS & BPS & AugNet & \textbf{83.7} & \textbf{69.6} & \textbf{80} & \textbf{70.4} & 67.6 & 42.9, \textbf{46.5} \\
BPS & BPS & Mi20 & 80.6 & 66.5 & 76.3 & 68.1 & - & 39.1 \\
BPS & BPS & CS19 & 78.4 & 65.1 & 74.6 & 62.1 & - & - \\
BPS & BPS & CS18 & 66.7 & 51.8 & 60.6 & 59.1 & -  & 25.7 
\end{tabular}
\end{center}
 \caption{Summary of the performance of five functional harmony models: Chen and Su (2018, 2019, and 2021), Micchi et al. (2020), and AugmentedNet. For the WTC dataset, the experiment with training done over BPS+WTC replicated the 4-fold cross validation presented by Chen and Su \cite{chen2021attend}. In this case, $\pm$ indicates the standard deviation. For all other rows, the results present the performance on the held test set. The comma-separated values in RN of the AugmentedNet rows indicate different methods for reconstructing the Roman numeral, as explained in \ref{sec:additionaltasks}.}
 \label{tab:results}
\end{table*}

\subsection{Training procedure}

\textbf{Epochs.}
We set a fixed number of 100 epochs in all experiments. 
We found that the use of early stopping was unreliable to determine the end of the training process.
Instead, we saved the weights after each epoch. 
After all epochs, we selected the best weights based on a custom metric that prefers the highest accuracy on the six conventional functional harmony tasks.
% We set the number of layers in the initial convolutional block to 6. 
% Each convolutional layer has a kernel size of 1, 2, 4, 8, 16, and 32 timesteps, respectively. In practice, this means that the last convolutional layer provides information up to a whole note away from the current timestep.

\textbf{Other hyper-parameters.}
Each of the layers in the network is accompanied by batch normalization before the activation function. In the recurrent layers, we apply the batch normalization after the activation function. All convolutional and dense layers use the rectified linear unit (ReLU) as their activation function. However, the two GRU layers use $\tanh$. In all of our experiments, we used 16 sequences per batch and Adam \cite{kingma2014adam} as our optimizer, with a learning rate of $10^{-7}$.



\textbf{Computing time.} The network was trained on a personal laptop\footnote{Intel i7 10750h, Nvidia RTX 2070, 32GB DDR4} with a Linux operating system, Tensorflow 2.4.1, and GPU acceleration.
With these hardware and software conditions, the training times are approximately ~30 minutes (BPS only), ~40 minutes (BPS+WTC), and ~250 minutes (Full dataset). 
The number of trainable parameters in the network is close to 90,000. This number already includes all the parameters introduced by the additional output tasks. Therefore, the model is similar in size to recent models \cite{micchi2020not, chen2021attend}.

\subsection{Results}


\textbf{Beethoven Piano Sonatas.} The last rows of Table \ref{tab:results} show the results of our model when evaluated over the BPS dataset. 
To the best of our efforts, we replicate the experimental conditions of the models we compare to. Single lines in the table delimit experiments that are directly comparable. 
For example, the upper rows of BPS compare the results of Micchi et al. \cite{micchi2020not} using all of their available training data and our model using all of our available training data. 

\textbf{Well-Tempered Clavier.}
The second to last group of rows in Table \ref{tab:results} show the results of our model when evaluated on the WTC dataset.
The model by Chen and Su \cite{chen2021attend} presented the results over 4-fold cross validation. We replicate this study for direct comparison.\footnote{However, we used our test split for the \emph{Full dataset} experiment in WTC.} As they have, we include the average accuracy across the 4 folds, and the standard deviation. 

The results show that our model outperforms both the recent convolutional methods \cite{micchi2020not} and Transformer-based ones \cite{chen2021attend} in the reconstruction of the Roman numeral label. 
% Furthermore, the addition of data from a different dataset seems to improve the results. For example, training with WTC and BPS benefits the performance in BPS and vice versa.
For ABC, HaydnOp20, TAVERN, and WiR, we show the generalization of our model when using all the training data available on the corresponding held test set. 

\textbf{Alternative resolution of Roman numeral annotations.}
As discussed in Section \ref{sec:additionaltasks}, it is possible to use the 75 most-common Roman numeral strings as an alternative task to the chord root, chord quality, primary degree, and secondary degree tasks. 
Thus, an alternative resolution of the Roman numeral label (AltRN) is presented in the last column of the AugmentedNet results. This accuracy corresponds to the reconstruction of the Roman numeral using the 75 most-common Roman numerals, chord inversion, and local key tasks. 
We assume that if these three tasks are predicted correctly, the Roman numeral label has been reconstructed correctly.
We found that this, in fact, leads to better results compared to the six conventional tonal tasks. 
Table \ref{tab:results} shows the comma-separated accuracy values for the Roman numeral, the one computed from the six conventional tonal tasks (RN), and the alternative approach (AltRN). For completeness, we show too the accuracy of the RomanNumeral75 output task, labeled 75RN in the table.

In summary, the \emph{Full dataset} rows show the best results achieved by our model for each dataset. In all cases, the results of our model are higher than existing methods in the final reconstruction of the Roman numeral label. Additionally, the best results in the reconstruction are achieved via the chord inversion, local key, and our RomanNumeral75 task.

\section{Conclusion}
We present advances in the use of convolutional recurrent neural networks to predict Roman numeral labels. 
In Beethoven Piano Sonatas (BPS) and the Well-Tempered Clavier (WTC) datasets, our network outperforms existing models in the prediction of the conventional tonal tasks and the reconstruction of the Roman numeral labels.
Furthermore, we demonstrate that the use of an additional task, RomanNumeral75, is helpful to achieve better results in the final reconstruction step, compared to using the six conventional tasks proposed by previous researchers.

% Some of the ideas presented here, such as the additional output tasks or the alternative representation of spelling may seem odd or arbitrary.
% Originally, we intended to explore different ways of reconstructing a Roman numeral annotation, for example, through the direct prediction of Roman numeral labels, or pitch class sets. 
% Incidentally, we found that the positive effects of MTL continued to benefit the learning process when we predicted the conventional tasks and additional tasks simultaneously, and exploited that to our favour.

% The original goal of the alternative spelling representation was to facilitate a wider range of key transpositions during data augmentation, as the representation would not be restricted to double sharps and double flats.
% We were able to increase the number transpositions through this process, but it was not beneficial to the learning of the model.
% However, it was beneficial if used as input to the initial convolutional block.

We consider that the ideas presented here may be useful to explore different directions in automatic functional harmony research.
For example, although five additional tasks were presented, there are other potential tasks that can be examined, such as triad vs.~seventh classification, tonal function (Tonic, Dominant, Sub-Dominant), or cadence detection. 
Our method for synthesizing `new' training examples applied three simple patterns that lead to better results compared to \emph{block-chord} textures. A deeper investigation of this technique could reveal new ways to exploit it across automatic tonal music analysis problems.

Finally, although we present improvements in the prediction of tonal tasks and reconstruction of the Roman numeral labels, we do not present experiments that assess the chord segmentation, leaving that for future work.

\section{Acknowledgments}
[ANONYMIZED]
% This research has been supported by the Social Sciences and Humanities Research Council of Canada (SSHRC) and the Fonds de recherche du Qu\'ebec–Soci\'et\'e et culture (FRQSC). We would also like to thank user \emph{ClassicMan} from the MuseScore community, who allowed us to use their MusicXML encodings of all Piano Sonatas by Beethoven. This saved us a great deal of time during this research.

% For bibtex users:
\bibliography{ISMIRtemplate}
\end{document}

% \begin{table}
%  \begin{center}
%  \begin{tabular}{|l|l|}
%   \hline
%   String value & Numeric value \\
%   \hline
%   Hello ISMIR  & \conferenceyear \\
%   \hline
%  \end{tabular}
% \end{center}
%  \caption{Table captions should be placed below the table.}
%  \label{tab:example}
% \end{table}

% \begin{figure}
%  \centerline{\framebox{
%  \includegraphics[width=0.9\columnwidth]{figure.png}}}
%  \caption{Figure captions should be placed below the figure.}
%  \label{fig:example}
% \end{figure}

% \begin{equation}\label{relativity}
% E=mc^{2}
% \end{equation}


% In previous research papers, the score collection of Beethoven Piano Sonatas has been consistently a problem. We received written permission from user ``ClassicMan'' to use their scores for this research project. It remains for future work to encode and agree on a version of Beethoven Piano Sonatas scores to use as a baseline.

% A significant portion of the present work has gone into revising the translation and standardization of the meta-dataset. When possible, all the changes have been merged into the main meta-dataset, where other researchers can benefit from the corrections. For all other examples that were curated specifically for this paper, we share all the data within the code repository.

% Three automatic metrics facilitated the detection of errors and problematic annotations or files. In order of priority: score-annotation alignment, pitch information correspondence, and bass correspondence.

% During the data preparation process, these metrics were used to curate the training examples manually. This is a laborious process that lasted for two months. It was later interrupted (due to time constraints) after a certain quality threshold was obtained. During the training process, the metrics were used to filter the training examples from dubious annotations. We refer to this process as ``data scrutinization''. In our experiments, we show the result of performing data scrutinization or not.

% We use the largest dataset of Roman Numeral Analysis annotations currently available \cite{gotham2019romantext}. This dataset consists of original annotations, additionally to the translation of existing datasets into a common, RomanText, representation. The original annotations include Bach's Well-Tempered Clavier, Monteverdi madrigals, and nineteenth-century songs. The translations include TAVERN \cite{devaney2015theme}, ABC \cite{neuwirth2018annotated}, and the MTG Haydn String Quartets \cite{napoleslopez2017automatic}.