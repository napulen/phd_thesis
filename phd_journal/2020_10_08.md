# Next steps during Fall/Winter

As usual, time went quickly and I missed the track of my first goal (~250 words of written ideas per day).

I still like this idea. Being realistic, I don't think I will come up with a dissertation from 250-word chunks of information written once a day. 

Something that may come from this, however, is the habit of writing every day, and keeping my dissertation present in my daily routine. At least in the form of a reminder.

I should really keep doing that.

Revisiting the last ideas I was talking about, things have moved forward since then. We finally got the *On local keys, modulations, and tonicizations* paper accepted. This is going to be a good reference for future work of my thesis. Lots of things to improve/derive from this.

Additionally, I started working on RNA as a generative paradigm. Harmonic reductions of annotated RNA serving as data augmentation examples. It seems to work. I am convinced I can make it work the more time I spent with it.

For example, things to consider:

- Improving the rule-based voice-leading algorithm will provide better training examples
- Examples can be generated by removing non-annotated onsets (e.g., onsets that usually involve non-chord tones and ornaments). However, those blank spaces could also be filled with a reharmonization of the same scale degree or even injecting *artificial* ornaments based on some heuristic.
- Examples can be generated from a portion of the original annotations (e.g., a phrase) but also from the full score. So far, I have seen that computing from the full score exercises the rule-based algorithm better. It usually makes more mistakes. I can at least use this to "debug" the code until I start getting convincing harmonizations/harmonic reductions.

Way too many things to do, and I have only used the Bach chorales for now. As soon as I introduce other datasets, things will get more complicated and interesting.

By the end of my dissertation, I expect to grow a dataset of 100,000 training examples using this technique. I think it will help building a powerful model.

Originally, I wanted to have many examples to investigate different input representations, knowing that scarce data was not an issue behind the results that I collect. I at least expect to be able to answer that question.