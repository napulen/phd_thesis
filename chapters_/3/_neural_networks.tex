% Taken verbatim from Comps Q2

Artificial Neural Networks (ANNs) are machine learning
algorithms that learn arbitrary functions by automatically
learning weights (or parameters) that connect the nodes in
the neural network architecture. Generally, a non-linear
activation function is applied to such weights, introducing
a non-linear behavior in the neural network that allows it
to learn functions of higher complexity, which a linear
model could not possibly learn. The training of the weights
is not achieved by programming task-specific rules but
instead, by identifying simple characteristics of the
training examples and extending them into more complex, more
abstract characteristics. The process of decomposing an
example into a combination of simpler features is known as
\emph{representation learning}, and it is one of the main
ideas that differentiate ANNs from other classes of machine
learning.

The study of ANNs started around the 1940s, and it has been
known through different names throughout the years
\parencite{goodfellow2016deep}.

\guide{A brief history of ANNs}

The research on ANNs can be traced back to the 1940s, when a
bio-inspired \emph{neuron} model was introduced
\parencite{mcculloch1943logical}. This neuron allowed to
model very simple functions by manually setting the weights
that connected the input into the neuron. This idea was
later extended to propose the Perceptron
\parencite{rosenblatt1958perceptron} and Adaline
\parencite{widrow1960adaptive} models, which were able to
automatically derivate such weights from the data. Although
these models showed promise, their popularity decreased
significantly when it was demonstrated that they could not
learn relatively simple functions, like the \emph{XOR}
function \parencite{minsky1972perceptrons}. Due to their
importance, the achievements carried out during this wave of
research (1940s-1960s) are acknowledged by the current
literature \parencite{goodfellow2016deep} and usually
referred to as the \emph{cybernetics} wave of neural
networks research.

Following the wave of cybernetics, a new one started around
the 1980s-1990s, colloquially known as \emph{connectionism}.
During the work of the \emph{connectionists},\footnote{A
term typically used to refer to the scientists of this time
period and research field} the research community benefited
from the development of the current form of the
back-propagation algorithm
\parencite{rumelhart1988learning}. The back-propagation
algorithm became (and remains) an elemental process in the
training of neural networks, which allows to propagate the
error throughout the network by making use of the
\emph{chain rule}. Finding the derivatives of each parameter
in the network, the values of such parameters can be updated
in the ``right direction'' (against the gradient) to improve
the classification accuracy through the next batch of
training examples. This facilitates the automatic training
of large and complicated neural networks, with multiple
layers, neurons, and non-linear activation functions. Even
though this and other improvements made neural networks a
promising area of research, they were still very difficult
to train in practice (due to the difficulty of finding a
good initialization of the weights) and were typically
outperformed by domain-knowledge techniques, losing the
interest of many scientists as a consequence.

Finally, a third wave of research started around 2006, when
new methods for training neural networks were introduced
\parencite{hinton2006fast}. These new methods not only
facilitated the training of neural networks but the training
of \textbf{much larger} neural networks. The interest in
such larger architectures extended, and in a historical
evaluation of the ImageNet dataset in 2012
\parencite{krizhevsky2012imagenet}, neural networks
outperformed the most sophisticated methods of computer
vision, setting a prominent gap in performance between
neural networks and every other method. This had an enormous
implication in the way that neural networks were perceived
by the research community and motivated their application
into different problems and fields of study. We know this
last wave of research as \emph{deep learning}, and it is
currently an active and growing wave of research across many
fields. Around this umbrella term of \emph{deep learning},
many state-of-the-art machine learning techniques have been
developed and continue to be improved.

\guide{Deep learning and Music Information Retrieval}
After the growing interest for neural networks in the wave
of deep learning research, many new models, architectures,
and applications have been proposed and put into practice in
recent years.
%achieving good results and generating subfields of research
%within the umbrella term of deep learning.
Among the most important innovations to the original neural
network architectures, we can consider Convolutional Neural
Networks (CNNs), AutoEncoders, Recurrent Neural Networks
(RNNs), and extensions of CNNs, such as the U-Net.

\guide{AutoEncoders}
AutoEncoders are models designed to copy the input signal
into the output, considering a number of restrictions. This
process is achieved through two steps, the first corresponds
to the \emph{encoding} of the input into a \emph{latent}
representation or \emph{code}, and the second step
corresponds to the \emph{decoding} of the latent
representation (code) into the output.

One of the most useful restrictions imposed to the
AutoEncoder architecture is to reduce the size of the latent
representation compared to the size of the input. By doing
this, the model is forced to learn a restricted amount of
data that \emph{characterizes} the input well enough so that
the decoder part of the model is able to reconstruct the
original signal as much as possible. This can also be
thought as a \emph{compression} of the input signal or a
reduction of the dimensionality of the input.

Other restrictions imposed to AutoEncoders are the
reconstruction of the original signal given a
\emph{distorted} or \emph{noisy} input signal. This is
usually known as a Denoising AutoEncoder (DAE). AutoEncoders
can be thought as unsupervised neural networks given that
the training mechanisms are practically identical to the
ones used in other neural network architectures. They are
also useful in combination with other neural network
architectures, as the latent representation of the
AutoEncoder can be used as an input feature, for example.

In MIR, AutoEncoders have been used, for example, in Optical
Music Recognition (OMR) problems
\parencite{castellanos2018document}.

\guide{U-Net}
Often, the problems that are expected to be solved by
machine learning algorithms require more than identifying
the presence of an object in a given input image. This is
the case, for example, with image segmentation, where an
output class needs to be provided for every pixel in the
image.

For such problems, a traditional CNN architecture is not
feasible, mainly, because the information of the
\emph{location} of the target class is lost through the
convolutional layers of the network. More specifically, the
\emph{pooling} layers of a CNN facilitate the identification
of the strongest features that have been found incrementally
across the image, at the expense of losing the information
regarding \emph{where} they have been found.

The U-Net is a modification of the traditional CNN
architecture, designed to deal with image segmentation
problems and making heavy use of data augmentation
\parencite{ronneberger2015unet}. It was introduced in 2015
for the segmentation of images in the field of biomedical
image processing and, since its introduction, has been
applied to numerous tasks in different fields.

The U-Net architecture consists of two stages, the first one
corresponds to a series of
convolution-nonlinearity-and-pooling layers, analogous to a
regular CNN (referred to as the contracting path). The
hidden layer that results after several of these
convolutional layers is then expanded back to almost the
size of the original image (but smaller than the original).
The expansion is achieved by replacing the \emph{pooling}
layers with up-convolutions. A cropped version of the
corresponding hidden layer in the contracting path is copied
onto the expanding path, giving the characteristic u-shape
of the architecture.

In MIR, models based on the U-Net have been proposed for
source separation \parencite{jansson2017singing,
stoller2018waveunet} and OMR \parencite{hajic2018towards}.

\guide{Other deep learning architectures in MIR}
Throughout the years, the solutions presented in the
research field of deep learning have been applied to
multiple Music Information Retrieval (MIR) tasks. The most
popular ones have already been discussed, however, other
applications include the historical Self-Organizing Maps
(SOMs) in the early 2000s \parencite{kiernan2000scorebased,
harford2003automatic}, Deep Belief Networks (DBNs)
\parencite{hamel2010learning, schmidt2013learning,
chacon2014developing, raczynski2010multiple,
battenberg2012analyzing, herwaarden2014predicting,
zhou2015chord}, and deep feedforward networks
\parencite{cherla2014multiple,  liang2015contentaware,
dawson2018keyfinding, valk2018deep}.
