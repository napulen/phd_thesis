% Copyright 2022 Néstor Nápoles López

The neural network described so far contains trainable
layers that learn parameters based on the error (loss)
propagated by the evaluation of the annotated examples
against the predictions of the network. The predictions of
the network are manifold (9, to be precise) and arranged in
a multitask learning configuration.

The specific multitask learning configuration is perhaps one
of the main contributions of this dissertation, as it
defines the tonal attributes of chords and keys that will be
predicted by the network. In previous work
\parencite{napoleslopez2021augmentednet}, we showed that
having additional tasks is sometimes beneficial, especially
in combination with the synthesized training examples
described in \refsubsec{synthesisofartificialexamples}.

The proposed multitask layer configuration consists of nine
multiclass classification problems: \gls{bass35},
\gls{tenor35}, \gls{alto35}, \gls{soprano35},
\gls{pcset121}, \gls{rn31}, \gls{localkey38},
\gls{tonicization38}, and \gls{harmonicrhythm7}. The tasks
have codenamed with their number of output classes
appended.\footnote{I opted for this naming convention to
more easily track the evolution of the multiclass
classification problems. Some of them, such as the
\gls{pcset121} or \gls{rn31} went through various revisions,
as the vocabularies were adjusted during data exploration
and experiments. The names, definitions, and number of
classes presented in this dissertation represent the latest
definition of these problems.}

Each of these tasks is subsequently used to generate the
final \gls{rna} annotations in string form.
