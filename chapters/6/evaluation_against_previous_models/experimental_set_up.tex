% Copyright 2022 Néstor Nápoles López

The test used for the comparison was the same one used in
the experiment of \refsec{trainingontheaggregateddataset}.
There are a total of 94 files in the test set, which are
sampled from the seven publicly available datasets (see
\refsec{publiclyavailabledatasets}). All of the input files
are provided in \gls{musicxml} format and the output files
in \gls{romantext}. Some of the models compared do not
output their annotations in the \gls{romantext}. Therefore,
the output annotations were translated into the format for a
common representation among all models.

Regarding the training of the model proposed in this
dissertation, it was trained for 200 epochs using a fixed
learning rate of $10^{-3}$ on the full training set plus
both methods of data augmentation. Afterwards, the model was
fine-tuned for an additional 100 epochs with a lower
learning rate of $10^{-5}$ on only the ``real'' training
data (i.e., removing transpositions and synthesized files).

