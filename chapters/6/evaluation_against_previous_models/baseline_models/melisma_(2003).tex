% Copyright 2022 Néstor Nápoles López

A comparison against the \gls{melisma} model is presented
for historical reference. \gls{melisma} was arguably the
first end-to-end \gls{arna} system that could annotate any
arbitrary musical score. After the development of the
\emph{tsroot} program \parencite{sapp2009tsroot}, the
\gls{melisma} system was capable of processing music scores
in the \gls{humkern} representation. For example, it was
used to annotate scores in the \emph{KernScores} library
\parencite{sapp2005online}. This model, to the best of my
knowledge, has never been evaluated against other methods.
Thus, an evaluation is presented here. Because the
\gls{melisma} model only supports \gls{humkern} inputs, all
of the \gls{musicxml} examples in the test set of this
evaluation were converted to \gls{humkern}. 

During the first attempt to make such conversion, many
mistranslations were found among the files of the test set,
which lead to \gls{melisma} being unable to process them. In
order to mitigate this problem, the \gls{musicxml} files
were preprocessed. The preprocessing consisted in removing
all the \emph{voice} information of the score, by collapsing
all the staffs and voices in the score into a single staff
with chord blocks and tied notes. This process seemed useful
for all other models as well, thus, the preprocessing step
of the \gls{musicxml} files was applied to the entire test
set in all experiments. The preprocessing was facilitated by
the \code{chordify()} function of the \emph{music21} Python
library \parencite{cuthbert2010music21}.

% \reftab{haydnsample_melisma} shows the representation of
% the input (left) and output annotations (right) provided
% by \gls{melisma}.

% \phdtablefitv[Example input (left \gls{spine} in
% \gls{humkern}) and output (right \gls{spine} in
% \gls{humharm}) from the \gls{melisma} model. The input
% corresponds to the music excerpt in
% \reffig{haydnsample}][0.9]{haydnsample_melisma}

% Each of the \gls{humharm} outputs generated by
% \gls{melisma} is translated to \gls{romantext} for direct
% comparison with the ground truth of the test set. The
% translation of \reftab{haydnsample_melisma} is shown
% below:

% \begin{verbatim} Composer: Haydn, Franz Joseph Title: Op.
%     20 No. 3 - IV Model: Melisma (2003), translated by
%     Néstor Nápoles López
    
%     Time Signature: 4/4
%     m1 b2 C: ii b2.5 i6 b3 V2
%     m2 i b3 V43 b3.5 i b4 V6
%     m3 V b1.5 V7 b2.5 i b3 V6 b3.5 i b4 ii
%     m4 V b1.5 V2 b2 ii
% \end{verbatim}

% In this excerpt, the system unfortunately fails to provide
% the annotation of the key at the beginning of the piece.
% Although some of the annotations are correct, they are
% interpreted in the default key context of $\keyC$. This is
% not always the case. Oftentimes, the model is able to
% provide key annotations at the beginning of the piece and
% in modulations within the piece. The reasons for these
% failures were not explored further and are left for future
% work.

% In total, out of 94 files in the test set, the
% \gls{melisma} model is able to provide valid \gls{rna}
% outputs in the \gls{humharm} format for \missing{XX} of
% them.
