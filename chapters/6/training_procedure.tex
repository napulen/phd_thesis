% Taken verbatim from AugmentedNet

\guide{Training procedure}

\textbf{Epochs.}
We set a fixed number of 100 epochs in all experiments. We
found that the use of early stopping was unreliable to
determine the end of the training process. Instead, we saved
the weights after each epoch. After all epochs, we selected
the best weights based on a custom metric that prefers the
highest accuracy on the six conventional functional harmony
tasks.
% We set the number of layers in the initial convolutional
% block to 6. Each convolutional layer has a kernel size of
% 1, 2, 4, 8, 16, and 32 timesteps, respectively. In
% practice, this means that the last convolutional layer
% provides information up to a whole note away from the
% current timestep.

\guide{Hyperparameters}

\textbf{Other hyper-parameters.}
Each of the layers in the network is accompanied by batch
normalization before the activation function. In the
recurrent layers, we apply the batch normalization after the
activation function. All convolutional and dense layers use
the rectified linear unit (ReLU) as their activation
function. However, the two GRU layers use $\tanh$. In all of
our experiments, we used 16 sequences per batch and Adam
\cite{kingma2014adam} as our optimizer, with a learning rate
of $10^{-7}$.



\textbf{Computing time.} The network was trained on a
personal laptop\footnote{Intel i7 10750h, Nvidia RTX 2070,
32GB DDR4} with a Linux operating system, Tensorflow 2.4.1,
and GPU acceleration. With these hardware and software
conditions, the training times are approximately ~30 minutes
(BPS only), ~40 minutes (BPS+WTC), and ~250 minutes (Full
dataset). The number of trainable parameters in the network
is close to 90,000. This number already includes all the
parameters introduced by the additional output tasks.
Therefore, the model is similar in size to recent models
\cite{micchi2020not, chen2021attend}.

\guide{Evaluation procedure}

In the past, the models by Micchi et al.
\cite{micchi2020not} and Chen and Su \cite{chen2021attend}
have been evaluated using the Beethoven Piano Sonatas (BPS)
and the Well-Tempered Clavier (WTC) datasets. We too provide
direct comparisons in these two datasets, however, we also
share the results of our model across the Annotated
Beethoven Corpus (ABC) \cite{neuwirth2018annotated},
annotated Haydn string quartets Op.20 (HaydnOp20)
\cite{napoleslopez2017automatic}, Theme and Variation
Encodings with Roman Numerals (TAVERN)
\cite{devaney2015theme}, and When-in-Rome (WiR)
\cite{gotham2019romantext} datasets.

For all datasets, the same procedure was followed regarding
 data splits. Training, validation, and test splits were
 produced randomly (except in BPS, where they were provided
 by Chen and Su \cite{chen2018functional}).
 %\footnote{In the original splits of BPS, there is a
 %duplicated example in the validation and test sets. We
 %noticed that Micchi et al. \cite{micchi2020not} corrected
 %the splits to remove the data leakage. Thus, we follow the
 %splits by Micchi et al. \cite{micchi2020not}}
A summary of all datasets is shown in Table
\ref{tab:datasets}. The summary indicates the number of
files in each split and the number of sequences (each of 640
frames) that were collected from that split.


Preliminary experiments were conducted in the training set,
using the validation set to assess the generalization,
adjust the hyper parameters, and inform the design of the
network architecture. The best-performing version of our
model was run once in the test set, this time including the
validation portion as part of the training. The results
obtained for all the rows labeled \emph{Full dataset} in
Table \ref{tab:results} report the results obtained on the
corresponding test split. To support reproduction of this
work, we provide the exact data splits at [ANONYMIZED].

\textbf{Data augmentation} For every training example, we
synthesized and texturized an additional one, using only the
Roman numeral annotations (and ignoring the original score).
The original and texturized training examples were
transposed to different keys for further data augmentation.
Both forms of data augmentation were only applied to the
training set of a particular experiment, leaving the
validation/test set intact to prevent any data leakage.

\begin{table}
 \begin{center}
 \begin{tabular}{l|lll}
  & & Files (Seqs) & \\
  Dataset & Training & Validation & Test \\
  \hline
  ABC \cite{neuwirth2018annotated} & 50 (448) & 10 (97) & 10
  (99) \\
  BPS \cite{chen2018functional} & 18 (155) & 7 (75) & 7 (75)
  \\
  HaydnOp20 \cite{napoleslopez2017automatic} & 16 (91) & 4
  (19) & 4 (19) \\
  TAVERN \cite{devaney2015theme} & 38 (404) & 8 (68) & 8
  (64) \\
  WiR \cite{gotham2019romantext} & 107 (301) & 21 (61) & 21
  (51) \\
  WTC \cite{gotham2019romantext} & 12 (25) & 6 (13) & 6 (14)
  \\
  \hline
  Total & 241 (1424) & 56 (333) & 56 (329) \\
%   +Transposition & XX & - & - \\
%   +Synthetic & XX & - & - \\
%   Grand total & XX & - & - \\
 \end{tabular}
\end{center}
 \caption{The functional harmony datasets used in our experiments. The splits were generated randomly (except for BPS). For each split, the number of files and the number of sequences (in parenthesis) are indicated.}
 \label{tab:datasets}
\end{table}

\begin{table*}
\begin{center}
\begin{tabular}{lll|lllll|l}
Dataset & Trained with & Model & Key & Degree & Quality &
Inversion & 75RN & RN[, AltRN] \\ [1.5ex] \hline \hline
WiR & Full dataset & AugNet & 81.6 & 70.0 & 87.1 & 90.9 &
70.1 & 55.8, \textbf{61.6} \\ [1ex] \hline\hline
HaydnOp20 & Full dataset & AugNet & 79.5 & 61.8 & 78.2 &
80.9 & 56.9 & 45.7, \textbf{48.4}\\ [1ex] \hline\hline
ABC & Full dataset & AugNet & 82.3 & 65.5 & 78.2 & 75.8 &
63.9 & 43.8, \textbf{47.4} \\ [1ex] \hline\hline
TAVERN & Full dataset & AugNet & 91.0 & 60.3 & 78.1 & 77.2 &
67.3 & 43.9, \textbf{53.5} \\ [1ex] \hline\hline
WTC & Full dataset & AugNet & 75.2 & 66.1 & 74.5 & 75.2 &
60.2 & 45.0, \textbf{47.7} \\
\hline
% WTC & BPS+WTC & AugmentedNet & \textbf{87.1} & 69.9 & 72.4
% & 73.3 & & 47.5, \textbf{49.9} \\
WTC & BPS+WTC & AugNet & \textbf{85.1}$_{\pm4.0}$ &
62.9$_{\pm5.5}$ & 69.1$_{\pm1.9}$ & 70.1$_{\pm3.7}$ &
59.9$_{\pm3.4}$ & 42.9$_{\pm4.2}$, \textbf{46.9}$_{\pm4.7}$
\\
WTC & BPS+WTC & CS21 & 56.3$_{\pm2.5}$ & - & - & - & - &
26.0$_{\pm1.7}$ \\ [1ex] \hline\hline
BPS & Full dataset & AugNet & \textbf{83.5} & \textbf{71.8}
& \textbf{79.8} & \textbf{72.7} & 69.1 & 44.6, \textbf{48.4}
\\
BPS & Full dataset & Mi20 & 82.9 & 68.3 & 76.6 & 72.0 & - &
42.8 \\
\hline
BPS & BPS+WTC & AugNet & \textbf{84} & 70.4 & 79.4 & 70.2 &
67.5 & 43.4, \textbf{46.2} \\
BPS & BPS+WTC & CS21 & 79.0 & - & - & - & - & 41.7 \\
\hline
BPS & BPS & AugNet & \textbf{83.7} & \textbf{69.6} &
\textbf{80} & \textbf{70.4} & 67.6 & 42.9, \textbf{46.5} \\
BPS & BPS & Mi20 & 80.6 & 66.5 & 76.3 & 68.1 & - & 39.1 \\
BPS & BPS & CS19 & 78.4 & 65.1 & 74.6 & 62.1 & - & - \\
BPS & BPS & CS18 & 66.7 & 51.8 & 60.6 & 59.1 & -  & 25.7
\end{tabular}
\end{center}
 \caption{Summary of the performance of five functional
 harmony models: Chen and Su (2018, 2019, and 2021), Micchi
 et al. (2020), and AugmentedNet. For the WTC dataset, the
 experiment with training done over BPS+WTC replicated the
 4-fold cross validation presented by Chen and Su
 \cite{chen2021attend}. In this case, $\pm$ indicates the
 standard deviation. For all other rows, the results present
 the performance on the held test set. The comma-separated
 values in RN of the AugmentedNet rows indicate different
 methods for reconstructing the Roman numeral, as explained
 in \ref{sec:additionaltasks}.}
 \label{tab:results}
\end{table*}


\guide{Results}


\textbf{Beethoven Piano Sonatas.} The last rows of Table
\ref{tab:results} show the results of our model when
evaluated over the BPS dataset. To the best of our efforts,
we replicate the experimental conditions of the models we
compare to. Single lines in the table delimit experiments
that are directly comparable. For example, the upper rows of
BPS compare the results of Micchi et al.
\cite{micchi2020not} using all of their available training
data and our model using all of our available training data.

\textbf{Well-Tempered Clavier.}
The second to last group of rows in Table \ref{tab:results}
show the results of our model when evaluated on the WTC
dataset. The model by Chen and Su \cite{chen2021attend}
presented the results over 4-fold cross validation. We
replicate this study for direct
comparison.\footnote{However, we used our test split for the
\emph{Full dataset} experiment in WTC.} As they have, we
include the average accuracy across the 4 folds, and the
standard deviation.

The results show that our model outperforms both the recent
convolutional methods \cite{micchi2020not} and
Transformer-based ones \cite{chen2021attend} in the
reconstruction of the Roman numeral label.
% Furthermore, the addition of data from a different dataset
% seems to improve the results. For example, training with
% WTC and BPS benefits the performance in BPS and vice
% versa.
For ABC, HaydnOp20, TAVERN, and WiR, we show the
generalization of our model when using all the training data
available on the corresponding held test set.

\textbf{Alternative resolution of Roman numeral annotations.}
As discussed in Section \ref{sec:additionaltasks}, it is
possible to use the 75 most-common Roman numeral strings as
an alternative task to the chord root, chord quality,
primary degree, and secondary degree tasks. Thus, an
alternative resolution of the Roman numeral label (AltRN) is
presented in the last column of the AugmentedNet results.
This accuracy corresponds to the reconstruction of the Roman
numeral using the 75 most-common Roman numerals, chord
inversion, and local key tasks. We assume that if these
three tasks are predicted correctly, the Roman numeral label
has been reconstructed correctly. We found that this, in
fact, leads to better results compared to the six
conventional tonal tasks. Table \ref{tab:results} shows the
comma-separated accuracy values for the Roman numeral, the
one computed from the six conventional tonal tasks (RN), and
the alternative approach (AltRN). For completeness, we show
too the accuracy of the RomanNumeral75 output task, labeled
75RN in the table.

In summary, the \emph{Full dataset} rows show the best
results achieved by our model for each dataset. In all
cases, the results of our model are higher than existing
methods in the final reconstruction of the Roman numeral
label. Additionally, the best results in the reconstruction
are achieved via the chord inversion, local key, and our
RomanNumeral75 task.

\guide{Discussion}
