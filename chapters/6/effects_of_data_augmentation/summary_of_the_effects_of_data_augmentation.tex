% Copyright 2022 Néstor Nápoles López

The results in Figures \ref{fig:da_val_loss} and
\ref{fig:da_val_accuracy} show the performance of the model
with and without data augmentation for 200 epochs on each
dataset. 

\reftab{augmentation}
summarizes the performance obtained after selecting the best
weights for each experiment.

\phdfigure[Validation loss of the different data
augmentation strategies]{ablation_augmentation_loss}

\phdfigure[Validation accuracy of the different data
 augmentation strategies]{ablation_augmentation_accuracy}

\phdtable[Average performance and standard deviation over
the four experiments with data augmentation on each publicly
available dataset]{augmentation_results}

Both data augmentation techniques have a positive effect in
the performance of the model compared to only using the
original data. The performance of the transposition
continues to be the most effective data-augmentation
technique, however, it also substantially increases the
training time compared to the synthesis itself. The most
effective technique is to use both, transposition and
synthetic examples, although the improvement is not
extensive. However, considering the difficulty of obtaining
expert-curated data for \gls{arna}, it seems to provide a
consistent improvement at the expense of more computation.

In future experiments, the proposed model is trained with
both data augmentation techniques simultaneously.
