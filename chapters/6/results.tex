% Copyright 2022 Néstor Nápoles López

This section introduces the results of comparing the five
\gls{arna} models. The first metric compared is the
inference time on the test set. The second metric is the
average accuracy obtained across the test set for the
\gls{pcset} $\elpcset$, key $\elkey$ and inversion $\elinv$
compared to the same labels in the ground truth.

% Unfortunately, the models are often defined in different
% ways and solving similar but not identical problems,
% making a one-to-one comparison difficult. For example, the
% model by \textcite{mcleod2021modular} considers one layer
% of key analysis, whereas this model and others consider
% two layers (i.e., modulations and tonicizations). However,
% when possible, a comparison of individual tasks is
% performed. Using a reduced vocabulary of Roman numerals,
% it is possible to ``collapse'' several classes of chords
% into a single string representation. Using this approach,
% the models can be compared for their Roman numeral
% annotations directly, instead of the classification
% problems. This approach is particularly useful when
% assessing the performance of the models on difficult
% chords, that appear only sporadically in the dataset. The
% performance on such difficult chords is presented in
% \refsubsubsec{performanceondifficultchords}.
