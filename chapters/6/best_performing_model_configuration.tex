% Copyright 2022 Néstor Nápoles López

\phdtable[Performance obtained in the ablation studies,
compared to the baseline configuration of the network. The
``Baseline'' row shows the average accuracy obtained in each
task across the 5-fold cross validation. Each row of the
ablation studies shows the difference in accuracy between
the value obtained in the experiment and the baseline. The
biggest drop in performance for each task column is
highlighted in bold font]{ablation}

\reftab{ablation} shows a summary of the performance of the
different configurations in the ablation experiments. Some
of these results confirm the expected results. For example,
removing the onset information affects the
\gls{harmonicrhythm7} more than any other change in the
network, indicating that measure onsets are important for a
better chord segmentation. Removing the \gls{chroma19} input
representation has drastic effects on the prediction of
chords (e.g., \gls{pcset121}, \gls{rn31}), but surprisingly
only in the \gls{soprano35} task, out of all the ``SATB''
tasks. On the contrary, removing the bottom note affects the
performance of the \gls{bass35} task, as expected, but also
surprisingly the \gls{tenor35} and \gls{alto35} ``SATB''
tasks.

Overall, the biggest drop in performance happens when the
recurrent layers of the network are removed. This has a
notable effect on the \gls{localkey38} and
\gls{tonicization38} tasks, which are generally the tasks
with the longer-term dependencies. 

All of the modifications in the ablation study have a
negative performance compared to the baseline model, except
for the dense linear layer. This was an unexpected result,
because that did not seem to be the case in preliminary
experiments. It could be that the nonlinear activation in
the dense layers of the baseline model work better when data
augmentation is introduced. This will be explored further.
