% Copyright 2022 Néstor Nápoles López

\phdtablefit[Performance obtained in the ablation studies,
compared to the baseline configuration of the network. The
``Baseline'' row shows the average accuracy obtained in each
task across the 5-fold cross validation. Each row of the
ablation studies shows the difference in accuracy between
the value obtained in the experiment and the baseline. The
biggest drop in performance for each task column is
highlighted in bold font]{ablation}

\reftab{ablation} shows a summary of the performance of the
different configurations in the ablation experiments. Some
of these results confirm the expected results. For example,
removing the \gls{duration14} input representation affects
the \gls{harmonicrhythm7} more than any other change in the
model configuration. This might indicate that measure onsets
are important for a better chord segmentation. Removing the
\gls{chroma19} input representation has noticeable effects
on the prediction of chords (e.g., \gls{pcset121},
\gls{rn31}). Unexpectedly, it also affects the
\gls{soprano35} task more than any other \gls{satb35} task.
On the contrary, removing the \gls{bass19} input
representation affects the performance of the \gls{tenor35}
and \gls{alto35} tasks, in addition to the \gls{bass35},
which was the expected outcome.

Overall, the biggest drop in performance happens when the
recurrent layers of the network are removed. This has a
notable effect on the \gls{localkey38} and
\gls{tonicization38} tasks, which are generally the tasks
with the longer-term dependencies. 

All of the modifications in the ablation study have a
negative performance compared to the baseline model, except
for the dense linear layer. This was an unexpected result,
because that did not seem to be the case in preliminary
experiments. It could be that the nonlinear activation in
the dense layers of the baseline model work better when data
augmentation is introduced. This will be explored further.
