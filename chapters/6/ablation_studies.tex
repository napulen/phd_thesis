% Copyright 2022 Néstor Nápoles López

It is difficult to understand what kind of representations a
deep learning model learns during training. Ablation studies
are an useful way to inspect the contribution of its
different components. This section introduces a series of
experiments to evaluate the performance of the model after
modifying or removing some of the components of the neural
network. The experiments are divided by sections of the
neural network: input representations, convolutional layers,
dense layers, and recurrent layers.

The ablation studies were run over the aggregated training
dataset using 5-fold cross-validation. There was no use of
data augmentation, neither in the form of transposition nor
synthetic files, whose effects was evaluated separately in
\refsec{effectsofdataaugmentation}.
