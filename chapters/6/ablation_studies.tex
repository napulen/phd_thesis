% Copyright 2022 Néstor Nápoles López

It is difficult to understand what kind of representations a
deep learning model learns during training. Ablation studies
are an useful way to inspect the contribution of its
different components. This section introduces a series of
experiments to evaluate the performance of the model after
modifying or removing some of the components of the neural
network. The experiments are divided by sections of the
neural network: input representations, convolutional layers,
dense layers, and recurrent layers.

The ablation studies were run over the aggregated dataset,
without transposition nor synthetic files for data
augmentation, whose effects was evaluated separately (see
\refsec{effectsofdataaugmentation}).
