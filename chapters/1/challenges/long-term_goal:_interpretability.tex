% Copyright 2021 Néstor Nápoles López

% This is \refsubsec{long-termgoal:bettermusictheories},
% which introduces the long-term goal: better music
% theories.

Perhaps a more interesting question is, what do we do if the
models become sufficiently accurate? One important aspect
that may be useful in music theory is that computers quickly
evaluate algorithms that would take a long time for a human
being to internalize. A simple example would be
voice-leading rules, which take many hours of practice for a
human to learn, but can be implemented and fine-tuned for a
computer within hours. \reffig{rimsky_voiceleading} shows an
example of a rule-based voice-leading algorithm, which I
implemented based on the rules in
\textcite[p.~10]{huron2016voice}.\footnotelink{https://github.com/napulen/romanyh}
The model arranges each chord based on the input \gls{rna}
annotations provided, respecting the encoded voice-leading
rules while connecting each pair of chords. 

\phdfigure[A voice-leading exercise that was automatically
generated from the \gls{rna} annotations in a modulation
example from Rimsky-Korsakov's Practical Manual of
Harmony]{rimsky_voiceleading}

One challenge in the implementation of this algorithm was
that some rules seemed to be detrimental to good voice
leading when they were implemented textually. For example,
the rule about augmented intervals:

\begin{italicquotes}
    Rule 16. Augmented intervals rule: Avoid augmented
    melodic intervals.
\end{italicquotes}

Implementing this rule unchanged results in a model that
avoids augmented unisons at all costs. One could argue that
computational models provide a rigorous empirical platform
to ``test'' the robustness of a music theory, a rigorous
platform that is difficult to come by in traditional human
analysis. Although the internal ``algorithm'' in a deep
learning model is not as easy to interpret as the one in
this voice-leading example, it is still possible to review
the features learned by a deep learning model in its
internal representations. This process has been studied in
computer vision, and it would be worth to be studied in
music models as these get increasingly accurate. Perhaps
this goal, interpretability, should be one that researchers
working on computational models should take into
consideration in the long term.
