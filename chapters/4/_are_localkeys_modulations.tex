% Taken verbatim from experiment in napoleslopez2020local

\guide{Experiment}~\label{sec:exp}

In our experiment, we investigate whether the predictions of
three local-key-estimation computational models coincide
with the modulation and tonicization annotations of the
music theory textbooks.

\guide{Evaluation Procedure}~\label{sec:evaluations}

Even if two predicted keys do not match the ground-truth
label, one of the predictions may still be better than the
other, due to the \emph{close} or \emph{far} relationship
that a predicted key may have to the ground truth. For this
reason, in addition to accuracy, we propose to also use a
weighted score to evaluate each onset's key.

Table \ref{tab:mirexscore} shows the two sets of weights we
utilized to evaluate the key predictions, based on the
relationship that the predicted key has to the ground truth.
The MIREX score has been used in the annual Music
Information Retrieval Evaluation eXchange (MIREX) evaluation
of global-key-estimation algorithms since 2005
\cite{downie2005}.

% \begin{table}[h] \begin{tabular}{l|l} \textbf{Key
% prediction's relation to the ground truth} &
% \textbf{Score} \\ \hline Same key & 1.0 \\
% Dominant / SubDominant & 0.5 \\
% Relative Major / Relative Minor & 0.3 \\
% Parallel Major / Parallel Minor & 0.2 \\
% Other & 0.0 \\
% \end{tabular} \caption{MIREX weighted score for key
% predictions.} \label{tab:mirexscore} \end{table}

% \begin{table}[h]
%     \caption{Evaluation weights for the key predictions.}
%     \label{tab:mirexscore}
%     \begin{tabular}{l|cc}
%         \toprule
%         Key Relationship (Reference, Predicted) & Accuracy &
%         MIREX \\
%         \midrule
%         Same key                                & 1.0      &
%         1.0   \\
%         Dominant / SubDominant                  & 0.0      &
%         0.5   \\
%         Relative Major / Relative Minor         & 0.0      &
%         0.3   \\
%         Parallel Major / Parallel Minor         & 0.0      &
%         0.2   \\
%         Other                                   & 0.0      &
%         0.0   \\
%         \bottomrule
%     \end{tabular}
% \end{table}

We apply both evaluations to the key of every onset in the
score. The annotations are evaluated according to Equation
\ref{eqn:mirex}.

\begin{equation}
    \label{eqn:mirex}
    \mathit{score} = \frac{\sum_{i=0}^{N} \mathit{w(k_i, l_i) d_i}}{\sum_{i=0}^{N} d_i}
\end{equation}

$N$ represents the number of onsets in the input score, $k$
is a vector of ground-truth key annotations for each onset,
$l$ is the vector of local-key predictions provided by the
model for each onset, and $d$ is a vector with the durations
in quarter notes of every onset. Note that the vector $k$
corresponds to either the labels in the \emph{Modulation} or
\emph{Tonicization} columns of Table \ref{tab:annotations},
depending on the task.

The $w$ function is a piece-wise function that evaluates
either of the weighted scores shown in Table
\ref{tab:mirexscore}, given a ground-truth key and a
prediction. The scalar value $score$ is in the range $[0,
1]$. A value of $1.0$ is obtained if and only if the model
predicts the key correctly at every onset. A value of $0.0$
is obtained if and only if the model makes incorrect
predictions (and for the MIREX weights, also without any
partial value) at each onset.

Using this methodology, we evaluate four baseline models and
three local-key-estimation models from the literature. In
total, we perform four evaluations for each model:
% (1) modulation with the accuracy weights, (2) tonicization
% with the accuracy weights, (3) modulation with the MIREX
% weights, and (4) tonicization with the MIREX weights.
\begin{enumerate}
    \item Modulation ($k=Modulation$) by accuracy
    ($w=Accuracy$).
    \item Tonicization ($k=Tonicization$) by accuracy
    ($w=Accuracy$).
    \item Modulation ($k=Modulation$) by MIREX ($w=MIREX$).
    \item Tonicization ($k=Tonicization$) by MIREX
    ($w=MIREX$).
\end{enumerate}

These evaluations coincide with the results shown in
Figure~\ref{fig:plot}.

% \begin{table}[h] \caption{Evaluations}
%  \label{tab:evaluations} \begin{tabular}{l|ll} \toprule &
%  Accuracy weights & MIREX weights \\
%     \midrule Modulation Ground Truth & Evaluation 1 &
%     Evaluation 3 \\
%     Tonicization Ground Truth & Evaluation 2 & Evaluation
%     4 \\
%  \bottomrule \end{tabular} \end{table}

\guide{Baseline Models}

We describe two baseline models (\emph{B1} and \emph{B2})
that---we expect---will perform worse than existing
local-key-estimation algorithms. Similarly, we propose two
theoretical ``models'' that set the maximum performance that
can be achieved when designing a modulation or tonicization
model (\emph{B3} and \emph{B4}). These artificial models
consist simply of the ground truth annotations for
modulations and tonicizations, but evaluated in the opposite
task (i.e., as if they were local-key predictions coming
from a model). We expect that these baselines will set a
reasonable frame for inspecting the performance of the
\emph{real} local-key-estimation models.

\guide{Random guess (B1)}
This model randomly chooses a key label for every onset in
the piece.\footnote{
    %In all of our evaluations, we collapse two enharmonic
    %spellings of a key as the same key label (in the range
    %[0--23]).
    The key label is generated by choosing randomly between
    24 possible keys ([0--23]), collapsing all enharmonic
    spellings into the same class. This may occlude
    important hints given in the note spellings of music
    scores, however it guarantees that this method can be
    applied to MIDI and audio files, which lack
    pitch-spelling information.} We expect this model
    (\emph{B1}) to be the worst-performing model in our
    experiment.

\guide{Global-key guess (B2)}
Given the large body of work that exists in
global-key-estimation algorithms, it would be reasonable to
assume that using the predictions of a global-key-estimation
model in every onset would deliver reasonable results. We
incorporate these global-key predictions as a baseline
model, to compare it against the more specialized
local-key-estimation models. The global-key-estimation model
that we considered is the default key-estimation model in
music21 \cite{cuthbert2010music21}.

\guide{Modulation (B3) and tonicization (B4) ground truth}

Due to the overlap that exists between the modulation and
tonicization key labels,\footnote{This is because we
duplicate the modulation label in the tonicization column
unless there is a tonicization (see Table
\ref{tab:annotations}).} it is expected that a
good-performing modulation model would also achieve a good
performance in predicting tonicizations (and vice versa). In
order to observe this, we consider two additional models:
the ground truth of modulation employed as a ``model'' that
predicts tonicization (\emph{B3}), and the ground truth of
tonicization employed as a ``model'' that predicts
modulation (\emph{B4}). For simplicity, we refer to these as
baseline models, although they represent ground-truth
annotations and not computational models per se.

We evaluate the performance that each of these theoretical
models, \emph{B3} and \emph{B4}, achieves in its own task
and the opposite one. More specifically, we expect the
following: (1) these models should obtain a perfect score in
their own task (no matter which weights are utilized) and
(2) both models should obtain an identical performance when
evaluated in the opposite task.\footnote{This is also true
for the MIREX weights, because the evaluation is
symmetrical. That is, $w(gt, pred) = w(pred, gt)$; when
$w=MIREX$}

\guide{Local-Key Models from the Literature}
Three recent models of local-key estimation are evaluated.
As part of the results in this paper, we intend to
investigate whether these three models are better suited for
finding ``modulations'' or ``tonicizations''. We consider
that this methodology could equally be applied to other
symbolic and audio local-key-estimation models.

\guide{N\'{a}poles L\'opez et al. (M1)} This model computes
two stages of output: local keys and a global key
\cite{napoleslopez2019key}. Both stages are computed through
an HMM. The main parameters of the HMM are a set of
\emph{key profiles} and a table of key distances. We compute
both stages but only evaluate the local-key predictions. The
model is applied with its default parameters.

\guide{Feisthauer et al. (M2)}
This model estimates the succession of keys and can be
configured by adjusting the weights associated to three
proximity measures~\cite{feisthauer2020smc}. Two sets of
weights are used. The first set consists of the default
weights when the model is not trained (M2a). The second set
consists of the optimal weights after training the model on
Mozart's string quartets (M2b).

\guide{Micchi et al. (M3)}
This model was introduced by Micchi et
al.~\cite{micchi20roman} and utilizes an LSTM network to
provide the harmonic analysis of a musical excerpt, which is
described through six features: key, degree 1, degree 2,
quality, inversion, and root. We evaluate the key
predictions of the model when it is used without any
post-processing. A web application is also provided by
Micchi et al. to facilitate the process of generating these
or other
annotations.\footnote{\url{http://roman.algomus.fr/}}

All of the local-key-estimation models have been trained on
different datasets (see Table \ref{tab:corpus}) and have
been used with their default parameters. The dataset of
modulations and tonicizations introduced in Section
\ref{sec:dataset} has been utilized only as a \emph{test}
set to these models. It is likely that the models would
achieve better results if they were trained on a sample of
the dataset. However, the current size of the dataset is not
sufficient to provide training, validation, and test splits.
Therefore, we decided to limit its use as a test set. With
this, we investigate the generalization capabilities of
these pre-trained models.

\guide{Results and discussion}~\label{sec:res}

Figure \ref{fig:plot} shows the four evaluations of the
baseline and local-key-estimation models. The MIREX scores
are generally higher because they reward a key prediction
that is \emph{nearby} the correct class. This has increased
the results of virtually all models. However, the global-key
baseline model (\emph{B2}) has benefited the most from the
MIREX evaluation, followed by \emph{M2b}. This suggests that
these models predict keys that are nearby the ground truth,
while other models tend to ``hit-or-miss''.

For the reverse ground truth ``models'', \emph{B3} and
\emph{B4}, the results are symmetric, as expected. When they
are used in the opposite task, they have a quasi-perfect
evaluation on \emph{ASC}, \emph{KP} and \emph{Reg}.
Incidentally, this shows the relatively low number of
tonicizations in these textbooks (see Section
\ref{sec:tonicization}). However, in \emph{Tch} and
especially \emph{Rim}, where there is a heavier use of
tonicizations, the local-key-estimation models show an
inclination toward the tonicization predictions, rather than
the modulation ones. This is unexpected, as most researchers
do not describe their local-key-estimation models as
``tonicization finders''.

As expected, the random-guess baseline (\emph{B1}) is the
worst performing model in all evaluations. It also
highlights the success of the global-key-estimation model
(\emph{B2}) compared to a random guess. This model
(\emph{B2}) achieves good performance overall; in the
\emph{Reg} examples, it even achieves better performance
than all the specialized local-key-estimation models
(\emph{M1}, \emph{M2a-b}, and \emph{M3}).

% Despite that this dataset is specialized on musical
% contexts with modulations and tonicizations, there are
% still many onsets that match the prediction of the global
% key.

The N\'apoles L\'opez et al. model \emph{(M1)} achieves a
good performance overall, and does slightly better in
predicting tonicizations than modulations. This is at least
the case for \emph{Tch}, and more evidently, for \emph{Rim}.


% \begin{figure*}
%     \centering
%     \includegraphics[width=\linewidth]{figs/plots_table}
%     \caption{Evaluation scores for each model on each
%     textbook of our dataset. The models predict modulations
%     and tonicizations. Furthermore, they are evaluated using
%     accuracy and MIREX weights, as described in Section
%     \ref{sec:evaluations}. A plot is shown for each of the
%     four evaluations. The $y$ axis shows the evaluations on
%     different textbooks of our dataset, as the performance
%     varies from one to another. The $x$ axis shows the mean
%     score obtained by a model across all the files in the
%     textbook. Bold scores indicate the best-performing model
%     in a given textbook and task, excluding \emph{B3} and
%     \emph{B4} (see Section 4.2.3).}
%     \label{fig:plot}
%     \Description{A plot of the results for both tasks
%     according to the MIREX score.}
% \end{figure*}

% \begin{table} \caption{Accuracy score.}
%  \label{tab:acc_results} \begin{tabular}{clccccc} \toprule
%  Model & Task & ASC & KP & Reg & Rim & Tch\\
%     \midrule B1 & Mod & 0.05 & 0.03 & 0.02 & 0.04 & 0.03\\
%       & Ton & 0.05 & 0.03 & 0.02 & 0.07 & 0.05\\
%     B2 & Mod & 0.61 & 0.49 & \textbf{0.53} & 0.28 & 0.25\\
%       & Ton & 0.62 & 0.48 & \textbf{0.52} & 0.52 & 0.34\\
%     \hline M1 & Mod & 0.82 & 0.74 & 0.45 & 0.35 & 0.51\\
%       & Ton & \textbf{0.84} & 0.75 & 0.45 & 0.69 & 0.63\\
%     M2a & Mod & 0.78 & 0.52 & 0.36 & 0.35 &
%     \textbf{0.70}\\
%         & Ton & 0.79 & 0.52 & 0.36 & 0.47 &
%         \textbf{0.77}\\
%     M2b & Mod & 0.44 & 0.39 & 0.11 & 0.37 & 0.41\\
%         & Ton & 0.44 & 0.39 & 0.11 & 0.27 & 0.32\\
%     M3 & Mod & \textbf{0.83} & \textbf{0.83} & 0.48 &
%     \textbf{0.40} & 0.58\\
%       & Ton & 0.83 & \textbf{0.83} & 0.49 & \textbf{0.75}
%       & 0.72\\
%     \hline B3 & Mod & 1.00 & 1.00 & 1.00 & 1.00 & 1.00\\
%       & Ton & 0.98 & 0.98 & 0.97 & 0.57 & 0.78\\
%     B4 & Mod & 0.98 & 0.98 & 0.97 & 0.57 & 0.78\\
%       & Ton & 1.00 & 1.00 & 1.00 & 1.00 & 1.00\\
%  \bottomrule \end{tabular} \end{table}

% \begin{table} \caption{MIREX weighted score}
%  \label{tab:mirex_results} \begin{tabular}{clccccc}
%  \toprule Model & Task & ASC & KP & Reg & Rim & Tch\\
%     \midrule B1 & Mod & 0.09 & 0.10 & 0.08 & 0.11 & 0.10\\
%       & Ton & 0.10 & 0.10 & 0.08 & 0.13 & 0.13\\
%     B2 & Mod & 0.69 & 0.60 & \textbf{0.58} & 0.46 & 0.37\\
%       & Ton & 0.69 & 0.59 & \textbf{0.57} & 0.64 & 0.47\\
%     \hline M1 & Mod & \textbf{0.86} & 0.83 & 0.53 & 0.49 &
%     0.61\\
%       & Ton & \textbf{0.87} & 0.83 & 0.54 & 0.77 & 0.74\\
%     M2a & Mod & 0.84 & 0.58 & 0.45 & 0.51 &
%     \textbf{0.75}\\
%         & Ton & 0.84 & 0.58 & 0.45 & 0.58 &
%         \textbf{0.81}\\
%     M2b & Mod & 0.63 & 0.47 & 0.18 & \textbf{0.55} &
%     0.49\\
%         & Ton & 0.63 & 0.46 & 0.18 & 0.43 & 0.41\\
%     M3 & Mod & \textbf{0.86} & \textbf{0.88} & 0.55 & 0.53
%     & 0.67\\
%       & Ton & 0.86 & \textbf{0.88} & 0.56 & \textbf{ing} &
%       0.80\\
%     \hline B3 & Mod & 1.00 & 1.00 & 1.00 & 1.00 & 1.00\\
%       & Ton & 0.99 & 0.98 & 0.98 & 0.65 & 0.81\\
%     B4 & Mod & 0.99 & 0.98 & 0.98 & 0.65 & 0.81\\
%       & Ton & 1.00 & 1.00 & 1.00 & 1.00 & 1.00\\
%  \bottomrule \end{tabular} \end{table}

The proximity measure model \emph{M2a} gets a lower average
score than \emph{M1} and \emph{M3}, except in the \emph{Tch}
textbook. It also performs better on the tonicization task
than on the modulation one. The variant of this model,
\emph{M2b}, gets, on average, the worst results of all the
models (excluding \emph{B1}). It also seems to be the only
model doing better in predicting modulations than
tonicizations.
%A possible explanation for the relatively low scores
% obtained by this model (\emph{M2b}) could be that it was
% trained on complete musical pieces by Mozart, where
% modulations are prepared for several measures that are
% different from the short excerpts of this dataset. The
% reason might be its training over complete musical pieces,
% where modulations spans over several measures, favoring
% the key stability over modulation.
The reason for this could be that the model was trained with
complete musical pieces; the modulations in those pieces
span several measures and, therefore, differ notably from
the short excerpts used in this dataset.

\emph{M3} results are slightly better than those obtained by
\emph{M1}. It is also interesting that these two models
(\emph{M1} and \emph{M3}) show a similar performance
``shape'' across all of the dataset (see Figure
\ref{fig:plot}), despite their disparities in design and
methodology. For example, both do poorly predicting the
modulation ground truth of \emph{Rim}, and better in
predicting the tonicization ground truth. This is
contrasting to the performance of, for example, \emph{M2b},
which did better for modulation than it did for tonicization
in \emph{Rim}, and shows a different performance ``shape''
to these models (\emph{M1} and \emph{M3}).

Lastly, even within this collection of ``cherry-picked''
examples of modulation, the diversity in the annotations by
different theorists is perceivable. Some, such as \emph{Rim}
and \emph{Tch} make heavier use of tonicizations in their
annotations, while \emph{ASC}, \emph{KP}, and \emph{Reg} do
not. This might be related to the issues of ambiguity and
disagreement mentioned in Section \ref{sec:ambiguity}. Our
evaluation methodology is not doing a great deal in
compensating for these issues. Future revisions of the
methods for evaluating local-key-estimation algorithms and
more data could certainly be of help toward addressing these
problems.

\guide{Conclusion}~\label{sec:discussion}

In this paper, we discussed the need to further investigate
the notion of a \emph{local key}, common in computational
musicology and music information retrieval, and its
relationship to the music-theoretical concepts of
\emph{modulation} and \emph{tonicization}. We provided a
small dataset of modulations and tonicizations that we
collected from five music theory textbooks. With this
dataset and a proposed methodology, we evaluated four
baseline models and three local-key-estimation algorithms
from the literature. We consider that this methodology could
be applied to other algorithms in the symbolic and audio
domain, and may contribute to overcome some of the semantic
gaps between the terminology of MIR research and music
theory. The dataset introduced in Section \ref{sec:dataset}
has been made publicly available under a Creative Commons
Attribution 4.0 International License at the following
location:
~\url{https://github.com/DDMAL/key_modulation_dataset}.
