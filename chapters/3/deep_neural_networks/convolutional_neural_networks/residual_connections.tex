% Copyright 2022 Néstor Nápoles López

As researchers scaled the depth of \gls{cnn} models, they
noticed that it was increasingly difficult to train the
larger models effectively. One strategy that helped to
mitigate this problem was the use of \emph{residual}
connections. A residual connection consists of a connection
between a given layer of the network and a latter one,
``skipping'' some of the intermediate layers in between the
two. This pattern of connections has allowed researchers to
design much deeper networks more effectively.