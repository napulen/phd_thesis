% Copyright 2022 Néstor Nápoles López

% This is \refsubsubsec{romannumeralanalysismodels}, which
% introduces the roman numeral analysis models.

\phdparagraph{pioneering works}

The pioneering work in \glspl{rna} is the one by
\textcite{winograd1968linguistics}. This model was evaluated
over music by Bach. It required a preliminary, hand-made,
representation of the score as a sequence of four-part
perfect chords. This representation was processed by a model
implemented in the \gls{lisp} programming language. The
hand-made representation required \emph{nonchord} tones to
be removed before processing the input with the model, a
crucial limitation, because this process was complex and
could not be automated. In addition to this limitation,
\textcite{temperley1997algorithm} provided insight about
other limitations in Winograd's model, for example, its
incapacity to deal with arpeggios and contrapuntal textures.

After Winograd, an \emph{expert system} model was introduced
by Maxwell, first in his PhD dissertation
\parencite{maxwell1984artificial}, and subsequently in a
book chapter \parencite{maxwell1992expert}. This model is
one of the best examples of rule-based systems for
\glspl{mir}. The model consisted of fifty five rules that
reduced vertical sonorities into chord sequences, and
decided the location of changes of key. Initially, the rules
of the system were short and concise:

\begin{italicquotes}
    Perfect and imperfect consonant intervals constitute a
    consonant interval. Every other is a dissonant interval.
\end{italicquotes}

However, as new rules were introduced, they became
increasingly more complex and cryptic:

\begin{italicquotes}
    If the goal chord falls on a strong beat and it is a
    major triad or major-minor seventh, and the root
    movement from the pre-cadence is an ascending or
    descending perfect fifth or major second or a descending
    minor second, and when the root motion is a descending
    fifth, the pre-cadence is not a potential dominant, and
    when the root motion is an ascending fifth the
    pre-cadence is triadic, then the pseudo-cadence is a
    half cadence, and its strength increases by 10.
\end{italicquotes}

The system was also criticized for its use of arbitrary,
\emph{hardcoded} values to determine the strength of a
cadence. An example shown in the last sentence of the
previous rule.

Regardless of the complex rules, Maxwell's model provided
convincing music-theoretical outputs when analyzing three
movements of the Bach Six French Suites: the sarabande from
Suite No.~1, the minuet from Suite No.~2 and the gavotte
from Suite No.~5. The pieces featured distinct types of
complexities: four-part harmony with several nonchord tones,
2-voice contrapuntual textures, and a varying contrapuntual
texture, respectively. Unfortunately, because these are only
three musical examples by the same composer, it is unlikely
that the system would generalize to other compositions.
\textcite{temperley1997algorithm} listed the limitations of
Winograd and Maxwell's approaches, summarizing them in the
following:

\begin{itemize}
    \item Sequences of notes that are not displayed
    simultaneously (vertically), as arpeggiations of chords.
    \item Missing pitches in the spelling of a full chord
    which can be deduced from the context.
    \item Ornamental notes. Maxwell proposes specific rules
    to deal with these notes, but according to Temperley,
    neither Maxwell's or Winograd's are good enough to
    correctly detect ornamental notes.
\end{itemize}

\phdparagraph{the melisma music analyzer}

The first end-to-end \glspl{rna} system can be attributed to
the contributions of Temperley, Sleator, and Sapp. First,
\textcite{temperley1997algorithm} proposed an algorithm to
find harmonic roots, which was complemented with preference
rules for meter analysis \parencite{temperley1999modeling}
and a key estimation model \parencite{temperley1999whats}.
The collective algorithms were published by
\textcite{temperley2004cognition} and implemented in
collaboration with Sleator as a suite of programs called the
\emph{Melisma Music Analyzer (version
1)}.\footnotelink{https://www.link.cs.cmu.edu/music-analysis/}\footnote{Although
Melisma (version 2) exists, it does not provide \gls{rna}
output.} The system operated with intermediate
representations for both inputs and outputs. Sapp filled in
the remaining gap with additional stages that allowed
\emph{Melisma} to digest Humdrum(\texttt{**kern}) inputs and
generate Humdrum(\texttt{**harm}) \gls{rna} annotations,
aligning them with the original score. The full end-to-end
workflow was facilitated by a program called \emph{tsroot}
\parencite{sapp2009tsroot} and used to generate fully
automatic \gls{rna} labels of the music scores in
the \emph{KernScores} database \parencite{sapp2005online}.

% Temperley steps forward in the definition of the problem
% of harmonic analysis, decomposing the task into two
% subtasks: \emph{root finding} and \emph{key finding}.
% Temperley claims then that functional harmonic analysis
% could be broken down into these subtasks, focusing at
% first in root finding, assuming that this task can be done
% independently to key finding. Root finding basically
% consists of dividing a piece into segments and label each
% of them with a root.

% Once in the task of root-finding, Temperley approaches the
% task defining certain rules: \emph{Pitch variance rule,
% compatibility rule, strong-beat rule, harmonic variance
% rule and ornamental dissonance rule}. Together with these
% rules, he introduces important definitions that aid in the
% process of root analysis: The concepts of \emph{Tonal
% Pitch Class} (TPC), \emph{Center of Gravity} (COG) and the
% \emph{line of fifths}.

% It is difficult to follow the chronology of this approach,
% as the implementation of this model comes mainly in the
% form of the Melisma Music Analyzer, which was released in
% 2001, and included the key estimation algorithm and a
% combined mode that eventually performed the complete
% functional harmonic analysis. The latest mode being the
% core implementation of what will be used to compute
% automatic harmonic analysis during this work.

\phdparagraph{probabilistic and grammar-based models}

After the implementation of the first Melisma Music
Analyzer, which is based on preference rules, Temperley
favored probabilistic models in subsequent works. A Bayesian
approach aimed to provide a unified modeling of harmonic
analysis, meter induction and melodic seggregation,
challenging the individualization of these problems without
considering the connections among them
\cite{temperley2009unified}.

% Another important probabilistic approach that emerged to
% solve the problem of functional harmonic analysis was that
% of Christopher Raphael \cite{raphael2003harmonic}. This
% model from Raphael is one of the few pure-functional
% harmonic analysis approaches, oriented towards the
% analysis of common-practice music. The idea is simple and
% some of his assumptions simplify the parameters of the
% model. Some constant that remains as in previous models is
% the fact that it gets rid of all the pitch-spelling
% information and replaced for solely pitch information.
% This model, unlike Temperley, does not try to reconstruct
% the pitch spelling information back by any algorithmic
% means, and in the words of Raphael, it is an obvious
% extension to the model.

% Another quite important effort in the statistical domain
% includes the work from Martin Rohrmeier
% \cite{rohrmeier2008statistical}, who uses a heuristic
% method of segmentation. Analyzes distributions of single
% pitch-class-sets, chord classes and pitch-class-sets
% transitions. One of the goals of Rohrmeier was the
% research of \emph{syntacticality} in harmony. The final
% goal is to produce descriptive analyses of harmonic
% structure based on an empirical approach. The choice of
% the corpus is, similarly to others, music from Joahann
% Sebastian Bach. In his case, chorales, because they
% constitute a large and coherent set of pieces regarding
% style and composition technique. Rohrmeier claims that
% this work is pioneer in the statistical analysis of a
% corpus for the purpose of finding features of tonal
% harmony. According to the results of Rohrmeier, the most
% frequent occurrences of pitch-class-sets in this music are
% those of tonic, dominant and subdominant chords. This
% would be expected and helps to reinforce those
% scale-degree theories that describe harmonic movement with
% transition tables of scale degrees. The results from this
% research, apart from being interesting in confirming
% music-theory beliefs regarding common chords and
% transitions in tonal music, could also be replicated in a
% different corpus to target its particular common chords
% and transitions.

% \subsection{Grammar-based} Three years after his
% statistical work in Bach Chorales, Martin Rohrmeier
% brought back the use of grammars to study the underlying
% structure of musical harmony \cite{rohrmeier2011towards},
% which inspired future works by other researchers in the
% field, specially towards analyzing jazz music. In this
% work, Rohrmeier claims that the structure of harmonic
% progressions exceeds the simplicity of a markovian
% transition table, and he proposes a set of
% phrase-structure grammar rules. For this purpose, the
% hierarchical analysis from the music-theory approach done
% by \cite{kostka1995tonal} is presented, with the belief
% that it can be brought to a closer formalization.
% Rohrmeier presents a tree representation of a chord
% sequence, using two principles: \begin{itemize} \item
% Chords have dependencies and the existence of one
% sometimes requires the existence of another \item Chords
% have functions, these functions can be realized by a set
% of chords. \end{itemize} The system comprises 27 rules for
% the generation of a grammar, this helps to model
% common-practice music as well as jazz music. The output of
% this algorithm is a hierarchical tree of the functions and
% dependencies of the chords. The level of detail from this
% work to model every special case of the harmonic language
% is remarkable, as careful attention has been put trying to
% comprehend distinct kinds of cadences, chords and
% modulations in the model.

% This work was eventually retaken and implemented by Bas de
% Haas \cite{de2013automatic} using chord labels as input
% for the system.

% As discussed previously, after I have overviewed the works
% in harmonic analysis, I will now narrow down the list of
% attempts that are most relevant to the expectations of
% this work. Among the most important factors that lead to
% separate the \emph{favorite} attempts from the rest, I
% could list two: The first one, being the capability of the
% system to deal with full scores as input, instead of a
% list of chord labels. The second, being the capability of
% the system to exploit, infer or reconstruct the
% pitch-spelling information from the original score in the
% output of the analyzed score.

% \section{Narrowing down the approaches} From the
% previously mentioned efforts of harmonic analysis, those
% that fit the best with the expected inputs and outputs of
% this work, are the following: \begin{table}[tbp]
% \centering \begin{tabular}{llll} Approach & Year &
% Implementation & Availability \\
%     Winograd & 1968 & LISP & No \\
%     Maxwell & 1992 & LISP & No \\
%     Temperley & 1997\footnote{The span of time between
%     this approach was presented as a paper and the current
%     implentation used for this work, is much wider,
%     reaching changes in code done during 2017} & C & Yes
%     \\
%     Raphael & 2003 & C & Partial \\
%     Illescas & 2008 & Java & Partial \end{tabular}
% \caption{Automatic functional harmonic analysis
% approaches} \label{table:shortlist_models} \end{table}

% From the approaches shown in
% \autoref{table:shortlist_models}, I decided to choose the
% model and implementation from David Temperley's algorithm
% to be run over the dataset of String Quartets Op.20.

% The most important reason for this selection is because
% this is the approach with the most mature implementation,
% and the effort for getting humdrum scores to be analyzed
% using it is the minimum of all the other attemtps.

% taken verbatim from my MSc thesis, chapter 4

% As I described during \autoref{chap:literature-review},
% the original model from David Temperley divided a system
% of automatic harmonic analysis in two subsystems: One that
% performs root detection and another one that performs key
% detection. \autoref{fig:software_stack1} shows how the
% core harmonic analysis of David Temperley comprises these
% two tasks.

% \begin{figure}[ht] \centering
%   \includegraphics[width=0.5\textwidth]{04-methodology/figures/1}
%   \caption{Harmonic analysis as divided by David
%   Temperley} \label{fig:software_stack1} \end{figure}

% However, thanks to the implementation work that has been
% already done by David Temperley, Daniel Sleator and Craig
% Sapp, the idea of using an implementation of this
% automatic harmonic analysis system over the dataset
% described in this work, which consists of musical scores
% encoded in humdrum files, is already feasible. During this
% chapter I will introduce the software stack, programs and
% scripts that allow for running an automatic harmonic
% analysis of a humdrum music score.

% I will start from the analysis programs of the Melisma
% Music Analyzer, which are the core of the analysis, to the
% scripts and programs of the Humdrum Extras software tools
% that allow for the use of real humdrum music scores.

% \section{The Melisma Music Analyzer} The Melisma Music
%   Analyzer was implemented by Daniel Sleator over the work
%   of David Temperley. It takes as input a \emph{Notefile},
%   which could be said to be a plain-text representation of
%   midi files. The Melisma Music Analyzer consists of
%   several standalone programs, therefore, the output
%   depends on the program that is being run over the
%   \emph{Notefile} input file. However, generally speaking,
%   they all output a plain-text analysis of some sort.

%   In order to obtain a harmonic analysis, a Notefile needs
%   to go through 3 stand-alone programs, one after another:
%   Meter, Harmony and Key.

%   \begin{figure}[ht] \centering
%     \includegraphics[width=1.0\textwidth]{04-methodology/figures/2}
%     \caption{Melisma Music Analyzer, from a Notefile to a
%     plain-text analysis} \label{fig:software_stack2}
%     \end{figure}

%   \subsection{Meter} This program extracts metrical
%     information about the musical piece, using the
%     theories of the Generative Theory of Tonal Music as a
%     basis. The output of this program is the same notefile
%     with beat information appended at the end.
%     \subsection{Harmony} This program takes as input the
%     notefile with beat information (the output from the
%     meter program), and outputs information about harmonic
%     roots for each beat. The name is somehow misleading,
%     as this program's output is not harmony, but a
%     harmonic root. Temperley divided the task of harmonic
%     analysis in root estimation and key estimation, this
%     program computing the first of these subtasks.
%     \subsection{Key} This program takes as input the
%     notefile with beat and harmonic-root information (the
%     ouput from the harmony program). Something to remark
%     about this program is that it might work with or
%     without the information of the harmony program. In the
%     first case, it performs a complete harmonic analysis.
%     In the second case, it will only perform a key
%     estimation.

%     \autoref{fig:software_stack2} shows the flow from an
%     input Notefile to the plain-text analysis that is
%     being output by the key estimation program of the
%     Melisma Music Analyzer.

%   \subsection{Problems with processing Notefile files} The
%     input format from the Melisma Music Analyzer, yet it
%     resembles a midi file, it is not a midi file. It is
%     also not a standard type of file that could be
%     encountered typically in other software. More
%     important, it is incompatible with the humdrum
%     encoding of the dataset used for this work, so at this
%     point, we are unable to run an analysis over these
%     musical scores.

%     However, there is one way around this problem. Using
%     one of the programs found in the \emph{Humdrum extras}
%     collection.

% \section{Humdrum extras} The humdrum extras are a set of
%   tools developed by Craig Sapp, mainly in the C++
%   programming language \cite{humextra}. These tools are
%   useful for additional processing of musical scores
%   encoded in humdrum. For this work, I am particularly
%   interested in a few of these utilities that help to pass
%   a humdrum file to the melisma music analyzer, and then
%   bring the output from melisma back to a humdrum
%   representation.

%   \begin{figure}[ht] \centering
%     \includegraphics[width=1.0\textwidth]{04-methodology/figures/3}
%     \caption{Automatic harmonic analysis of a humdrum
%     musical score} \label{fig:software_stack3}
%     \end{figure}

%   The first step is mitigating the problem around the
%   Notefile format, for this, the \emph{kern2melisma}
%   program from the Humdrum Extras collection results quite
%   useful.

%   \subsection{kern2melisma} This program provides a parser
%     to convert a humdrum file into the \emph{Notefile}
%     format used by Melisma. It is the first step in the
%     workflow of a functional harmonic analysis from a
%     humdrum score.

%   Once the input file is able to be processed over the
%   programs of the Melisma Music Analyzer, it will be
%   possible to obtain the plain-text analysis of the
%   \emph{Key} program. However, this analysis is difficult
%   to parse as it is. Luckily, there is already a tool from
%   the Humdrum Extras that provides help parsing this
%   analysis, this tool is the \emph{key2humdrum} script,
%   written in PERL.

%   \subsection{key2humdrum} This program takes the output
%     from the \emph{Key} program and outputs a
%     pseudo-humdrum representation.

%   \subsection{Appending to a humdrum file} The last step
%     in getting the information back into a humdrum file is
%     parsing the output of the key2humdrum program and
%     appending this information to a humdrum spine. This
%     process is not done by a standalone program, but
%     rather a program that comprehends all the process
%     described during this chapter. This program is called
%     \emph{tsroot}.

%   \subsection{tsroot} The tsroot programs performs all the
%     steps described before, starting from calling the
%     \emph{kern2melisma} to calling the Melisma programs
%     and \emph{key2humdrum}. Additionally, this program
%     also interprets the output of key2humdrum and produces
%     a final humdrum score with the analysis information
%     appended to it.


Notable subsequent studies include
\textcite{raphael2004functional},
\textcite{illescas2007harmonic}, and
\textcite{magalhaes2011functional}, who proposed
\glspl{hmm}, dynamic programming, and grammar-based
approaches, respectively.

\phdparagraph{deep learning models}

More recently, deep neural networks have become the
preferred tool for approaching this problem.
\textcite{chen2018functional} were the first to introduce
`multi-task learning' (MTL) \parencite{ruder2017overview} to
the problem as a suitable way for the neural network to
share representations between related tonal tasks. Chen and
Su's model consists of a bidirectional \gls{lstm}
\parencite{hochreiter1997long} followed by task-specific
dense layers, which implement the MTL aspect. In this work,
the authors also introduced the `Beethoven Piano Sonata
Functional Harmony' dataset for evaluating such models. The
MTL layout outperformed single-task configurations and it
has continued to prove the best-performing approach in
subsequent deep learning studies. In subsequent work, the
same authors have adopted Transformer-based networks to deal
with functional harmony and \gls{acr}
\parencite{chen2019harmony, chen2021attend}. The work with
these networks has explored the capability of the attention
mechanisms to improve the performance of \gls{acr}, paying
special consideration to chord segmentation and its
evaluation.

\textcite{micchi2020not}, in turn, proposed a DenseNet-like
\parencite{huang2017densely} convolutional neural network,
followed by a recurrent component. The recurrent component
consists of a bidirectional \gls{gru}
\parencite{cho2014learning} connected to task-specific dense
layers, similar to those of \textcite{chen2018functional}.
In their experiments, the DenseNet-like convolutions
outperformed dilated convolutions and a \gls{gru} by itself
(i.e., with pooling instead of the convolutional blocks).
Micchi et al.~also demonstrated the positive effect of using
pitch \textit{spelling} in the inputs and outputs. This
confers at least two advantages: it provides a more
informative output (e.g., not only the correct key, but the
correct spelling between two enharmonic keys), and it
increases the possible number of transpositions available
for data augmentation.

Recent models include those of \textcite{micchi2021deep},
\textcite{mcleod2021modular}, and
\textcite{napoleslopez2021augmentednet}.
