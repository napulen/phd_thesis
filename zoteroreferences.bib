
@book{shield_introduction_1800,
	title = {An {Introduction} to {Harmony}},
	isbn = {978-1-385-16111-1},
	language = {English},
	author = {Shield, William},
	year = {1800},
	note = {OCLC: 1037074321},
	keywords = {Thesis}
}

@book{callcott_musical_1810,
	address = {Boston},
	title = {A musical grammar, in four parts. {I}. {Notation}, {II}. {Melody}, {III}. {Harmony}, {IV}. {Rhythm}.},
	url = {//catalog.hathitrust.org/Record/012193294},
	number = {iv, [iii]-iv p., 1 .̋, [ix]-xii, 332 p.},
	publisher = {Published by West \& Blake, and Manning \& Loring. Manning and Loring, printers},
	author = {Callcott, John Wall},
	year = {1810},
	keywords = {Thesis}
}

@book{logan_musicology_nodate,
	title = {Musicology: {A} {Text}-{Book} for {Schools} and for {General} {Use} ({Classic} {Reprint})},
	language = {English},
	publisher = {Forgotten Books},
	author = {Logan, Maurice S.},
	keywords = {Thesis}
}

@inproceedings{feisthauer_estimating_2020,
	title = {Estimating keys and modulations in musical pieces},
	author = {Feisthauer, Laurent and Bigo, Louis and Giraud, Mathieu and Leve, Florence},
	year = {2020},
	keywords = {Thesis}
}

@book{christiansen_practical_0000,
	address = {Minneapolis, Minn.},
	title = {Practical modulation},
	url = {//catalog.hathitrust.org/Record/007551313},
	number = {43 p.},
	publisher = {Augsburg Publishing House},
	author = {Christiansen, F. Melius},
	year = {0000},
	keywords = {Thesis}
}

@book{shepard_how_1890,
	address = {Orange, N.J.},
	title = {How to modulate: a simple and systematic guide in modulating from any key to any other: and a review of the principles of artistic modulation as applied in general composition},
	url = {//catalog.hathitrust.org/Record/008695332},
	number = {vi, 66 p.},
	publisher = {Shepard},
	author = {Shepard, F. H.},
	year = {1890},
	keywords = {Thesis}
}

@book{foote_modulation_2016,
	address = {Place of publication not identified},
	title = {Modulation and related harmonic questions (classic reprint).},
	isbn = {978-1-330-57951-0},
	language = {English},
	publisher = {FORGOTTEN Books},
	author = {Foote, Arthur},
	year = {2016},
	note = {OCLC: 982565113},
	keywords = {Thesis}
}

@book{wedge_keyboard_1924,
	title = {Keyboard {Harmony}: {A} {Practical} {Application} of {Music} {Theory}, {Including} the {Study} of {Melody} {Harmonization}, {Broken} {Chords} and {Arpeggios}, {Modulation} and {Improvisation}},
	url = {https://books.google.ca/books?id=Ftr6wfNx1rQC},
	publisher = {G. Schirmer, Incorporated},
	author = {Wedge, G.A.},
	year = {1924},
	lccn = {24029404},
	keywords = {Thesis}
}

@book{otterstrom_theory_1935,
	address = {Chicago, Illinois},
	title = {A theory of modulation {\textbar} {Eine} modulationstheorie},
	publisher = {The University of Chicago Press},
	author = {Otterström, Thorvald},
	year = {1935},
	keywords = {Thesis}
}

@book{schachter_art_2016,
	address = {New York},
	title = {The art of tonal analysis: twelve lessons in {Schenkerian} theory},
	isbn = {978-0-19-022739-5 978-0-19-090917-8},
	shorttitle = {The art of tonal analysis},
	publisher = {Oxford University Press},
	author = {Schachter, Carl and Straus, Joseph Nathan},
	year = {2016},
	keywords = {Thesis}
}

@book{schachter_unfoldings_1999,
	title = {Unfoldings : {Essays} in {Schenkerian} {Theory} and {Analysis}.},
	isbn = {978-0-19-512013-4},
	url = {https://proxy.library.mcgill.ca/login?url=http://search.ebscohost.com/login.aspx?direct=true&db=nlebk&AN=143996&scope=site},
	abstract = {Carl Schachter is, by common consent, one of the three or four most important music theorists currently at work in North America. He is the preeminent practitioner in the world of the Schenkerian approach to the music of the eighteenth and nineteenth centuries, which focuses on the linear organization of music and now dominates discussions of the standard repertoire in university courses and in professional journals. His articles have appeared in a variety of journals, including some that are obscure or hard to obtain. This volume gathers some of his finest essays, including those on rhythm in tonal music, Schenkerian theory, and text setting, as well as a pair of analytical monographs, on Bach's Fugue in B-flat major from Volume 1 of the Well-Tempered Clavier and Chopin's Fantasy, Op. 49.},
	publisher = {Oxford University Press},
	author = {Schachter, Carl and Straus, Joseph Nathan},
	year = {1999},
	keywords = {Thesis}
}

@inproceedings{huang_music_2019,
	title = {Music {Transformer}},
	url = {https://openreview.net/forum?id=rJe4ShAcF7},
	booktitle = {International {Conference} on {Learning} {Representations}},
	author = {Huang, Cheng-Zhi Anna and Vaswani, Ashish and Uszkoreit, Jakob and Simon, Ian and Hawthorne, Curtis and Shazeer, Noam and Dai, Andrew M. and Hoffman, Matthew D. and Dinculescu, Monica and Eck, Douglas},
	year = {2019},
	keywords = {Internship@Avid}
}

@inproceedings{bigo_relevance_2018,
	address = {Paris, France},
	title = {Relevance of {Musical} {Features} for {Cadence} {Detection}},
	url = {https://doi.org/10.5281/zenodo.1492423},
	doi = {10.5281/zenodo.1492423},
	booktitle = {Proceedings of the 19th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Bigo, Louis and Feisthauer, Laurent and Giraud, Mathieu and Levé, Florence},
	month = sep,
	year = {2018},
	keywords = {Internship@Avid},
	pages = {355--361}
}

@article{sapp_computational_2007,
	title = {Computational {Chord}-{Root} {Identification} in {Symbolic} {Musical} {Data}: {Rationale}, {Methods}, and {Applications}.},
	volume = {15},
	journal = {Computing in Musicology},
	author = {Sapp, Craig Stuart},
	year = {2007},
	keywords = {Internship@Avid}
}

@phdthesis{hadjeres_interactive_nodate,
	title = {Interactive {Deep} {Generative} {Models} for {Symbolic} {Music}},
	author = {Hadjeres, Gaëtan},
	keywords = {Internship@Avid}
}

@book{walder_modelling_2016,
	title = {Modelling {Symbolic} {Music}: {Beyond} the {Piano} {Roll}},
	author = {Walder, Christian},
	year = {2016},
	note = {\_eprint: 1606.01368},
	keywords = {Internship@Avid}
}

@book{briot_deep_2019,
	title = {Deep learning techniques for music generation},
	volume = {10},
	publisher = {Springer},
	author = {Briot, Jean-Pierre and Hadjeres, Gaëtan and Pachet, François},
	year = {2019},
	keywords = {Internship@Avid}
}

@article{schottstaedt_automatic_1984,
	title = {Automatic {Species} {Counterpoint}},
	url = {https://ccrma.stanford.edu/files/papers/stanm19.pdf},
	author = {Schottstaedt, Bill},
	month = may,
	year = {1984},
	note = {Place: Stanford, CA
Publisher: CCRMA},
	keywords = {Internship@Avid}
}

@article{schottstaedt_automatic_1984-1,
	title = {Automatic {Species} {Counterpoint}},
	url = {https://ccrma.stanford.edu/files/papers/stanm19.pdf},
	author = {Schottstaedt, Bill},
	month = may,
	year = {1984},
	note = {Place: Stanford, CA
Publisher: CCRMA},
	keywords = {Automatic Species Counterpoint, Counterpoint, Data}
}

@inproceedings{ju_interactive_2019,
	address = {Delft, The Netherlands},
	title = {An {Interactive} {Workflow} for {Generating} {Chord} {Labels} for {Homorhythmic} {Music} in {Symbolic} {Formats}},
	url = {https://doi.org/10.5281/zenodo.3527950},
	doi = {10.5281/zenodo.3527950},
	booktitle = {Proceedings of the 20th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Ju, Yaolong and Howes, Samuel and McKay, Cory and Condit-Schultz, Nathaniel and Calvo-Zaragoza, Jorge and Fujinaga, Ichiro},
	month = nov,
	year = {2019},
	keywords = {Internship@Avid},
	pages = {862--869}
}

@article{toiviainen_measuring_2003,
	title = {Measuring and modeling real-time responses to music: {The} dynamics of tonality induction},
	volume = {32},
	shorttitle = {Measuring and modeling real-time responses to music},
	doi = {10.1068/p3312},
	abstract = {We examined a variety of real-time responses evoked by a single piece of music, the organ Duetto BWV 805 by J S Bach. The primary data came from a concurrent probe-tone method in which the probe tone is sounded continuously with the music. Listeners judged how well the probe tone fit with the music at each point in time. The process was repeated for all probe tones of the chromatic scale. A self-organizing map (SOM) [Kohonen 1997 Self-organizing Maps (Berlin: Springer)] was used to represent the developing and changing sense of key reflected in these judgments. The SOM was trained on the probe-tone profiles for 24 major and minor keys (Krumhansl and Kessler 1982 Psychological Review 89 334-368). Projecting the concurrent probe-tone data onto the map showed changes both in the perceived keys and in their strengths. Two dynamic models of tonality induction were tested. Model 1 is based on pitch class distributions. Model 2 is based on the tone-transition distributions; it tested the idea that the order of tones might provide additional information about tonality. Both models contained dynamic components for characterizing pitch strength and creating pitch memory representations. Both models produced results closely matching those of the concurrent probe-tone data. Finally real-time judgments of tension were measured. Tension correlated with distance away from the predominant key in the direction of keys built on the dominant and supertonic tones, and also correlated with dissonance.},
	journal = {Perception},
	author = {Toiviainen, Petri and Krumhansl, Carol},
	month = feb,
	year = {2003},
	keywords = {Comps, Comps\_Q8},
	pages = {741--66}
}

@inproceedings{allan_harmonising_2004,
	address = {Vancouver, British Columbia, Canada},
	series = {{NIPS}'04},
	title = {Harmonising chorales by probabilistic inference},
	abstract = {We describe how we used a data set of chorale harmonisations composed by Johann Sebastian Bach to train Hidden Markov Models. Using a probabilistic framework allows us to create a harmonisation system which learns from examples, and which can compose new harmonisations. We make a quantitative comparison of our system's harmonisation performance against simpler models, and provide example harmonisations.},
	urldate = {2020-04-02},
	booktitle = {Proceedings of the 17th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {Allan, Moray and Williams, Christopher K. I.},
	month = dec,
	year = {2004},
	keywords = {Internship@Avid},
	pages = {25--32}
}

@phdthesis{liang_bachbot_nodate,
	title = {{BachBot}: {Automatic} composition in the style of {Bach} chorales},
	language = {en},
	author = {Liang, Feynman},
	keywords = {Internship@Avid}
}

@inproceedings{oord_wavenet_2016,
	title = {{WaveNet}: {A} {Generative} {Model} for {Raw} {Audio}},
	url = {https://arxiv.org/abs/1609.03499},
	booktitle = {Arxiv},
	author = {Oord, Aäron van den and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alexander and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
	year = {2016},
	keywords = {Internship@Avid}
}

@inproceedings{liang_automatic_2017,
	title = {Automatic {Stylistic} {Composition} of {Bach} {Chorales} with {Deep} {LSTM}},
	url = {https://www.microsoft.com/en-us/research/publication/automatic-stylistic-composition-of-bach-chorales-with-deep-lstm/},
	abstract = {This work was done as part of the Cambridge lab's involvement in Cambridge University's MPhil in Machine Learning, Speech, and Language Technology program, and was carried out by two students (under our supervision) named Feynman Liang and Martin Tomczak. In this research project we set out to build an AI system based upon LSTMs that was able to compose music like Johann Sebastian Bach. This presented some challenges: How do you represent music for use in AI? How is music composed, and can an AI reproduce that process? How do you determine if a piece of generated music is "in the style" of a composer, i.e. Bach? Addressing each of these was an interesting challenge that required expertise both from inside the lab and without. One of the key collaborators, Mark Gotham, is a computational musicologist. He helped us answer questions (1) and (2) by introducing us to notations that were amenable to machine learning, and by walking us through how students in musical composition learn to compose music in the style of certain composers. In particular, he introduced us to the task of "completing music", where one or more parts are provided and the student has to complete the other parts for the music. In this context, we applied our AI know-how to train a deep LSTM model to compose and complete musical compositions. Really intriguingly, analysis of the trained model provided evidence of neurons specializing without prior knowledge or explicit supervision to detect common music-theoretic concepts such as tonics, chords, and cadences. This left us with the problem of how to evaluate it, and for this we created a website, http://bachbot.com (try it out yourself!) and used it to conduct one of the largest musical discrimination tests ever performed involving 2,336 participants. Among the results, the proportion of responses correctly differentiating BachBot from Bach was only 1\% better than random guessing.},
	booktitle = {18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	author = {Liang, Feynman and Gotham, Mark and Johnson, Matthew and Shotton, Jamie},
	month = oct,
	year = {2017},
	note = {Edition: 18th International Society for Music Information Retrieval Conference},
	keywords = {Internship@Avid}
}

@article{lattner_imposing_2018,
	title = {Imposing higher-level {Structure} in {Polyphonic} {Music} {Generation} using {Convolutional} {Restricted} {Boltzmann} {Machines} and {Constraints}},
	volume = {2},
	issn = {2399-7656},
	url = {http://arxiv.org/abs/1612.04742},
	doi = {10.5920/jcms.2018.01},
	abstract = {We introduce a method for imposing higher-level structure on generated, polyphonic music. A Convolutional Restricted Boltzmann Machine (C-RBM) as a generative model is combined with gradient descent constraint optimisation to provide further control over the generation process. Among other things, this allows for the use of a "template" piece, from which some structural properties can be extracted, and transferred as constraints to the newly generated material. The sampling process is guided with Simulated Annealing to avoid local optima, and to find solutions that both satisfy the constraints, and are relatively stable with respect to the C-RBM. Results show that with this approach it is possible to control the higher-level self-similarity structure, the meter, and the tonal properties of the resulting musical piece, while preserving its local musical coherence.},
	number = {2},
	urldate = {2020-04-02},
	journal = {Journal of Creative Music Systems},
	author = {Lattner, Stefan and Grachten, Maarten and Widmer, Gerhard},
	month = mar,
	year = {2018},
	note = {arXiv: 1612.04742},
	keywords = {Internship@Avid}
}

@article{hadjeres_style_2016,
	title = {Style {Imitation} and {Chord} {Invention} in {Polyphonic} {Music} with {Exponential} {Families}},
	url = {http://arxiv.org/abs/1609.05152},
	abstract = {Modeling polyphonic music is a particularly challenging task because of the intricate interplay between melody and harmony. A good model should satisfy three requirements: statistical accuracy (capturing faithfully the statistics of correlations at various ranges, horizontally and vertically), flexibility (coping with arbitrary user constraints), and generalization capacity (inventing new material, while staying in the style of the training corpus). Models proposed so far fail on at least one of these requirements. We propose a statistical model of polyphonic music, based on the maximum entropy principle. This model is able to learn and reproduce pairwise statistics between neighboring note events in a given corpus. The model is also able to invent new chords and to harmonize unknown melodies. We evaluate the invention capacity of the model by assessing the amount of cited, re-discovered, and invented chords on a corpus of Bach chorales. We discuss how the model enables the user to specify and enforce user-defined constraints, which makes it useful for style-based, interactive music generation.},
	urldate = {2020-04-02},
	journal = {arXiv:1609.05152 [cs]},
	author = {Hadjeres, Gaëtan and Sakellariou, Jason and Pachet, François},
	month = sep,
	year = {2016},
	note = {arXiv: 1609.05152},
	keywords = {Internship@Avid}
}

@inproceedings{hadjeres_deepbach_2017,
	address = {Sydney, NSW, Australia},
	series = {{ICML}'17},
	title = {{DeepBach}: a steerable model for bach chorales generation},
	shorttitle = {{DeepBach}},
	abstract = {This paper introduces DeepBach, a graphical model aimed at modeling polyphonic music and specifically hymn-like pieces. We claim that, after being trained on the chorale harmonizations by Johann Sebastian Bach, our model is capable of generating highly convincing chorales in the style of Bach. DeepBach's strength comes from the use of pseudo-Gibbs sampling coupled with an adapted representation of musical data. This is in contrast with many automatic music composition approaches which tend to compose music sequentially. Our model is also steerable in the sense that a user can constrain the generation by imposing positional constraints such as notes, rhythms or cadences in the generated score. We also provide a plugin on top of the MuseScore music editor making the interaction with Deep-Bach easy to use.},
	urldate = {2020-04-02},
	booktitle = {Proceedings of the 34th {International} {Conference} on {Machine} {Learning} - {Volume} 70},
	publisher = {JMLR.org},
	author = {Hadjeres, Gaëtan and Pachet, François and Nielsen, Frank},
	month = aug,
	year = {2017},
	keywords = {Internship@Avid},
	pages = {1362--1371}
}

@article{fernandez_ai_2013,
	title = {{AI} {Methods} in {Algorithmic} {Composition}: {A} {Comprehensive} {Survey}},
	volume = {48},
	issn = {1076-9757},
	number = {1},
	journal = {J. Artif. Int. Res.},
	author = {Fernández, Jose David and Vico, Francisco},
	month = oct,
	year = {2013},
	note = {Place: El Segundo, CA, USA
Publisher: AI Access Foundation},
	keywords = {Internship@Avid},
	pages = {513--582}
}

@article{boulanger-lewandowski_modeling_2012,
	title = {Modeling {Temporal} {Dependencies} in {High}-{Dimensional} {Sequences}: {Application} to {Polyphonic} {Music} {Generation} and {Transcription}},
	shorttitle = {Modeling {Temporal} {Dependencies} in {High}-{Dimensional} {Sequences}},
	url = {http://arxiv.org/abs/1206.6392},
	abstract = {We investigate the problem of modeling symbolic sequences of polyphonic music in a completely general piano-roll representation. We introduce a probabilistic model based on distribution estimators conditioned on a recurrent neural network that is able to discover temporal dependencies in high-dimensional sequences. Our approach outperforms many traditional models of polyphonic music on a variety of realistic datasets. We show how our musical language model can serve as a symbolic prior to improve the accuracy of polyphonic transcription.},
	urldate = {2020-04-02},
	journal = {arXiv:1206.6392 [cs, stat]},
	author = {Boulanger-Lewandowski, Nicolas and Bengio, Yoshua and Vincent, Pascal},
	month = jun,
	year = {2012},
	note = {arXiv: 1206.6392},
	keywords = {Internship@Avid}
}

@inproceedings{huang_counterpoint_2017,
	address = {Suzhou, China},
	title = {Counterpoint by {Convolution}.},
	url = {https://doi.org/10.5281/zenodo.1416370},
	doi = {10.5281/zenodo.1416370},
	booktitle = {Proceedings of the 18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Huang, Cheng-Zhi Anna and Cooijmans, Tim and Roberts, Adam and Courville, Aaron C. and Eck, Douglas},
	month = oct,
	year = {2017},
	keywords = {Internship@Avid},
	pages = {211--218}
}

@article{huang_counterpoint_2019,
	title = {Counterpoint by {Convolution}},
	url = {http://arxiv.org/abs/1903.07227},
	abstract = {Machine learning models of music typically break up the task of composition into a chronological process, composing a piece of music in a single pass from beginning to end. On the contrary, human composers write music in a nonlinear fashion, scribbling motifs here and there, often revisiting choices previously made. In order to better approximate this process, we train a convolutional neural network to complete partial musical scores, and explore the use of blocked Gibbs sampling as an analogue to rewriting. Neither the model nor the generative procedure are tied to a particular causal direction of composition. Our model is an instance of orderless NADE (Uria et al., 2014), which allows more direct ancestral sampling. However, we find that Gibbs sampling greatly improves sample quality, which we demonstrate to be due to some conditional distributions being poorly modeled. Moreover, we show that even the cheap approximate blocked Gibbs procedure from Yao et al. (2014) yields better samples than ancestral sampling, based on both log-likelihood and human evaluation.},
	urldate = {2020-03-29},
	journal = {arXiv:1903.07227 [cs, eess, stat]},
	author = {Huang, Cheng-Zhi Anna and Cooijmans, Tim and Roberts, Adam and Courville, Aaron and Eck, Douglas},
	month = mar,
	year = {2019},
	note = {arXiv: 1903.07227},
	keywords = {Internship@Avid}
}

@inproceedings{levenshtein_binary_1966,
	title = {Binary codes capable of correcting deletions, insertions, and reversals},
	volume = {10},
	booktitle = {Soviet physics doklady},
	author = {Levenshtein, Vladimir I},
	year = {1966},
	keywords = {FolkPlagiarism},
	pages = {707--710}
}

@article{damerau_technique_1964,
	title = {A technique for computer detection and correction of spelling errors},
	volume = {7},
	issn = {0001-0782},
	url = {https://doi.org/10.1145/363958.363994},
	doi = {10.1145/363958.363994},
	abstract = {The method described assumes that a word which cannot be found in a dictionary has at most one error, which might be a wrong, missing or extra letter or a single transposition. The unidentified input word is compared to the dictionary again, testing each time to see if the words match—assuming one of these errors occurred. During a test run on garbled text, correct identifications were made for over 95 percent of these error types.},
	number = {3},
	urldate = {2020-02-12},
	journal = {Communications of the ACM},
	author = {Damerau, Fred J.},
	month = mar,
	year = {1964},
	keywords = {FolkPlagiarism},
	pages = {171--176}
}

@misc{tagliarino_guitar_2003,
	address = {Milwaukee},
	title = {Guitar fretboard workbook},
	isbn = {978-0-634-04901-9},
	language = {English},
	publisher = {Hal Leonard Corporation},
	collaborator = {Tagliarino, Barrett and {Hal Leonard Publishing Corporation}},
	year = {2003},
	note = {OCLC: 319810609},
	keywords = {MusicPractice}
}

@book{rimsky-korsakov_practical_2005,
	address = {New York, NY},
	title = {Practical manual of harmony},
	isbn = {978-0-8258-5699-0},
	language = {English},
	publisher = {C. Fischer},
	author = {Rimsky-Korsakov, Nikolay and Achron, Joseph and Hopkins, Nicholas},
	year = {2005},
	note = {OCLC: 60523181},
	keywords = {Comps, Comps\_Q6, Comps\_Q6\_Theory, Comps\_Q7}
}

@inproceedings{devaney_theme_2015,
	address = {Málaga, Spain},
	title = {Theme {And} {Variation} {Encodings} with {Roman} {Numerals} ({TAVERN}): {A} {New} {Data} {Set} for {Symbolic} {Music} {Analysis}.},
	url = {https://doi.org/10.5281/zenodo.1417497},
	doi = {10.5281/zenodo.1417497},
	booktitle = {Proceedings of the 16th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Devaney, Johanna and Arthur, Claire and Condit-Schultz, Nathaniel and Nisula, Kirsten},
	month = oct,
	year = {2015},
	keywords = {Comps, Comps\_Q5, harmalysis},
	pages = {728--734}
}

@article{neuwirth_annotated_2018,
	title = {The {Annotated} {Beethoven} {Corpus} ({ABC}): {A} {Dataset} of {Harmonic} {Analyses} of {All} {Beethoven} {String} {Quartets}},
	volume = {5},
	issn = {2297-2668},
	shorttitle = {The {Annotated} {Beethoven} {Corpus} ({ABC})},
	url = {https://www.frontiersin.org/articles/10.3389/fdigh.2018.00016/full},
	doi = {10.3389/fdigh.2018.00016},
	abstract = {The Annotated Beethoven Corpus (ABC): A Dataset of Harmonic Analyses of All Beethoven String Quartets},
	language = {English},
	urldate = {2019-08-05},
	journal = {Frontiers in Digital Humanities},
	author = {Neuwirth, Markus and Harasim, Daniel and Moss, Fabian C. and Rohrmeier, Martin},
	year = {2018},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Dataset, harmalysis}
}

@inproceedings{chen_functional_2010,
	address = {Utrecht, Netherlands},
	title = {Functional {Harmony} {Annotation} {Database} for {Statistical} {Music} {Analysis}},
	booktitle = {Proceedings of the 11th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Chen, Tsung-Ping and Su, Li},
	year = {2010},
	keywords = {RNA}
}

@inproceedings{chen_functional_2018,
	address = {Paris, France},
	title = {Functional {Harmony} {Recognition} of {Symbolic} {Music} {Data} with {Multi}-task {Recurrent} {Neural} {Networks}},
	url = {https://doi.org/10.5281/zenodo.1492351},
	doi = {10.5281/zenodo.1492351},
	booktitle = {Proceedings of the 19th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Chen, Tsung-Ping and Su, Li},
	month = sep,
	year = {2018},
	keywords = {RNA},
	pages = {90--97}
}

@article{vos_parallel-processing_1996,
	title = {A {Parallel}-{Processing} {Key}-{Finding} {Model}},
	volume = {14},
	issn = {0730-7829, 1533-8312},
	url = {https://mp.ucpress.edu/content/14/2/185},
	doi = {10.2307/40285717},
	abstract = {Skip to Next Section
A model of key finding is presented for single-voiced pieces of tonal music. Each tone is input as a pitch class and a duration. The model makes a parallel search for the key in the scalar and chordal domains, taking into account primacy and memory constraints. The model has been tested for a range of tonal music including the fugue subjects of J. S. Bach's Wohltemperierte Klavier (WTK). The notated key was usually found after a few processing steps and from then on remained stable— but was still sensitive to modulation. The performance of the parallel-processing model was compared with the performance of key-finding models previously proposed by Krumhansl and Schmuckler and by Longuet-Higgins and Steedman. The comparison showed that the new model's most distinctive features, implementation of parallel key search in the scalar and chordal domains, as well as the implementation of search-restricting factors, primacy and memory, make the new model a powerful and plausible alternative to the other models. Subsequently, the parallel-processing model's perceptual plausibility has been tested in two experiments, in which 20 musically well-trained subjects had to produce the key(s) of eight WTK fugue themes (Experiment 1) and to rate the key transparency for seven contrapuntal variations of the A minor subject of J. S. Bach's Kunst der Fuge (Experiment 2). A substantial concordance between listeners' judgments and the key inferences produced by the model was found in both experiments. Conceptual limitations, such as the model's disregard for the potential impact of recency on key finding and for expectations from functional implications of tone order, are discussed. Potential extensions of the model are suggested, as well as ideas for further perceptual studies in which the model might be tested in a more advanced manner than in the present study.},
	language = {en},
	number = {2},
	urldate = {2019-11-12},
	journal = {Music Perception: An Interdisciplinary Journal},
	author = {Vos, Piet G. and van Geenen, Erwin W.},
	month = dec,
	year = {1996},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic},
	pages = {185--223}
}

@book{weber_theory_2018,
	title = {The theory of musical composition: treated with a view to a naturally consecutive arrangement of topics. {Vol}. 1 {Vol}. 1},
	isbn = {978-1-332-59842-7},
	shorttitle = {The theory of musical composition},
	language = {English},
	author = {Weber, Gottfried and Warner, James F and Bishop, John},
	year = {2018},
	note = {OCLC: 1101626873},
	keywords = {Comps}
}

@article{djaouti_classifying_2011,
	title = {Classifying {Serious} {Games}: the {G}/{P}/{S} model},
	doi = {10.4018/978-1-60960-495-0.ch006},
	journal = {Handbook of Research on Improving Learning and Motivation through Educational Games: Multidisciplinary Approaches},
	author = {Djaouti, Damien and Alvarez, Julian and Jessel, Jean-Pierre},
	year = {2011},
	keywords = {ReadLater}
}

@book{nelson_guitar_2007,
	address = {Milwaukee, WI},
	title = {Guitar aerobics: a 52-week, one-lick-per-day workout program for developing, improving and maintaining guitar technique},
	isbn = {978-1-4234-1435-3},
	shorttitle = {Guitar aerobics},
	language = {English},
	publisher = {Hal Leonard},
	author = {Nelson, Troy},
	year = {2007},
	note = {OCLC: 966552420},
	keywords = {MusicPractice}
}

@misc{musescore_handbook_nodate,
	title = {Handbook for {MuseScore} 3},
	url = {https://musescore.org/en/handbook},
	abstract = {This handbook is for MuseScore version 3.0 and above. It is maintained and translated by the MuseScore community. Find out how you can help. (If you are still…},
	language = {en},
	urldate = {2019-12-21},
	journal = {Musescore.org},
	author = {MuseScore},
	keywords = {harmalysis}
}

@misc{noauthor_roman_nodate,
	title = {Roman {Numeral} {Analysis} ({RNA})},
	url = {https://musescore.org/en/handbook/3/roman-numeral-analysis-rna},
	abstract = {As of version 3.3, MuseScore supports Roman Numeral Analysis (RNA), a chord analysis system using a system of lower and upper case roman numerals, superscripts…},
	language = {en},
	urldate = {2019-12-18},
	journal = {Musescore.org},
	keywords = {harmalysis}
}

@misc{huron_representation:_nodate,
	title = {Representation: **harm — humdrum-tools 1 documentation},
	url = {https://www.humdrum.org/rep/harm/},
	urldate = {2019-12-18},
	author = {Huron, David},
	keywords = {harmalysis}
}

@mastersthesis{napoles_lopez_automatic_2017,
	title = {Automatic harmonic analysis of classical string quartets from symbolic score},
	copyright = {All rights reserved},
	url = {https://doi.org/10.5281/zenodo.1095617},
	school = {Universitat Pompeu Fabra},
	author = {Nápoles López, Néstor},
	month = dec,
	year = {2017},
	doi = {10.5281/zenodo.1095617},
	keywords = {My Publications}
}

@inproceedings{gotham_romantext_2019,
	address = {Delft, The Netherlands},
	title = {The {RomanText} {Format}: {A} {Flexible} and {Standard} {Method} for {Representing} {Roman} {Numerial} {Analyses}},
	url = {https://doi.org/10.5281/zenodo.3527756},
	doi = {10.5281/zenodo.3527756},
	booktitle = {Proceedings of the 20th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Gotham, Mark and Tymoczko, Dmitri and Cuthbert, Michael},
	month = nov,
	year = {2019},
	keywords = {ISMIR2019, Roman Numeral Analysis, harmalysis},
	pages = {123--129}
}

@inproceedings{colombo_deep_2017,
	title = {Deep {Artificial} {Composer}: {A} {Creative} {Neural} {Network} {Model} for {Automated} {Melody} {Generation}},
	booktitle = {Proc. {EvoMUSART}},
	author = {Colombo, F. and Seeholzer, A. and Gerstner, W.},
	year = {2017},
	keywords = {FolkPlagiarism}
}

@book{schubert_modal_2008,
	address = {New York},
	edition = {2nd ed},
	title = {Modal counterpoint, {Renaissance} style},
	isbn = {978-0-19-533194-3},
	publisher = {Oxford University Press},
	author = {Schubert, Peter},
	year = {2008},
	keywords = {ReadLater}
}
@book{mynett_metal_2017,
	address = {New York London},
	title = {Metal {Music} {Manual}: producing, engineering, mixing and mastering contemporary {Heavy} {Music}},
	isbn = {978-1-315-75007-1 978-1-138-80931-4 978-1-138-80932-1},
	shorttitle = {Metal {Music} {Manual}},
	abstract = {Introduction -- Contemporary metal music -- The parameters of heaviness -- Preproduction -- Sound at source -- Engineering overview -- Drums -- Guitars -- Bass -- Vocals -- Edits, polarity and phase alignment, samples, and gates -- Balance and stereo width -- Compression -- EQ -- Effects processing and automation -- Master buss processing -- Mastering -- Loudness normalization},
	language = {eng},
	publisher = {Routledge},
	author = {Mynett, Mark},
	year = {2017},
	note = {OCLC: 915386849},
	keywords = {ReadLater}
}

@article{cho_relative_2014,
	title = {On the {Relative} {Importance} of {Individual} {Components} of {Chord} {Recognition} {Systems}},
	volume = {22},
	issn = {2329-9290, 2329-9304},
	doi = {10.1109/TASLP.2013.2295926},
	abstract = {Most chord recognition systems share a common architecture comprising two main stages: feature extraction and pattern matching, and two optional sub stages: pre-filtering and post-filtering. Understanding the interaction between these basic components is very important not only for achieving optimal performance, but also for assessing the potential and limitations of the system. Unfortunately, there are no studies that sufficiently evaluate the effects of the different approaches to each processing step and the interactions between these steps. In this paper we attempt to remedy this deficiency by performing a systematic evaluation encompassing a wide variety of techniques used for each processing step. In our study we find that filtering has a significant impact on performance, but providing musical context information in the transition matrix is rendered moot by the need to enforce continuity in the estimations. We discovered that the benefits of using complex chord models can be largely offset by an appropriate choice of features. In addition, the initial performance gap between different features were not fully compensated by any subsequent processing stages.},
	number = {2},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {Cho, Taemin and Bello, Juan P.},
	month = feb,
	year = {2014},
	keywords = {Comps, Comps\_Q4},
	pages = {477--492}
}

@inproceedings{harte_automatic_2005,
	title = {Automatic {Chord} {Identifcation} using a {Quantised} {Chromagram}},
	url = {http://www.aes.org/e-lib/browse.cfm?elib=13128},
	abstract = {This paper presents an approach to the problem of identifying musical chords from audio recordings. In our approach, a tuning algorithm is applied to a 36-bin chromagram to accurately locate the boundaries between semitones. This allows the calculation of a 12-bin semitone-quantised chromagram, which can then be compared with a set of predefined chord templates in order to generate a sequence of chord estimates. The performance of our method is evaluated by comparing the results with a test...},
	language = {English},
	urldate = {2019-11-15},
	publisher = {Audio Engineering Society},
	author = {Harte, Christopher and Sandler, Mark},
	month = may,
	year = {2005},
	keywords = {Comps, Comps\_Q4}
}

@book{tchaikovsky_guide_2005,
	address = {Mineola, N.Y.},
	title = {Guide to the practical study of harmony},
	isbn = {978-0-486-44272-3},
	language = {English},
	publisher = {Dover},
	author = {Tchaikovsky, Peter Ilich},
	year = {2005},
	note = {OCLC: 61050713},
	keywords = {Comps, Comps\_Q6, Comps\_Q6\_Theory}
}

@book{aldwell_harmony_2017,
	address = {Boston, MA},
	edition = {5th edition},
	title = {Harmony \& voice leading},
	isbn = {978-1-337-56057-3},
	publisher = {Cengage},
	author = {Aldwell, Edward and Schachter, Carl and Cadwallader, Allen Clayton},
	year = {2017},
	keywords = {Comps, Comps\_Q6, Comps\_Q6\_Theory}
}

@article{cohen_tonality_1991,
	title = {Tonality and perception: {Musical} scales primed by excerpts {fromThe} {Well}-{Tempered} {Clavier} of {J}. {S}. {Bach}},
	volume = {53},
	issn = {1430-2772},
	shorttitle = {Tonality and perception},
	url = {https://doi.org/10.1007/BF00920484},
	doi = {10.1007/BF00920484},
	abstract = {SummaryThe psychological relevance of the musicians' concept of tonality was tested in the context of the music of J. S. Bach. Musically trained listeners were instructed to sing the musical scale that first came to mind immediately after hearing short excerpts from Preludes of J. S. Bach'sThe Well-Tempered Clavier. For each Prelude, the tonic (first note) and the mode (major or minor) of the scale produced were compared to the tonic and mode designated by Bach. Results indicated that listeners (1) often established the designated tonic and mode within the first four notes of the piece; (2) within the first four bars, often established tonalities different from that of the designated key, a tendency that increased by the eighth bar; and (3) reestablished the tonic in the last four bars. These observations validate, in general, music-theoretic assumptions about the listener's hearing of tonality, and raise issues regarding the salient relations that engage the cognitive structures underlying tonality perception.},
	language = {en},
	number = {4},
	urldate = {2019-10-07},
	journal = {Psychological Research},
	author = {Cohen, Annabel J.},
	month = dec,
	year = {1991},
	keywords = {Comps, Comps\_Q5, Comps\_Q8},
	pages = {305--314}
}

@book{lerdahl_tonal_2005,
	title = {Tonal {Pitch} {Space}},
	isbn = {978-0-19-987037-0},
	url = {http://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780195178296.001.0001/acprof-9780195178296},
	abstract = {This book builds on and in many ways completes the project of Fred Lerdahl and Ray Jackendoff's influential A Generative Theory of Tonal Music. Like the earlier volume, this book is both a music-theoretic treatise and a contribution to the cognitive science of music. After presenting some modifications to Lerdahl and Jackendoff's original framework, the book develops a quantitative model of listeners' intuitions of the relative distances of pitches, chords, and regions from a given tonic. The model is used to derive prolongational structure, trace paths through pitch space at multiple prolongational levels, and compute patterns of tonal tension and attraction as musical events unfold. The consideration of pitch-space paths illuminates issues of musical narrative, and the treatment of tonal tension and attraction provides a technical basis for studies of musical expectation and expression. These investigations lead to a fresh theory of tonal function and reveal an underlying parallel between tonal and metrical structures. Later portions of the book apply these ideas to highly chromatic tonal as well as atonal music. In response to stylistic differences, the shape of pitch space changes and psychoacoustic features become increasingly important, while underlying features of the theory remain constant, reflecting unvarying features of the musical mind. The theory is illustrated throughout by analyses of music from Bach to Schoenberg, and frequent connections are made to the music-theoretic and psychological literature.},
	language = {en\_US},
	urldate = {2019-10-08},
	publisher = {Oxford University Press},
	author = {Lerdahl, Fred},
	month = jan,
	year = {2005},
	keywords = {Comps, Comps\_Unidentified}
}

@book{lerdahl_generative_1990,
	address = {Cambridge, Mass.},
	edition = {4. print},
	series = {The {MIT} {Press} series on cognitive theory and mental representation},
	title = {A {Generative} {Theory} of {Tonal} {Music}},
	isbn = {978-0-262-62049-9},
	language = {eng},
	publisher = {MIT Press},
	author = {Lerdahl, Fred and Jackendoff, Ray},
	year = {1990},
	keywords = {Comps, Comps\_Unidentified}
}

@article{mauch_simultaneous_2010,
	title = {Simultaneous {Estimation} of {Chords} and {Musical} {Context} {From} {Audio}},
	volume = {18},
	issn = {1558-7916},
	doi = {10.1109/TASL.2009.2032947},
	abstract = {Chord labels provide a concise description of musical harmony. In pop and jazz music, a sequence of chord labels is often the only written record of a song, and forms the basis of so-called lead sheets. We devise a fully automatic method to simultaneously estimate from an audio waveform the chord sequence including bass notes, the metric positions of chords, and the key. The core of the method is a six-layered dynamic Bayesian network, in which the four hidden source layers jointly model metric position, key, chord, and bass pitch class, while the two observed layers model low-level audio features corresponding to bass and treble tonal content. Using 109 different chords our method provides substantially more harmonic detail than previous approaches while maintaining a high level of accuracy. We show that with 71\% correctly classified chords our method significantly exceeds the state of the art when tested against manually annotated ground truth transcriptions on the 176 audio tracks from the MIREX 2008 Chord Detection Task. We introduce a measure of segmentation quality and show that bass and meter modeling are especially beneficial for obtaining the correct level of granularity.},
	number = {6},
	journal = {IEEE Transactions on Audio, Speech, and Language Processing},
	author = {Mauch, Matthias and Dixon, Simon},
	month = aug,
	year = {2010},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey},
	pages = {1280--1289}
}

@inproceedings{niedermayer_importance_2011,
	address = {Miami, United States},
	title = {On the {Importance} of "{Real}" {Audio} {Data} for {MIR} {Algorithm} {Evaluation} at the {Note}-{Level} - {A} {Comparative} {Study}.},
	url = {https://doi.org/10.5281/zenodo.1417923},
	doi = {10.5281/zenodo.1417923},
	booktitle = {Proceedings of the 12th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Niedermayer, Bernhard and Böck, Sebastian and Widmer, Gerhard},
	month = oct,
	year = {2011},
	keywords = {Comps, Comps\_Q5, Comps\_Q6, Comps\_Q6\_MIR, Comps\_Q6\_NoteLevel},
	pages = {543--548}
}

@inproceedings{papadopoulos_large-scale_2007,
	address = {Bordeaux, France},
	title = {Large-{Scale} {Study} of {Chord} {Estimation} {Algorithms} {Based} on {Chroma} {Representation} and {HMM}},
	doi = {10.1109/CBMI.2007.385392},
	abstract = {This paper deals with the automatic estimation of chord progression over time of an audio file. From the audio signal, a set of chroma vectors representing the pitch content of the file over time is extracted. From these observations the chord progression is then estimated using hidden Markov models. Several methods are proposed that allow taking into account music theory, perception of key and presence of higher harmonics of pitch notes. The proposed methods are then compared to existing algorithms. A large-scale evaluation on 110 hand-labeled songs from the Beatles allows concluding on improvement over the state of the art.},
	booktitle = {2007 {International} {Workshop} on {Content}-{Based} {Multimedia} {Indexing}},
	author = {Papadopoulos, H. and Peeters, G.},
	month = jun,
	year = {2007},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_ChordRecognition, Comps\_Q4, Comps\_Q4\_FeatureExtraction, Comps\_ToDo},
	pages = {53--60}
}

@inproceedings{raphael_harmonic_2003,
	title = {Harmonic analysis with probabilistic graphical models},
	abstract = {A technique for harmonic analysis is presented that partitions a piece of music into contiguous regions and labels each with the key, mode, and functional chord, e.g. tonic, dominant, etc. The analysis is performed with a hidden Markov model and, as such, is automatically trainable from generic MIDI files and capable of finding the globally optimal harmonic labeling. Experiments are presented highlighting our current state of the art. An extension to a more complex probabilistic graphical model is outlined in which music is modeled as a collection of voices that evolve independently given the harmonic progression.},
	booktitle = {{ISMIR}},
	author = {Raphael, Christopher and Stoddard, Josh},
	year = {2003},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_ChordRecognition, Comps\_Skimmed, Comps\_Summarized}
}

@inproceedings{rohrmeier_statistical_2008,
	address = {Hokkaido University Sapporo, Japan},
	title = {Statistical {Properties} of {Tonal} {Harmony} in {Bach}’s {Chorales}},
	booktitle = {Proceedings of the 10th international conference on music perception and cognition},
	author = {Rohrmeier, Martin and Cross, Ian},
	year = {2008},
	keywords = {Comps, Comps\_Unidentified},
	pages = {619--627}
}

@article{raphael_functional_2004,
	title = {Functional {Harmonic} {Analysis} {Using} {Probabilistic} {Models}},
	volume = {28},
	issn = {0148-9267},
	url = {https://doi.org/10.1162/0148926041790676},
	doi = {10.1162/0148926041790676},
	number = {3},
	urldate = {2019-08-07},
	journal = {Computer Music Journal},
	author = {Raphael, Christopher and Stoddard, Joshua},
	month = sep,
	year = {2004},
	keywords = {Comps, Comps\_Unidentified},
	pages = {45--52}
}

@inproceedings{sapp_harmonic_2001,
	address = {Havana, Cuba},
	title = {Harmonic {Visualizations} of {Tonal} {Music}.},
	volume = {1},
	booktitle = {Proceedings of the {International} {Computer} {Music} {Conference}},
	author = {Sapp, Craig Stuart},
	year = {2001},
	keywords = {Comps, Comps\_Q5},
	pages = {419--422}
}

@article{serra_statistical_2008,
	title = {Statistical {Analysis} of {Chroma} {Features} in {Western} {Music} {Predicts} {Human} {Judgments} of {Tonality}},
	volume = {37},
	issn = {0929-8215},
	url = {https://doi.org/10.1080/09298210902894085},
	doi = {10.1080/09298210902894085},
	abstract = {Motivated by evidence that image source statistics predict the response properties of several visual perception aspects, we provide an empirical analysis of the relation between chroma statistics and human judgments of tonality. To accomplish this, a statistical analysis method based on chroma feature covariance is proposed. It makes use of a large collection of western music to build a tonal profile. The obtained profile is compared to alternative tonal profiles proposed in the literature, either cognitively, perceptually, or theoretically inspired. The high degree of correlation we find between the covariance-based tonal profile proposed here and several ones proposed in the literature (reaching values higher than 0.9) is interpreted as evidence that human-derived profiles faithfully reflect the statistics of the musical input listeners have been exposed to. Furthermore, we show that very short time scales allow us to correctly predict these profiles, which brings us to discuss the role that local-scale implicit learning plays in building mental representations of tonality.},
	number = {4},
	urldate = {2019-08-04},
	journal = {Journal of New Music Research},
	author = {Serrà, Joan and Gómez, Emilia and Herrera, Perfecto and Serra, Xavier},
	month = dec,
	year = {2008},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_FeatureExtraction, Comps\_Q5, Comps\_Q8, Comps\_Read, Comps\_Summarized},
	pages = {299--309}
}

@book{temperley_cognition_2004,
	title = {The {Cognition} of {Basic} {Musical} {Structures}},
	publisher = {MIT press},
	author = {Temperley, David},
	year = {2004},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic, Comps\_Q5, Comps\_Q7}
}

@article{tymoczko_local_2010,
	title = {Local harmonic grammar in {Western} classical music},
	journal = {Unpublished manuscript},
	author = {Tymoczko, Dmitri},
	year = {2010},
	keywords = {Comps, Comps\_Unidentified}
}

@book{tymoczko_geometry_2011,
	address = {New York, UNITED STATES},
	title = {A {Geometry} of {Music}: {Harmony} and {Counterpoint} in the {Extended} {Common} {Practice}},
	isbn = {978-0-19-971435-3},
	shorttitle = {A {Geometry} of {Music}},
	url = {http://ebookcentral.proquest.com/lib/mcgill/detail.action?docID=665450},
	abstract = {How is the Beatles' "Help!" similar to Stravinsky's "Dance of the Adolescents?" How does Radiohead's "Just" relate to the improvisations of Bill Evans? And how do Chopin's works exploit the non-Euclidean geometry of musical chords?In this groundbreaking work, author Dmitri Tymoczko describes a new framework for thinking about music that emphasizes the commonalities among styles from medieval polyphony to contemporary rock. Tymoczko identifies five basic musical features that jointly contribute to the sense of tonality, and shows how these features recur throughout the history of Western music. In the process he sheds new light on an age-old question: what makes music sound good?A Geometry of Music provides an accessible introduction to Tymoczko's revolutionary geometrical approach to music theory. The book shows how to construct simple diagrams representing relationships among familiar chords and scales, giving readers the tools to translate between the musical and visual realms and revealing surprising degrees of structure in otherwise hard-to-understand pieces.Tymoczko uses this theoretical foundation to retell the history of Western music from the eleventh century to the present day. Arguing that traditional histories focus too narrowly on the "common practice" period from 1680-1850, he proposes instead that Western music comprises an extended common practice stretching from the late middle ages to the present. He discusses a host of familiar pieces by a wide range of composers, from Bach to the Beatles, Mozart to Miles Davis, and many in between.A Geometry of Music is accessible to a range of readers, from undergraduate music majors to scientists and mathematicians with an interest in music. Defining its terms along the way, it presupposes no special mathematical background and only a basic familiarity with Western music theory. The book also contains exercises designed to reinforce and extend readers' understanding, along with a series of appendices that explore the technical details of this exciting new theory.},
	urldate = {2019-10-18},
	publisher = {Oxford University Press, Incorporated},
	author = {Tymoczko, Dmitri},
	year = {2011},
	keywords = {Comps, Comps\_Unidentified}
}

@inproceedings{martorell_systematic_2014,
	address = {Taipei, Taiwan},
	title = {Systematic {Multi}-scale {Set}-class {Analysis}.},
	url = {https://doi.org/10.5281/zenodo.1417595},
	doi = {10.5281/zenodo.1417595},
	booktitle = {Proceedings of the 15th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Martorell, Agustín and Gómez, Emilia},
	month = oct,
	year = {2014},
	keywords = {Comps, Comps\_Unidentified},
	pages = {219--224}
}

@inproceedings{burgoyne_learning_2005,
	address = {London, United Kingdom},
	title = {Learning {Harmonic} {Relationships} in {Digital} {Audio} with {Dirichlet}-{Based} {Hidden} {Markov} {Models}.},
	url = {https://doi.org/10.5281/zenodo.1414870},
	doi = {10.5281/zenodo.1414870},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Burgoyne, John Ashley and Saul, Lawrence K.},
	month = sep,
	year = {2005},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_HarmonicAudio, Comps\_Q1\_MIR\_Key, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Q6, Comps\_Q6\_MIR, Comps\_Read, Comps\_Summarized},
	pages = {438--443}
}

@inproceedings{harte_detecting_2006,
	address = {New York, NY, USA},
	series = {{AMCMM} '06},
	title = {Detecting {Harmonic} {Change} in {Musical} {Audio}},
	isbn = {978-1-59593-501-4},
	url = {http://doi.acm.org/10.1145/1178723.1178727},
	doi = {10.1145/1178723.1178727},
	abstract = {We propose a novel method for detecting changes in the harmonic content of musical audio signals. Our method uses a new model for Equal Tempered Pitch Class Space. This model maps 12-bin chroma vectors to the interior space of a 6-D polytope; pitch classes are mapped onto the vertices of this polytope. Close harmonic relations such as fifths and thirds appear as small Euclidian distances. We calculate the Euclidian distance between analysis frames n +1 and n -1 to develop a harmonic change measure for frame n. A peak in the detection function denotes a transition from one harmonically stable region to another. Initial experiments show that the algorithm can successfully detect harmonic changes such as chord boundaries in polyphonic audio recordings.},
	urldate = {2019-08-06},
	booktitle = {Proceedings of the 1st {ACM} {Workshop} on {Audio} and {Music} {Computing} {Multimedia}},
	publisher = {ACM},
	author = {Harte, Christopher and Sandler, Mark and Gasser, Martin},
	year = {2006},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Q6, Comps\_Q6\_MIR, Comps\_Skimmed, Comps\_Summarized},
	pages = {21--26}
}

@incollection{goto_music_2006,
	address = {Boston, MA},
	title = {Music {Scene} {Description}},
	isbn = {978-0-387-32845-4},
	url = {https://doi.org/10.1007/0-387-32845-9_11},
	abstract = {This chapter introduces a research approach called ‘music scene description’ [232], [225], [228], where the goal is to build a computer system that can understand musical audio signals at the level of untrained human listeners without trying to extract every musical note from music. People listening to music can easily hum the melody, clap hands in time to the musical beat, notice a phrase being repeated, and find chorus sections. The brain mechanisms underlying these abilities, however, are not yet well understood. In addition, it has been difficult to implement these abilities on a computer system, although a system with them is useful in various applications such as music information retrieval, music production/editing, and music interfaces. It is therefore an important challenge to build a music scene description system that can understand complex real-world music signals like those recorded on commercially distributed compact discs (CDs).},
	language = {en},
	urldate = {2019-10-08},
	booktitle = {Signal {Processing} {Methods} for {Music} {Transcription}},
	publisher = {Springer US},
	author = {Goto, Masataka},
	editor = {Klapuri, Anssi and Davy, Manuel},
	year = {2006},
	doi = {10.1007/0-387-32845-9_11},
	keywords = {Comps, Comps\_Unidentified},
	pages = {327--359}
}

@inproceedings{barthelemy_figured_2001,
	address = {Bloomington, United States},
	title = {Figured {Bass} and {Tonality} {Recognition}.},
	url = {https://doi.org/10.5281/zenodo.1417161},
	doi = {10.5281/zenodo.1417161},
	booktitle = {Proceedings of the 2nd {International} {Symposium} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Barthélemy, Jérôme},
	month = oct,
	year = {2001},
	keywords = {Comps, Comps\_Q5}
}

@article{brown_musical_1994,
	title = {Musical and {Temporal} {Influences} on {Key} {Discovery}},
	volume = {11},
	number = {4},
	journal = {Music Perception: An Interdisciplinary Journal},
	author = {Brown, Helen and Butler, David and Jones, Mari Riess},
	month = jul,
	year = {1994},
	keywords = {Comps},
	pages = {371--407}
}

@article{vos_key_1999,
	title = {Key {Implications} of {Ascending} {Fourth} and {Descending} {Fifth} {Openings}},
	volume = {27},
	issn = {0305-7356},
	url = {https://doi.org/10.1177/0305735699271002},
	doi = {10.1177/0305735699271002},
	abstract = {Substantial evidence is reported in support of the rule that, if a Western tonal composition opens melodically with an ascending fourth or a descending fifth ("4/5 opening"), then the second tone is the tonic of the composition's key, and the first tone its dominant. The evidence is taken from unaccompanied melodic openings of compositions by Bach, Mozart, Brahms, and of national anthems, hymns, and folksongs. The implementation of the hitherto unrecognised rule in a computational key-finding model (Vos and Van Geenen, 1996) appeared to improve the validity of the model. 4/5 openings were additionally explored in relation to their concomitant metrical structures. 4/5 openings corresponded to upbeat/downbeat progressions in 99\% of surveyed German folksongs, but only 23\% of hymns. The findings are discussed with an emphasis on the need for more historical, music-theoretical, and perceptual research of musical openings.},
	language = {en},
	number = {1},
	urldate = {2019-11-14},
	journal = {Psychology of Music},
	author = {Vos, Piet G.},
	month = apr,
	year = {1999},
	keywords = {Comps},
	pages = {4--17}
}

@article{krumhansl_tonal_1990,
	title = {Tonal {Hierarchies} and {Rare} {Intervals} in {Music} {Cognition}},
	volume = {7},
	issn = {0730-7829, 1533-8312},
	url = {https://mp.ucpress.edu/content/7/3/309},
	doi = {10.2307/40285467},
	abstract = {Skip to Next Section
Four issues raised by Butler's (1989) commentary are addressed. The first issue is the possibility that the results of perceptual studies of tonal hierarchies can be attributed to task-specific strategies developed in response to particular stimuli. Such strategies cannot account for the convergence across experiments employing varied tasks and stimulus materials. The second issue is the correspondence between statistical summaries of music and perceptual data. The correspondence is shown to be quite general and to have implications for the acquisition of tonal knowledge. The third issue is the process listeners use to identify the tonal center. Patternmatching to tonal hierarchies is shown to be a plausible process contributing to key-finding, whereas a tritone rule has limited applicability. The final issue is the effect of temporal order on pitch perception. Principled temporal-order effects are found in many psychological experiments, but not in those focusing on the tritone relation.},
	language = {en},
	number = {3},
	urldate = {2019-11-14},
	journal = {Music Perception: An Interdisciplinary Journal},
	author = {Krumhansl, Carol L.},
	month = apr,
	year = {1990},
	keywords = {Comps},
	pages = {309--324}
}

@article{butler_describing_1989,
	title = {Describing the {Perception} of {Tonality} in {Music}: {A} {Critique} of the {Tonal} {Hierarchy} {Theory} and a {Proposal} for a {Theory} of {Intervallic} {Rivalry}},
	volume = {6},
	issn = {07307829, 15338312},
	url = {http://www.jstor.org/stable/40285588},
	abstract = {Strengths and limitations of the tonal hierarchy theory, and of the probetone testing procedure used to substantiate that theory, are discussed. The tonal hierarchy theory is characterized as an important contribution in that it begins to describe hierarchical relationships of tones in the diatonic set. The tonal hierarchy theory is, however, criticized because it does not describe the mental process or processes by which the tonal center of a piece of tonal music is recognized, nor does it account for the dynamic perception of tonality as it unfolds during actual musical listening. The probe-tone testing procedure most often used to substantiate the tonal hierarchy theory is criticized for the ambiguity of its response task, so that test results could be an artifact of effects of short-term memory. An alternative perceptual theory is proposed to describe the timedependent nature of pitch relationships in music. In this description, listeners are assumed to recognize the tonal center in tonal music on a bestevidence basis, and it is asserted that the clearest evidence is carried in the rarest-occurring intervals in the diatonic set. Evidence, gathered in a series of experiments, is cited to demonstrate that listeners both with and without extensive formal training in music form strong (and usually tacit) mental representations of unambiguous tonality when tones are arranged across time so as to form meaningful tonal referents.},
	number = {3},
	journal = {Music Perception: An Interdisciplinary Journal},
	author = {Butler, David},
	year = {1989},
	keywords = {Comps, Comps\_Q8},
	pages = {219--241}
}

@inproceedings{gebhardt_confidence_2018,
	address = {Paris, France},
	title = {A {Confidence} {Measure} {For} {Key} {Labelling}},
	copyright = {Creative Commons Attribution 4.0, Open Access},
	url = {https://zenodo.org/record/1492332},
	doi = {10.5281/zenodo.1492332},
	abstract = {We present a new measure for automatically estimating the confidence of musical key classification. Our approach leverages the degree of harmonic information held within a musical audio signal (its "keyness") as well as the steadiness of local key detections across the its duration (its "stability"). Using this confidence measure, musical tracks which are likely to be misclassified, i.e. those with low confidence, can then be handled differently from those analysed by standard, fully automatic key detection methods. By means of a listening test, we demonstrate that our developed features significantly correlate with listeners' ratings of harmonic complexity, steadiness and the uniqueness of key. Furthermore, we demonstrate that tracks which are incorrectly labelled using an existing key detection system obtain low confidence values. Finally, we introduce a new method called "root note heuristics" for the special treatment of tracks with low confidence. We show that by applying these root note heuristics, key detection results can be improved for minimalistic music.},
	urldate = {2019-08-06},
	booktitle = {Proceedings of the 19th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	author = {Gebhardt, Roman B. and Stein, Michael and Lykartsis, Athanasios},
	month = sep,
	year = {2018},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Evaluation, Comps\_Q5, Comps\_Q8}
}

@inproceedings{bellmann_about_2006,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {About the {Determination} of {Key} of a {Musical} {Excerpt}},
	isbn = {978-3-540-34028-7},
	abstract = {Knowledge of the key of a musical passage is a pre-requisite for all the analyses that require functional labelling. In the past, people from either a musical or AI background have tended to solve the problem by means of implementing a computerized version of musical analysis. Previous attempts are discussed and then attention is focused on a non-analytical solution first reported by J.A.Gabura. A practical way to carry it out is discussed as well as its limitations in relation to examples. References are made to the MusicXML format as needed.},
	language = {en},
	booktitle = {Computer {Music} {Modeling} and {Retrieval}},
	publisher = {Springer Berlin Heidelberg},
	author = {Bellmann, Héctor},
	editor = {Kronland-Martinet, Richard and Voinier, Thierry and Ystad, Sølvi},
	year = {2006},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic, Comps\_Q5, Comps\_Q8, Comps\_Skimmed, Comps\_Summarized},
	pages = {76--91}
}

@article{quinn_are_2010,
	title = {Are {Pitch}-{Class} {Profiles} {Really} “{Key} for {Key}”?},
	volume = {7},
	number = {2},
	journal = {Zeitschrift der Gesellschaft für Musiktheorie [Journal of the German-speaking Society of Music Theory]},
	author = {Quinn, Ian},
	year = {2010},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic, Comps\_Q5, Comps\_Q8, Comps\_Read, Comps\_Summarized},
	pages = {151--163}
}

@article{wiggins_non-existence_2010,
	title = {On the non-existence of music: {Why} music theory is a figment of the imagination},
	volume = {14},
	issn = {1029-8649},
	shorttitle = {On the non-existence of music},
	url = {https://doi.org/10.1177/10298649100140S110},
	doi = {10.1177/10298649100140S110},
	abstract = {We argue for an approach to the theory of music which starts from the position that music is primarily a construct of human minds (and secondarily a social construct) and contrast it with the approach implicit in the work of some music theorists, which treats music as though it were an externally defined quasi-Platonic absolute. We argue that a natural conclusion of this approach is that music theory, while already being a kind of folk psychology, can benefit from being more explicitly informed by music cognition studies. We give examples from work in the computational modelling of music cognition, following our approach, which attempts to place each musical phenomenon in an ecological context motivated by evolutionary considerations, and which aims to explain musical phenomena independently of the explicit intervention of the theorist. We argue that only thus can a theory be said veridically to explicate the phenomenology of music. We place our argument in context of the Generative Theory of Tonal Music (Lerdahl \& Jackendoff, 1983), Generative Linguistics, and other papers in the current volume, and compare them all with results of modelling studies based on our espoused approach.},
	language = {en},
	number = {1\_suppl},
	urldate = {2019-10-15},
	journal = {Musicae Scientiae},
	author = {Wiggins, Geraint A. and Müllensiefen, Daniel and Pearce, Marcus T.},
	month = mar,
	year = {2010},
	keywords = {Comps, Comps\_Q5},
	pages = {231--255}
}

@article{weis_investigating_2018,
	title = {Investigating {Style} {Evolution} of {Western} {Classical} {Music}: {A} {Computational} {Approach}},
	issn = {1029-8649},
	shorttitle = {Investigating style evolution of {Western} classical music},
	url = {https://doi.org/10.1177/1029864918757595},
	doi = {10.1177/1029864918757595},
	abstract = {In musicology, there has been a long debate about a meaningful partitioning and description of music history regarding composition styles. Particularly, concepts of historical periods have been criticized since they cannot account for the continuous and interwoven evolution of style. To systematically study this evolution, large corpora are necessary suggesting the use of computational strategies. This article presents such strategies and experiments relying on a dataset of 2000 audio recordings, which cover more than 300 years of music history. From the recordings, we extract different tonal features. We propose a method to visualize these features over the course of history using evolution curves. With the curves, we re-trace hypotheses concerning the evolution of chord transitions, intervals, and tonal complexity. Furthermore, we perform unsupervised clustering of recordings across composition years, individual pieces, and composers. In these studies, we found independent evidence of historical periods that broadly agrees with traditional views as well as recent data-driven experiments. This shows that computational experiments can provide novel insights into the evolution of styles.},
	language = {en},
	urldate = {2019-08-06},
	journal = {Musicae Scientiae},
	author = {Weiß, Christof and Mauch, Matthias and Dixon, Simon and Müller, Meinard},
	month = mar,
	year = {2018},
	keywords = {Comps, Comps\_Q5},
	pages = {1029864918757595}
}

@book{piston_harmony_1987,
	address = {New York},
	edition = {5th ed},
	title = {Harmony},
	isbn = {978-0-393-95480-7},
	publisher = {Norton},
	author = {Piston, Walter and DeVoto, Mark},
	year = {1987},
	keywords = {Comps, Comps\_Q5, Comps\_Q6, Comps\_Q6\_Theory}
}

@article{ni_understanding_2013,
	title = {Understanding {Effects} of {Subjectivity} in {Measuring} {Chord} {Estimation} {Accuracy}},
	volume = {21},
	issn = {1558-7916},
	doi = {10.1109/TASL.2013.2280218},
	abstract = {To assess the performance of an automatic chord estimation system, reference annotations are indispensable. However, owing to the complexity of music and the sometimes ambiguous harmonic structure of polyphonic music, chord annotations are inherently subjective, and as a result any derived accuracy estimates will be subjective as well. In this paper, we investigate the extent of the confounding effect of subjectivity in reference annotations. Our results show that this effect is important, and they affect different types of automatic chord estimation systems in different ways. Our results have implications for research on automatic chord estimation, but also on other fields that evaluate performance by comparing against human provided annotations that are confounded by subjectivity.},
	number = {12},
	journal = {IEEE Transactions on Audio, Speech, and Language Processing},
	author = {Ni, Y. and McVicar, M. and Santos-Rodríguez, R. and Bie, T. De},
	month = dec,
	year = {2013},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Dataset},
	pages = {2607--2615}
}

@book{kostka_tonal_2018,
	address = {New York, NY},
	edition = {Eighth edition},
	title = {Tonal harmony: with an introduction to post-tonal music},
	isbn = {978-1-259-44709-9 978-1-259-25356-0},
	shorttitle = {Tonal harmony},
	publisher = {McGraw-Hill Education},
	author = {Kostka, Stefan M. and Payne, Dorothy and Almén, Byron},
	year = {2018},
	keywords = {Comps, Comps\_Q6, Comps\_Q6\_Theory}
}

@book{huron_voice_2016,
	address = {Cambridge, Massachusetts},
	title = {Voice {Leading}: {The} {Science} {Behind} the {Musical} {Art}},
	isbn = {978-0-262-03485-2},
	shorttitle = {Voice leading},
	publisher = {MIT Press},
	author = {Huron, David B.},
	year = {2016},
	keywords = {Comps, Comps\_Unidentified}
}

@article{hewlett_computing_1991,
	title = {Computing in {Musicology}},
	volume = {25},
	issn = {1572-8412},
	url = {https://doi.org/10.1007/BF00141188},
	doi = {10.1007/BF00141188},
	abstract = {While there are many parallels between computing activities in musicology and those in other humanities disciplines, the particular nature of musical material and the ways in which this must be accommodated set many activities apart from those in text-based disciplines. As in other disciplines, early applications were beset by hardware constraints, which placed a premium on expertise and promoted design-intensive projects. Massive musical encoding and bibliographical projects were initiated. Diversification of hardware platforms and languages in the Seventies led to task-specific undertakings, including preliminary work on many of today's programs for music printing and analysis. The rise of personal computers and associated general-purpose software in the Eighties has enabled many scholars to pursue projects individually, particularly with the assistance of database, word processing, and notation software. Current issues facing the field include the need for standards for data interchange, the creation of banks of reusable data, the establishment of qualitative standards for encoded data, and the encouragement of realistic appraisals of what computers can do.The musicologist Eleanor Selfridge-Field, who is the author of three books on Italian music and numerous articles, editions, and reviews, has worked at CCARH since its founding in 1984. Her most recent book, The Music of Benedetto and Alessandro Marcello (Oxford: Clarendon Press, 1990), which contains 1300 musical examples, was produced from camera-ready copy supplied by CCARH.Drs. Hewlett and Selfridge-Field jointly edit the series Computing in Musicology, which is published by CCARH, and co-chair the International Musicological Society's Study Group on Musical Data and Computer Applications.},
	language = {en},
	number = {6},
	urldate = {2019-09-16},
	journal = {Computers and the Humanities},
	author = {Hewlett, Walter B. and Selfridge-Field, Eleanor},
	month = dec,
	year = {1991},
	keywords = {Comps, Comps\_Q5},
	pages = {381--392}
}

@article{everett_making_2004,
	title = {Making {Sense} of {Rock}’s {Tonal} {Systems}},
	volume = {10},
	url = {https://www.mtosmt.org/issues/mto.04.10.4/mto.04.10.4.w_everett.html},
	language = {en},
	number = {4},
	urldate = {2019-08-05},
	journal = {Music Theory Online},
	author = {Everett, Walter},
	month = dec,
	year = {2004},
	keywords = {Comps, Comps\_Q5}
}

@inproceedings{chew_spiral_2002,
	title = {The {Spiral} {Array}: {An} {Algorithm} for {Determining} {Key} {Boundaries}},
	shorttitle = {The spiral array},
	booktitle = {International {Conference} on {Music} and {Artificial} {Intelligence}},
	publisher = {Springer},
	author = {Chew, Elaine},
	year = {2002},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic, Comps\_Q3\_Unidentified, Comps\_Q5, Comps\_Summarized},
	pages = {18--31}
}

@phdthesis{chew_towards_2000,
	type = {{PhD} {Thesis}},
	title = {Towards a mathematical model of tonality},
	copyright = {M.I.T. theses are protected by copyright. They may be viewed from this source for any purpose, but reproduction or distribution in any format is prohibited without written permission. See provided URL for inquiries about permission.},
	url = {https://dspace.mit.edu/handle/1721.1/9139},
	abstract = {This dissertation addresses the question of how musical pitches generate a tonal center. Being able to characterize the relationships that generate a tonal center is crucial to the computer analysis and the generating of western tonal music. It also can inform issues of compositional styles, structural boundaries, and performance decisions. The proposed Spiral Array model offers a parsimonious description of the inter-relations among tonal elements, and suggests new ways to re-conceptualize and reorganize musical information. The Spiral Array generates representations for pitches, intervals, chords and keys within a single spatial framework, allowing comparisons among elements from different hierarchical levels. Structurally, this spatial representation is a helical realization of the harmonic network (tonnetz). The basic idea behind the Spiral Array is the representation of higher level tonal elements as composites of their lower level parts. The Spiral Array assigns greatest prominence to perfect fifth and major /minor third interval relations, placing elements related by these intervals in proximity to each other. As a result, distances between tonal entities as represented spatially in the model correspond to perceived distances among sounding entities. The parameter values that affect proximity relations are prescribed based on a few perceived relations among pitches, intervals, chords and keys. This process of interfacing between the model and actual perception creates the opportunity to research some basic, but till now unanswered questions about the relationships that generate tonality. A generative model, the Spiral Array case; provides a framework on which to design viable and efficient algorithms for problems in music cognition. I demonstrate its versatility by applying the model to three different problems: I develop an algorithm to determine the key of musical passages that, on average, performs better than existing ones when applied to the 24 fugue subjects in Book I of Bach's WTC; I propose the first computationally viable method for determining modulations (the change of key); and, I design a basic algorithm for finding the roots of chords, comparing its results to those of algorithms by other researchers. All three algorithms were implemented in Matlab.},
	language = {eng},
	urldate = {2019-08-05},
	school = {Massachusetts Institute of Technology},
	author = {Chew, Elaine},
	year = {2000},
	keywords = {Comps, Comps\_Q5}
}

@inproceedings{aucouturier_mel_2012,
	address = {Porto, Portugal},
	title = {Mel {Cepstrum} \& {Ann} {Ova}: {The} {Difficult} {Dialog} {Between} {MIR} and {Music} {Cognition}.},
	url = {https://doi.org/10.5281/zenodo.1417179},
	doi = {10.5281/zenodo.1417179},
	booktitle = {Proceedings of the 13th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Aucouturier, Jean-Julien and Bigand, Emmanuel},
	month = oct,
	year = {2012},
	keywords = {Comps, Comps\_Q5, Comps\_Q8},
	pages = {397--402}
}

@article{agmon_functional_1995,
	title = {Functional {Harmony} {Revisited}: {A} {Prototype}-{Theoretic} {Approach}},
	volume = {17},
	issn = {0195-6167},
	shorttitle = {Functional {Harmony} {Revisited}},
	url = {https://academic.oup.com/mts/article/17/2/196/1031187},
	doi = {10.2307/745871},
	abstract = {Abstract.  From a prototype-theoretic point of view the three harmonic functions known as tonic, subdominant, and dominant are three (partially-overlapping) cho},
	language = {en},
	number = {2},
	urldate = {2019-08-04},
	journal = {Music Theory Spectrum},
	author = {Agmon, Eytan},
	month = oct,
	year = {1995},
	keywords = {Comps, Comps\_Unidentified},
	pages = {196--214}
}

@article{longuet-higgins_perception_1976,
	title = {Perception of melodies},
	volume = {263},
	copyright = {1976 Nature Publishing Group},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/263646a0},
	doi = {10.1038/263646a0},
	abstract = {A computer program has been written which will transcribe a live performance of a classical melody into the equivalent of standard musical notation. It is intended to embody, in computational form, a psychological theory of how Western musicians perceive the rhythmic and tonal relationships between the notes of such melodies.},
	language = {en},
	number = {5579},
	urldate = {2019-11-14},
	journal = {Nature},
	author = {Longuet-Higgins, H. C.},
	month = oct,
	year = {1976},
	keywords = {Comps, Comps\_Q7},
	pages = {646--653}
}

@inproceedings{el_hihi_hierarchical_1995,
	address = {Cambridge, MA, USA},
	series = {{NIPS}'95},
	title = {Hierarchical {Recurrent} {Neural} {Networks} for {Long}-term {Dependencies}},
	url = {http://dl.acm.org/citation.cfm?id=2998828.2998898},
	abstract = {We have already shown that extracting long-term dependencies from sequential data is difficult, both for determimstic dynamical systems such as recurrent networks, and probabilistic models such as hidden Markov models (HMMs) or input/output hidden Markov models (IOHMMs). In practice, to avoid this problem, researchers have used domain specific a-priori knowledge to give meaning to the hidden or state variables representing past context. In this paper, we propose to use a more general type of a-priori knowledge, namely that the temporal dependencies are structured hierarchically. This implies that long-term dependencies are represented by variables with a long time scale. This principle is applied to a recurrent network which includes delays and multiple time scales. Experiments confirm the advantages of such structures. A similar approach is proposed for HMMs and IOHMMs.},
	urldate = {2019-11-13},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {MIT Press},
	author = {El Hihi, Salah and Bengio, Yoshua},
	year = {1995},
	note = {event-place: Denver, Colorado},
	keywords = {Comps, Comps\_Q9},
	pages = {493--499}
}

@book{jaeger_long_2012,
	series = {Jacobs {University} {Technical} {Reports}},
	title = {Long {Short}-{Term} {Memory} in {Echo} {State} {Networks}: {Details} of a {Simulation} {Study}},
	number = {27},
	author = {Jaeger, Herbert},
	year = {2012},
	keywords = {Comps, Comps\_Q9}
}

@article{yildiz_re-visiting_2012,
	title = {Re-visiting the echo state property},
	volume = {35},
	issn = {0893-6080},
	url = {http://www.sciencedirect.com/science/article/pii/S0893608012001852},
	doi = {10.1016/j.neunet.2012.07.005},
	abstract = {An echo state network (ESN) consists of a large, randomly connected neural network, the reservoir, which is driven by an input signal and projects to output units. During training, only the connections from the reservoir to these output units are learned. A key requisite for output-only training is the echo state property (ESP), which means that the effect of initial conditions should vanish as time passes. In this paper, we use analytical examples to show that a widely used criterion for the ESP, the spectral radius of the weight matrix being smaller than unity, is not sufficient to satisfy the echo state property. We obtain these examples by investigating local bifurcation properties of the standard ESNs. Moreover, we provide new sufficient conditions for the echo state property of standard sigmoid and leaky integrator ESNs. We furthermore suggest an improved technical definition of the echo state property, and discuss what practicians should (and should not) observe when they optimize their reservoirs for specific tasks.},
	language = {en},
	urldate = {2019-11-13},
	journal = {Neural Networks},
	author = {Yildiz, Izzet B. and Jaeger, Herbert and Kiebel, Stefan J.},
	month = nov,
	year = {2012},
	keywords = {Comps, Comps\_Q9},
	pages = {1--9}
}

@article{bengio_learning_1994,
	title = {Learning long-term dependencies with gradient descent is difficult},
	volume = {5},
	issn = {1045-9227, 1941-0093},
	doi = {10.1109/72.279181},
	abstract = {Recurrent neural networks can be used to map input sequences to output sequences, such as for recognition, production or prediction problems. However, practical difficulties have been reported in training recurrent neural networks to perform tasks in which the temporal contingencies present in the input/output sequences span long intervals. We show why gradient based learning algorithms face an increasingly difficult problem as the duration of the dependencies to be captured increases. These results expose a trade-off between efficient learning by gradient descent and latching on information for long periods. Based on an understanding of this problem, alternatives to standard gradient descent are considered.{\textless}{\textgreater}},
	number = {2},
	journal = {IEEE Transactions on Neural Networks},
	author = {Bengio, Y. and Simard, P. and Frasconi, P.},
	month = mar,
	year = {1994},
	keywords = {Comps, Comps\_Q9},
	pages = {157--166}
}

@book{goodfellow_deep_2016,
	address = {Cambridge, Massachusetts},
	series = {Adaptive computation and machine learning},
	title = {Deep learning},
	isbn = {978-0-262-03561-3},
	publisher = {The MIT Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	year = {2016},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_ANN, Comps\_Q9}
}

@inproceedings{papadopoulos_simultaneous_2008,
	title = {Simultaneous estimation of chord progression and downbeats from an audio file},
	doi = {10.1109/ICASSP.2008.4517561},
	abstract = {Harmony and metrical structure are some of the most important attributes of Western tonal music. In this paper, we present a new method for simultaneously estimating the chord progression and the downbeats from an audio file. For this, we propose a specific topology of hidden Markov models that allows us to model chords dependency on metrical structure. The model is evaluated on a dataset of 66 popular music songs from the Beatles and shows improvement over the state of the art.},
	booktitle = {2008 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing}},
	author = {Papadopoulos, Helene and Peeters, Geoffroy},
	month = mar,
	year = {2008},
	note = {ISSN: 1520-6149, 2379-190X},
	keywords = {Comps, Comps\_Unidentified},
	pages = {121--124}
}

@inproceedings{purwins_new_2000,
	title = {A new method for tracking modulations in tonal music in audio data format},
	volume = {6},
	doi = {10.1109/IJCNN.2000.859408},
	abstract = {Cq-profiles are 12-dimensional vectors, each component referring to a pitch class. They can be employed to represent keys. Cq-profiles are calculated with the constant Q filter bank. They have the following advantages: 1) they correspond to probe tone ratings; 2) calculation is possible in real-time; 3) stability is obtained with respect to sound quality; and 4) they are transposable. By using the cq-profile technique as a simple auditory model in combination with the SOM, an arrangement of keys emerges, that resembles results from psychological experiments and from the music theory. Cq-profiles are reliably applied to modulation tracking by introducing a special distance measure.},
	booktitle = {Proceedings of the {IEEE}-{INNS}-{ENNS} {International} {Joint} {Conference} on {Neural} {Networks}. {IJCNN} 2000. {Neural} {Computing}: {New} {Challenges} and {Perspectives} for the {New} {Millennium}},
	author = {Purwins, H. and Blankertz, B. and Obermayer, K.},
	month = jul,
	year = {2000},
	note = {ISSN: 1098-7576},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Q5, Comps\_Q6, Comps\_Q6\_MIR, Comps\_Skimmed, Comps\_Summarized},
	pages = {270--275 vol.6}
}

@phdthesis{budge_study_1943,
	address = {New York},
	title = {A study of chord frequencies based on the music of representative composers of the eighteenth and nineteenth centuries,},
	language = {English},
	school = {Teachers college, Columbia University},
	author = {Budge, Helen},
	year = {1943},
	note = {OCLC: 3300662},
	keywords = {Comps}
}

@inproceedings{shenoy_key_2004,
	title = {Key determination of acoustic musical signals},
	volume = {3},
	doi = {10.1109/ICME.2004.1394598},
	abstract = {The work presents a novel rule-based approach for determining the key of acoustic musical signals. Knowledge of the key enables to be derived, from music knowledge, the pitch class elements that a piece of music uses. Our technique is a combination of chroma based frequency analysis and music knowledge of rhythm structure and chord change patterns followed by rule-based inference. Experimental results illustrate that 90\% accuracy is achieved for key determination and we have given an explanation for the cases that have generated an incorrect key. Steps for further development are also outlined.},
	booktitle = {2004 {IEEE} {International} {Conference} on {Multimedia} and {Expo} ({ICME}) ({IEEE} {Cat}. {No}.{04TH8763})},
	author = {Shenoy, A. and Mohapatra, R. and Ye Wang},
	month = jun,
	year = {2004},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey},
	pages = {1771--1774 Vol.3}
}

@inproceedings{arndt_circular_2008,
	title = {Circular {Pitch} {Space} {Based} {Musical} {Tonality} {Analysis}},
	url = {http://www.aes.org/e-lib/browse.cfm?elib=14521},
	abstract = {The focus of this paper is to give an overview of existing circular pitch spaces, its special properties and application for semantic audio analysis. Beside this the symmetry model is proposed as a framework to describe the inter-model relationships between different circular pitch spaces. Similar to color spaces in vision musical pitch spaces organize pitches in a way that semantic/cognitive/theoretical/physical relationships between tones become geometrically apparent. Within the last years...},
	language = {English},
	urldate = {2019-11-13},
	publisher = {Audio Engineering Society},
	author = {Arndt, Daniel and Brandenburg, Karlheinz and Gatzsche, Gabriel and Mehnert, Markus},
	month = may,
	year = {2008},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey}
}

@inproceedings{zhu_music_2005,
	title = {Music {Key} {Detection} for {Musical} {Audio}},
	doi = {10.1109/MMMC.2005.56},
	abstract = {The key or the scale information of a piece of music provides important clues on its high level musical content, like harmonic and melodic context, which can be useful for music classification, retrieval or further content analysis. Researchers have previously addressed the issue of finding the key for symbolically encoded music (MIDI); however, very little work has been done on key detection for acoustic music. In this paper, we present a method for estimating the root of diatonic scale and the key directly from acoustic signals (waveform) of popular and classical music. We propose a method to extract pitch profile features from the audio signal, which characterizes the tone distribution in the music. The diatonic scale root and key are estimated based on the extracted pitch profile by using a tone clustering algorithm and utilizing the tone structure of keys. Experiments on 72 music pieces have been conducted to evaluate the proposed techniques. The success rate of scale root detection for pop music pieces is above 90\%.},
	booktitle = {11th {International} {Multimedia} {Modelling} {Conference}},
	author = {Zhu, Yongwei and Kankanhalli, M.S. and Gao, Sheng},
	month = jan,
	year = {2005},
	note = {ISSN: 1550-5502},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey},
	pages = {30--37}
}

@article{martens_tree-based_2005,
	title = {Tree-based versus distance-based key recognition in musical audio},
	volume = {9},
	issn = {1433-7479},
	url = {https://doi.org/10.1007/s00500-004-0374-7},
	doi = {10.1007/s00500-004-0374-7},
	abstract = {A tree-based method for the recognition of the tonal center or key in a musical audio signal is presented. Time-varying key feature vectors of 264 synthesized sounds are extracted from an auditory-based pitch model and converted into character strings using PCA-analysis and classification trees. The results are compared with distance-based methods. The characteristics of the new tonality analysis tool are illustrated on various examples. The potential of this method as a building stone in a music retrieval system is discussed.},
	language = {en},
	number = {8},
	urldate = {2019-11-13},
	journal = {Soft Computing},
	author = {Martens, G. and De Meyer, H. and De Baets, B. and Leman, M. and Lesaffre, M. and Martens, J.-P.},
	month = aug,
	year = {2005},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey},
	pages = {565--574}
}

@inproceedings{cheng_automatic_2008,
	address = {Hannover, Germany},
	title = {Automatic chord recognition for music classification and retrieval},
	doi = {10.1109/ICME.2008.4607732},
	abstract = {As one of the most important mid-level features of music, chord contains rich information of harmonic structure that is useful for music information retrieval. In this paper, we present a chord recognition system based on the N-gram model. The system is time-efficient, and its accuracy is comparable to existing systems. We further propose a new method to construct chord features for music emotion classification and evaluate its performance on commercial song recordings. Experimental results demonstrate the advantage of using chord features for music classification and retrieval.},
	booktitle = {2008 {IEEE} {International} {Conference} on {Multimedia} and {Expo}},
	author = {Cheng, Heng-Tze and Yang, Yi-Hsuan and Lin, Yu-Ching and Liao, I-Bin and Chen, Homer H.},
	month = jun,
	year = {2008},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey},
	pages = {1505--1508}
}

@book{temperley_music_2007,
	address = {Cambridge, Mass},
	title = {Music and probability},
	isbn = {978-0-262-20166-7},
	publisher = {MIT Press},
	author = {Temperley, David},
	year = {2007},
	note = {OCLC: ocm68373527},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic}
}

@article{yoshino_cognitive_2004,
	title = {Cognitive modeling of key interpretation in melody perception},
	volume = {46},
	number = {4},
	journal = {Japanese Psychological Research},
	author = {Yoshino, Iwao and Abe, Jun-Ichi},
	year = {2004},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic},
	pages = {283--297}
}

@inproceedings{madsen_key-finding_2007,
	title = {Key-{Finding} with {Interval} {Profiles}},
	url = {http://hdl.handle.net/2027/spo.bbp2372.2007.155},
	booktitle = {Proceedings of the 2007 {International} {Computer} {Music} {Conference}, {ICMC} 2007, {Copenhagen}, {Denmark}, {August} 27-31, 2007},
	author = {Madsen, Søren Tjagvad and Widmer, Gerhard},
	year = {2007},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic}
}

@article{krumhansl_quantification_1979,
	title = {Quantification of the hierarchy of tonal functions within a diatonic context},
	volume = {5},
	issn = {1939-1277(Electronic),0096-1523(Print)},
	doi = {10.1037/0096-1523.5.4.579},
	abstract = {24 undergraduates rated test tones in the octave range from middle to high C according to how well each completed a diatonic C major scale played in an adjacent octave just before the final test tone. Ratings were well explained in terms of 3 factors: distance in pitch height from the context tones, octave equivalence, and a hierarchy of tonal functions (tonic tone, other tones of the major triad chord, other tones of the diatonic scale, and the nondiatonic tones). In these ratings, pitch height was more prominent for less musical listeners or with less musical (sinusoidal) tones, whereas octave equivalence and the tonal hierarchy prevailed for musical listeners, especially with harmonically richer tones. In a 2nd experiment with 8 undergraduates, ratings for quarter tones interpolated halfway between the halftone steps of the standard chromatic scale were approximately the averages of ratings for adjacent chromatic tones, suggesting failure to discriminate tones at this fine level of division. (56 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {4},
	journal = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {Krumhansl, Carol L. and Shepard, Roger N.},
	year = {1979},
	keywords = {Comps, Comps\_Q3, Comps\_Q8},
	pages = {579--594}
}

@article{schmuckler_perceptual_2005,
	title = {Perceptual {Tests} of an {Algorithm} for {Musical} {Key}-{Finding}.},
	volume = {31},
	issn = {1939-1277},
	url = {https://psycnet.apa.org/fulltext/2005-13471-022.pdf},
	doi = {10.1037/0096-1523.31.5.1124},
	number = {5},
	urldate = {2019-08-05},
	journal = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {Schmuckler, Mark A. and Tomovski, Robert},
	year = {2005},
	keywords = {Comps, Comps\_Q3, Comps\_Q8, Comps\_Read, Comps\_Summarized},
	pages = {1124}
}

@inproceedings{schluter_exploring_2015,
	address = {Málaga, Spain},
	title = {Exploring {Data} {Augmentation} for {Improved} {Singing} {Voice} {Detection} with {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1417745},
	doi = {10.5281/zenodo.1417745},
	booktitle = {Proceedings of the 16th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Schlüter, Jan and Grill, Thomas},
	month = oct,
	year = {2015},
	keywords = {Comps, Comps\_Q3\_Evaluation, Comps\_Q4, Comps\_Q4\_AudioDegradation},
	pages = {121--126}
}

@book{krumhansl_cognitive_1990,
	address = {New York, NY, US},
	series = {Cognitive foundations of musical pitch},
	title = {Cognitive foundations of musical pitch},
	isbn = {978-0-19-505475-0 978-0-19-514836-7},
	abstract = {Cognitive Foundations of Musical Pitch considers the problem of how listeners encode, organize, and remember pitch patterns in music. The work seeks to explicate the nature of listeners' knowledge of how pitch structures are formed, identify musical properties that shape this knowledge, and characterize the process through which sequences of sounds become coherent, memorable, and meaningful. The approach taken is that of cognitive psychology, in which laboratory methods examine the nature of mental representations and processes. Previous publications have described a number of the studies. They are summarized here together with new results, allowing richer connections to be drawn between the empirical findings. Theoretical and methodological issues surrounding the laboratory studies are also examined. The experiments focus primarily on pitch structures in traditional Western music. This choice of focus is based on the large corpus of literature in music theory that deals with this style. This literature has been important for designing the experimental materials and interpreting the results. A number of studies extend the methods to music outside this tradition. Throughout, care has been taken to provide adequate background in experimental methods and music theory so that no special background is needed to follow the major arguments. However, the reader will naturally discover certain topics to be of greater interest than others depending on his or her special expertise. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	publisher = {Oxford University Press},
	author = {Krumhansl, Carol L.},
	year = {1990},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic, Comps\_Q5, Comps\_Q6, Comps\_Q6\_Theory, Comps\_Q8}
}

@inproceedings{gatzsche_symmetry_2007,
	address = {Vienna, Austria},
	title = {A {Symmetry} {Based} {Approach} for {Musical} {Tonality} {Analysis}.},
	url = {https://doi.org/10.5281/zenodo.1416214},
	doi = {10.5281/zenodo.1416214},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Gatzsche, Gabriel and Mehnert, Markus and Gatzsche, David and Brandenburg, Karlheinz},
	month = sep,
	year = {2007},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic, Comps\_Q3\_Unidentified},
	pages = {207--210}
}

@article{dawson_key-finding_2018,
	title = {Key-{Finding} by {Artificial} {Neural} {Networks} {That} {Learn} about {Key} {Profiles}},
	volume = {72},
	issn = {1878-7290(Electronic),1196-1961(Print)},
	doi = {10.1037/cep0000135},
	abstract = {We explore the ability of a very simple artificial neural network, a perceptron, to assert the musical key of novel stimuli. First, perceptrons are trained to associate standardized key profiles (taken from 1 of 3 different sources) to different musical keys. After training, we measured perceptron accuracy in asserting musical keys for 296 novel stimuli. Depending upon which key profiles were used during training, perceptrons can perform as well as established key-finding algorithms on this task. Further analyses indicate that perceptrons generate higher activity in a unit representing a selected key and much lower activities in the units representing the competing keys that are not selected than does a traditional algorithm. Finally, we examined the internal structure of trained perceptrons and discovered that they, unlike traditional algorithms, assign very different weights to different components of a key profile. Perceptrons learn that some profile components are more important for specifying musical key than are others. These differential weights could be incorporated into traditional algorithms that do not themselves employ artificial neural networks. (PsycINFO Database Record (c) 2018 APA, all rights reserved)},
	number = {3},
	journal = {Canadian Journal of Experimental Psychology/Revue canadienne de psychologie expérimentale},
	author = {Dawson, Michael R. W. and Zielinski, Jasen A. Z.},
	year = {2018},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_Key, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_ToDo},
	pages = {153--170}
}

@inproceedings{bernardes_automatic_2017,
	address = {New Orleans, USA},
	title = {Automatic {Musical} {Key} {Estimation} with {Adaptive} {Mode} {Bias}},
	booktitle = {2017 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	publisher = {IEEE},
	author = {Bernardes, Gilberto and Davies, Matthew EP and Guedes, Carlos},
	year = {2017},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey},
	pages = {316--320}
}
@inproceedings{henaff_unsupervised_2011,
	address = {Miami, United States},
	title = {Unsupervised {Learning} of {Sparse} {Features} for {Scalable} {Audio} {Classification}.},
	url = {https://doi.org/10.5281/zenodo.1416086},
	doi = {10.5281/zenodo.1416086},
	booktitle = {Proceedings of the 12th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Henaff, Mikael and Jarrett, Kevin and Kavukcuoglu, Koray and LeCun, Yann},
	month = oct,
	year = {2011},
	keywords = {Comps, Comps\_Unidentified},
	pages = {681--686}
}

@misc{shalev-shwartz_understanding_2014,
	title = {Understanding {Machine} {Learning}: {From} theory to algorithms},
	url = {/core/books/understanding-machine-learning/3059695661405D25673058E43C8BE2A6},
	abstract = {Cambridge Core - Algorithmics, Complexity, Computer Algebra, Computational Geometry - Understanding Machine Learning -  by Shai Shalev-Shwartz},
	language = {en},
	urldate = {2019-09-23},
	journal = {Cambridge Core},
	author = {Shalev-Shwartz, Shai and Ben-David, Shai},
	month = may,
	year = {2014},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_ANN}
}

@inproceedings{hajic_towards_2018,
	address = {Paris, France},
	title = {Towards {Full}-{Pipeline} {Handwritten} {OMR} with {Musical} {Symbol} {Detection} by {U}-{Nets}},
	url = {https://doi.org/10.5281/zenodo.1492389},
	doi = {10.5281/zenodo.1492389},
	booktitle = {Proceedings of the 19th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Hajič, Jan and Dorfer, Matthias and Widmer, Gerhard and Pecina, Pavel},
	month = sep,
	year = {2018},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_OMR, Comps\_Q2\_UNet, Comps\_ToDo},
	pages = {225--232}
}

@article{werbos_generalization_1988,
	title = {Generalization of backpropagation with application to a recurrent gas market model},
	volume = {1},
	issn = {0893-6080},
	url = {http://www.sciencedirect.com/science/article/pii/089360808890007X},
	doi = {10.1016/0893-6080(88)90007-X},
	abstract = {Backpropagation is often viewed as a method for adapting artificial neural networks to classify patterns. Based on parts of the book by Rumelhart and colleagues, many authors equate backpropagation with the generalized delta rule applied to fully-connected feedforward networks. This paper will summarize a more general formulation of backpropagation, developed in 1974, which does more justice to the roots of the method in numerical analysis and statistics, and also does more justice to creative approaches expressed by neural modelers in the past year or two. It will discuss applications of backpropagation to forecasting over time (where errors have been halved by using methods other than least squares), to optimization, to sensitivity analysis, and to brain research. This paper will go on to derive a generalization of backpropagation to recurrent systems (which input their own output), such as hybrids of perceptron-style networks and Grossberg/Hopfield networks. Unlike the proposal of Rumelhart, Hinton, and Williams, this generalization does not require the storage of intermediate iterations to deal with continuous recurrence. This generalization was applied in 1981 to a model of natural gas markets, where it located sources of forecast uncertainty related to the use of least squares to estimate the model parameters in the first place.},
	language = {en},
	number = {4},
	urldate = {2019-11-11},
	journal = {Neural Networks},
	author = {Werbos, Paul J.},
	month = jan,
	year = {1988},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_History, Comps\_Q9},
	pages = {339--356}
}

@inproceedings{de_reuse_robust_2019,
	address = {Delft, The Netherlands},
	title = {Robust {Transcript} {Alignment} on {Medieval} {Chant} {Manuscripts}},
	url = {https://sites.google.com/view/worms2019/proceedings},
	booktitle = {2nd {International} {Workshop} on {Reading} {Music} {Systems}},
	author = {de Reuse, Timothy and Fujinaga, Ichiro},
	editor = {Calvo-Zaragoza, Jorge and Pacha, Alexander},
	year = {2019},
	keywords = {ISMIR2019, ReadLater, WoRMS2019},
	pages = {21--26}
}

@incollection{lecun_generalization_1989,
	title = {Generalization and network design strategies},
	language = {English (US)},
	booktitle = {Connectionism in perspective},
	publisher = {Elsevier},
	author = {Lecun, Yann},
	editor = {Pfeifer, R. and Schreter, Z. and Fogelman, F. and Steels, L.},
	year = {1989},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_History}
}

@article{le_cun_handwritten_1989,
	title = {Handwritten digit recognition: applications of neural network chips and automatic learning},
	volume = {27},
	issn = {0163-6804, 1558-1896},
	shorttitle = {Handwritten digit recognition},
	doi = {10.1109/35.41400},
	abstract = {Two novel methods for achieving handwritten digit recognition are described. The first method is based on a neural network chip that performs line thinning and feature extraction using local template matching. The second method is implemented on a digital signal processor and makes extensive use of constrained automatic learning. Experimental results obtained using isolated handwritten digits taken from postal zip codes, a rather difficult data set, are reported and discussed.{\textless}{\textgreater}},
	number = {11},
	journal = {IEEE Communications Magazine},
	author = {Le Cun, Y. and Jackel, L.D. and Boser, B. and Denker, J.S. and Graf, H.P. and Guyon, I. and Henderson, D. and Howard, R.E. and Hubbard, W.},
	month = nov,
	year = {1989},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_History},
	pages = {41--46}
}

@article{hinton_fast_2006,
	title = {A {Fast} {Learning} {Algorithm} for {Deep} {Belief} {Nets}},
	volume = {18},
	issn = {0899-7667},
	url = {http://dx.doi.org/10.1162/neco.2006.18.7.1527},
	doi = {10.1162/neco.2006.18.7.1527},
	number = {7},
	journal = {Neural Comput.},
	author = {Hinton, Geoffrey E. and Osindero, Simon and Teh, Yee-Whye},
	month = jul,
	year = {2006},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_History},
	pages = {1527--1554}
}

@article{rumelhart_learning_1988,
	title = {Learning representations by back-propagating errors},
	volume = {5},
	number = {3},
	journal = {Cognitive modeling},
	author = {Rumelhart, David E and Hinton, Geoffrey E and Williams, Ronald J and {others}},
	year = {1988},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_History},
	pages = {1}
}

@book{minsky_perceptrons:_1972,
	address = {Cambridge/Mass.},
	edition = {2. print. with corr},
	title = {Perceptrons: an introduction to computational geometry},
	isbn = {978-0-262-63022-1 978-0-262-13043-1},
	shorttitle = {Perceptrons},
	language = {eng},
	publisher = {The MIT Press},
	author = {Minsky, Marvin and Papert, Seymour A.},
	year = {1972},
	note = {OCLC: 833070641},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_History}
}

@techreport{widrow_adaptive_1960,
	title = {Adaptive switching circuits},
	institution = {Stanford University},
	author = {Widrow, Bernard and Hoff, Marcian E},
	year = {1960},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_History}
}

@article{mcculloch_logical_1943,
	title = {A logical calculus of the ideas immanent in nervous activity},
	volume = {5},
	issn = {1522-9602},
	url = {https://doi.org/10.1007/BF02478259},
	doi = {10.1007/BF02478259},
	abstract = {Because of the “all-or-none” character of nervous activity, neural events and the relations among them can be treated by means of propositional logic. It is found that the behavior of every net can be described in these terms, with the addition of more complicated logical means for nets containing circles; and that for any logical expression satisfying certain conditions, one can find a net behaving in the fashion it describes. It is shown that many particular choices among possible neurophysiological assumptions are equivalent, in the sense that for every net behaving under one assumption, there exists another net which behaves under the other and gives the same results, although perhaps not in the same time. Various applications of the calculus are discussed.},
	language = {en},
	number = {4},
	urldate = {2019-11-06},
	journal = {The bulletin of mathematical biophysics},
	author = {McCulloch, Warren S. and Pitts, Walter},
	month = dec,
	year = {1943},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_History},
	pages = {115--133}
}

@inproceedings{rios-vila_readsco:_2019,
	address = {Delft, The Netherlands},
	title = {{ReadSco}: {An} {Open}-{Source} {Web}-{Based} {Optical} {Music} {Recognition} {Tool}},
	url = {https://sites.google.com/view/worms2019/proceedings},
	booktitle = {2nd {International} {Workshop} on {Reading} {Music} {Systems}},
	author = {Ríos-Vila, Antonio and Calvo-Zaragoza, Jorge and Rizo, David and Iñesta, José M.},
	editor = {Calvo-Zaragoza, Jorge and Pacha, Alexander},
	year = {2019},
	keywords = {ISMIR2019, ReadLater, WoRMS2019},
	pages = {27--30}
}

@inproceedings{pacha_incremental_2019,
	address = {Delft, The Netherlands},
	title = {Incremental {Supervised} {Staff} {Detection}},
	url = {https://sites.google.com/view/worms2019/proceedings},
	booktitle = {2nd {International} {Workshop} on {Reading} {Music} {Systems}},
	author = {Pacha, Alexander},
	editor = {Calvo-Zaragoza, Jorge and Pacha, Alexander},
	year = {2019},
	keywords = {ISMIR2019, ReadLater, WoRMS2019},
	pages = {16--20}
}

@inproceedings{wick_ommr4all_2019,
	address = {Delft, The Netherlands},
	title = {{OMMR4all} — a {Semiautomatic} {Online} {Editor} for {Medieval} {Music} {Notations}},
	url = {https://sites.google.com/view/worms2019/proceedings},
	booktitle = {2nd {International} {Workshop} on {Reading} {Music} {Systems}},
	author = {Wick, Christoph and Puppe, Frank},
	editor = {Calvo-Zaragoza, Jorge and Pacha, Alexander},
	year = {2019},
	keywords = {ISMIR2019, ReadLater, WoRMS2019},
	pages = {31--34}
}

@inproceedings{pugin_optical_2006,
	address = {Victoria, Canada},
	title = {Optical {Music} {Recognitoin} of {Early} {Typographic} {Prints} using {Hidden} {Markov} {Models}.},
	url = {https://doi.org/10.5281/zenodo.1416974},
	doi = {10.5281/zenodo.1416974},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Pugin, Laurent},
	month = oct,
	year = {2006},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_OMR, Comps\_ToDo},
	pages = {53--56}
}

@inproceedings{lee_automatic_2006,
	address = {Victoria, Canada},
	title = {Automatic {Chord} {Recognition} from {Audio} {Using} a {HMM} with {Supervised} {Learning}.},
	url = {https://doi.org/10.5281/zenodo.1415158},
	doi = {10.5281/zenodo.1415158},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Lee, Kyogu and Slaney, Malcolm},
	month = oct,
	year = {2006},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_ChordRecognition, Comps\_Skimmed, Comps\_Summarized},
	pages = {133--137}
}

@inproceedings{eichner_instrument_2006,
	address = {Victoria, Canada},
	title = {Instrument classification using {Hidden} {Markov} {Models}.},
	url = {https://doi.org/10.5281/zenodo.1414960},
	doi = {10.5281/zenodo.1414960},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Eichner, Matthias and Wolff, Matthias and Hoffmann, Rüdiger},
	month = oct,
	year = {2006},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Skimmed, Comps\_Summarized},
	pages = {349--350}
}

@inproceedings{pikrakis_novel_2005,
	address = {London, United Kingdom},
	title = {A {Novel} {HMM} {Approach} to {Melody} {Spotting} in {Raw} {Audio} {Recordings}.},
	url = {https://doi.org/10.5281/zenodo.1414886},
	doi = {10.5281/zenodo.1414886},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Pikrakis, Aggelos and Theodoridis, Sergios},
	month = sep,
	year = {2005},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_MelodicSpotting, Comps\_Skimmed, Comps\_Summarized},
	pages = {652--657}
}

@inproceedings{jang_continuous_2005,
	address = {London, United Kingdom},
	title = {Continuous {HMM} and {Its} {Enhancement} for {Singing}/{Humming} {Query} {Retrieval}.},
	url = {https://doi.org/10.5281/zenodo.1414842},
	doi = {10.5281/zenodo.1414842},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Jang, Jyh-Shing Roger and Hsu, Chao-Ling and Lee, Hong-Ru},
	month = sep,
	year = {2005},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_Unidentified, Comps\_Skimmed, Comps\_Summarized},
	pages = {546--551}
}

@inproceedings{bello_robust_2005,
	address = {London, United Kingdom},
	title = {A {Robust} {Mid}-{Level} {Representation} for {Harmonic} {Content} in {Music} {Signals}.},
	url = {https://doi.org/10.5281/zenodo.1417431},
	doi = {10.5281/zenodo.1417431},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Bello, Juan Pablo and Pickens, Jeremy},
	month = sep,
	year = {2005},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_Unidentified, Comps\_Q4, Comps\_Skimmed, Comps\_Summarized},
	pages = {304--311}
}

@inproceedings{shifrin_effectiveness_2003,
	address = {Baltimore, United States},
	title = {Effectiveness of {HMM}-based retrieval on large databases.},
	url = {https://doi.org/10.5281/zenodo.1417187},
	doi = {10.5281/zenodo.1417187},
	booktitle = {Proceedings of the 4th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Shifrin, Jonah and Birmingham, William P.},
	month = oct,
	year = {2003},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_Unidentified, Comps\_Skimmed, Comps\_Summarized}
}

@inproceedings{sheh_chord_2003,
	address = {Baltimore, United States},
	title = {Chord segmentation and recognition using {EM}- trained hidden markov models.},
	url = {https://doi.org/10.5281/zenodo.1416734},
	doi = {10.5281/zenodo.1416734},
	booktitle = {Proceedings of the 4th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Sheh, Alexander and Ellis, Daniel P. W.},
	month = oct,
	year = {2003},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_ChordRecognition, Comps\_Skimmed, Comps\_Summarized}
}

@inproceedings{orio_hmm-based_2003,
	address = {Baltimore, United States},
	title = {An {HMM}-based pitch tracker for audio queries.},
	url = {https://doi.org/10.5281/zenodo.1417601},
	doi = {10.5281/zenodo.1417601},
	booktitle = {Proceedings of the 4th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Orio, Nicola and Sette, M. Sisti},
	month = oct,
	year = {2003},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_AudioQuery, Comps\_Skimmed, Comps\_Summarized}
}

@inproceedings{jin_indexing_2002,
	address = {Paris, France},
	title = {Indexing {Hidden} {Markov} {Models} for {Music} {Retrieval}.},
	url = {https://doi.org/10.5281/zenodo.1418259},
	doi = {10.5281/zenodo.1418259},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Jin, Hui and Jagadish, H. V.},
	month = oct,
	year = {2002},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_MusicSearch, Comps\_Skimmed, Comps\_Summarized}
}

@inproceedings{batlle_automatic_2000,
	address = {Plymouth, United States},
	title = {Automatic {Segmentation} for {Music} {Classification} using {Competitive} {Hidden} {Markov} {Models}.},
	url = {https://doi.org/10.5281/zenodo.1416764},
	doi = {10.5281/zenodo.1416764},
	booktitle = {Proceedings of the 1st {International} {Symposium} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Batlle, Eloi and Cano, Pedro},
	month = oct,
	year = {2000},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_AudioSegmentation, Comps\_Skimmed, Comps\_Summarized}
}

@inproceedings{durey_melody_2001,
	address = {Bloomington, United States},
	title = {Melody {Spotting} {Using} {Hidden} {Markov} {Models}.},
	url = {https://doi.org/10.5281/zenodo.1415680},
	doi = {10.5281/zenodo.1415680},
	booktitle = {Proceedings of the 2nd {International} {Symposium} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Durey, Adriane and Clements, Mark A.},
	month = oct,
	year = {2001},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_MelodicSearch, Comps\_Skimmed, Comps\_Summarized}
}

@inproceedings{ueda_hmm-based_2010,
	address = {Dallas, USA},
	title = {{HMM}-based approach for automatic chord detection using refined acoustic features},
	doi = {10.1109/ICASSP.2010.5495218},
	abstract = {We discuss an HMM-based method for detecting the chord sequence from musical acoustic signals using percussion-suppressed, Fourier-transformed chroma and delta-chroma features. To reduce the interference often caused by percussive sounds in popular music, we use Harmonic/Percussive Sound Separation (HPSS) technique to suppress percussive sounds and to emphasize harmonic sound components. We also use the Fourier transform of chroma to approximately diagonalize the covariance matrix of feature parameters so as to reduce the number of model parameters without degrading performance. It is shown that HMM with the new features yields higher recognition rates (the best in MIREX 2008 audio chord detection task) than that with conventional features.},
	booktitle = {2010 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing}},
	author = {Ueda, Yushi and Uchiyama, Yuki and Nishimoto, Takuya and Ono, Nobutaka and Sagayama, Shigeki},
	month = mar,
	year = {2010},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_ChordRecognition, Comps\_Skimmed, Comps\_Summarized},
	pages = {5518--5521}
}

@inproceedings{paulus_combining_2007,
	address = {Vienna, Austria},
	title = {Combining {Temporal} and {Spectral} {Features} in {HMM}- {Based} {Drum} {Transcription}.},
	url = {https://doi.org/10.5281/zenodo.1417257},
	doi = {10.5281/zenodo.1417257},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Paulus, Jouni and Klapuri, Anssi},
	month = sep,
	year = {2007},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_DrumTranscription, Comps\_Skimmed, Comps\_Summarized},
	pages = {225--228}
}

@inproceedings{paulus_acoustic_2006,
	title = {Acoustic {Modelling} of {Drum} {Sounds} with {Hidden} {Markov} {Models} for {Music} {Transcription}},
	volume = {5},
	doi = {10.1109/ICASSP.2006.1661257},
	abstract = {This paper describes two methods for applying hidden Markov models (HMMs) to acoustic modelling of drum sound events for polyphonic music transcription. The proposed methods are instrument-wise binary modelling and modelling of instrument combinations. In the first, each target instrument is modelled with a "sound" model and all target instruments share a "silence" model. Each instrument is transcribed independently from the others. In the latter method, different instrument combinations are modelled, and an additional "silence" model is created. The proposed methods are evaluated with simulations with acoustic data, and compared with two reference methods. Simulations show that combination modelling performs better than instrument-wise modelling},
	author = {Paulus, Jouni},
	month = jun,
	year = {2006},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_DrumTranscription},
	pages = {V--V}
}

@article{beverburg_reale_dissolving_nodate,
	title = {Dissolving {Monotonality}: {Expressive} {Modulation} in {Two} {Works} by {C}. {P}. {E}. {Bach}},
	volume = {27},
	journal = {Journal of Applied Musical Thought},
	author = {Beverburg Reale, Haley},
	keywords = {Comps, Comps\_Q6, Comps\_Q6\_Theory},
	pages = {53--105}
}

@book{rameau_treatise_1971,
	address = {New York},
	title = {Treatise on harmony},
	isbn = {978-0-486-22461-9},
	language = {engfre},
	publisher = {Dover Publications},
	author = {Rameau, Jean-Philippe},
	year = {1971},
	keywords = {Comps, Comps\_Q6, Comps\_Q6\_Theory}
}

@book{gollin_reception_2012,
	title = {The {Reception} of {Hugo} {Riemann}'s {Music} {Theory}},
	isbn = {978-0-19-532133-3},
	url = {https://www.oxfordhandbooks.com/view/10.1093/oxfordhb/9780195321333.001.0001/oxfordhb-9780195321333-e-1},
	publisher = {Oxford University Press},
	author = {Gollin, Edward and Rehding, Alexander and Holtmeier, Ludwig},
	year = {2012},
	keywords = {Comps, Comps\_Q6, Comps\_Q6\_Theory}
}

@article{goldenberg_when_2018,
	title = {When and {How} are {Modulations} {Diatonic}?},
	volume = {32},
	journal = {Journal of Applied Musical Thought},
	author = {Goldenberg, Yosef},
	year = {2018},
	keywords = {Comps, Comps\_Q5, Comps\_Q6, Comps\_Q6\_Theory},
	pages = {37--58}
}

@incollection{muller_pitch-_2007,
	address = {Berlin, Heidelberg},
	title = {Pitch- and {Chroma}-{Based} {Audio} {Features}},
	isbn = {978-3-540-74048-3},
	url = {https://doi.org/10.1007/978-3-540-74048-3_3},
	abstract = {Automatic music processing poses a number of challenging questions because of the complexity and diversity of music data. As discussed in Sect. 2.1, one generally has to account for various aspects such as the data format (e.g., score, MIDI, audio), the instrumentation (e.g., orchestra, piano, drums, voice), and many other parameters such as articulation, dynamics, or tempo. To make music data comparable and algorithmically accessible, the first step in all music processing tasks is to extract suitable features that capture relevant key aspects while suppressing irrelevant details or variations. Here, the notion of similarity is of crucial importance in the design of audio features. In some applications and particularly in the case in music retrieval, one may be interested in characterizing an audio recording irrespective of certain details concerning the interpretation or instrumentation. Conversely, other applications may be concerned with measuring just the niceties that relate to a musician’s individual articulation or emotional expressiveness.},
	language = {en},
	urldate = {2019-10-15},
	booktitle = {Information {Retrieval} for {Music} and {Motion}},
	publisher = {Springer Berlin Heidelberg},
	editor = {Müller, Meinard},
	year = {2007},
	doi = {10.1007/978-3-540-74048-3_3},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_ChromagramRobustness},
	pages = {51--67}
}

@article{bartsch_audio_2005,
	title = {Audio thumbnailing of popular music using chroma-based representations},
	volume = {7},
	issn = {1520-9210, 1941-0077},
	doi = {10.1109/TMM.2004.840597},
	abstract = {With the growing prevalence of large databases of multimedia content, methods for facilitating rapid browsing of such databases or the results of a database search are becoming increasingly important. However, these methods are necessarily media dependent. We present a system for producing short, representative samples (or "audio thumbnails") of selections of popular music. The system searches for structural redundancy within a given song with the aim of identifying something like a chorus or refrain. To isolate a useful class of features for performing such structure-based pattern recognition, we present a development of the chromagram, a variation on traditional time-frequency distributions that seeks to represent the cyclic attribute of pitch perception, known as chroma. The pattern recognition system itself employs a quantized chromagram that represents the spectral energy at each of the 12 pitch classes. We evaluate the system on a database of popular music and score its performance against a set of "ideal" thumbnail locations. Overall performance is found to be quite good, with the majority of errors resulting from songs that do not meet our structural assumptions.},
	number = {1},
	journal = {IEEE Transactions on Multimedia},
	author = {Bartsch, M.A. and Wakefield, G.H.},
	month = feb,
	year = {2005},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_ChromagramRobustness},
	pages = {96--104}
}

@inproceedings{fremerey_towards_2009,
	address = {Dagstuhl, Germany},
	series = {Dagstuhl {Seminar} {Proceedings}},
	title = {Towards {Bridging} the {Gap} between {Sheet} {Music} and {Audio}},
	isbn = {1862-4405},
	doi = {10.4230/LIPIcs.STACS.2009.1858},
	booktitle = {Knowledge representation for intelligent music processing},
	publisher = {LZI},
	author = {Fremerey, Christian and Müller, Meinard and Clausen, Michael},
	editor = {Selfridge-Field, Eleanor and Wiering, Frans and Wiggins, Geraint A.},
	year = {2009},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_AudioVsSymbolic},
	pages = {1--11}
}

@incollection{muller_music_2015,
	address = {Cham},
	title = {Music {Representations}},
	isbn = {978-3-319-21945-5},
	url = {https://doi.org/10.1007/978-3-319-21945-5_1},
	abstract = {Music can be represented in many different ways and formats. For example, a composer may write down a composition in the form of a musical score. In a score, musical symbols are used to visually encode notes and how these notes are to be played by a musician.},
	booktitle = {Fundamentals of {Music} {Processing}: {Audio}, {Analysis}, {Algorithms}, {Applications}},
	publisher = {Springer International Publishing},
	author = {Müller, Meinard},
	year = {2015},
	doi = {10.1007/978-3-319-21945-5_1},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_AudioVsSymbolic},
	pages = {1--37}
}

@article{white_chord_2018,
	title = {Chord {Context} and {Harmonic} {Function} in {Tonal} {Music}},
	volume = {40},
	issn = {0195-6167},
	url = {https://doi.org/10.1093/mts/mty021},
	doi = {10.1093/mts/mty021},
	abstract = {This article investigates several questions of harmonic function using aggressively data-driven approaches. We apply Hidden Markov Modeling—a technique used to identify contextual regularities within streams of data—to the Kostka-Payne, McGill Billboard, and Bach chorale corpora. The resulting models question the generalizability of the traditional three-function model, illustrating the syntactic uniqueness of various corpora while also highlighting recurrent characteristics of tonal repertories. Finally, this article offers some general observations, including questioning the role that tonal hierarchy plays in theories of function and discussing the cultural politics inherent in assuming the universality of one functional system.},
	number = {2},
	urldate = {2019-08-10},
	journal = {Music Theory Spectrum},
	author = {White, Christopher Wm. and Quinn, Ian},
	month = nov,
	year = {2018},
	keywords = {Comps, Comps\_Priority, Comps\_Q5, Comps\_Q8, Comps\_Skimmed, Comps\_Summarized},
	pages = {314--335O}
}

@article{brown_interplay_1988,
	title = {The {Interplay} of {Set} {Content} and {Temporal} {Context} in a {Functional} {Theory} of {Tonality} {Perception}},
	volume = {5},
	issn = {0730-7829, 1533-8312},
	url = {https://mp.ucpress.edu/content/5/3/219},
	doi = {10.2307/40285398},
	abstract = {Skip to Next Section
The purpose of this study was to provide evidence for the perceptual component of an analysis of pitch relationships in tonal music that includes consideration of both formal analytic systems and musical listeners' responses to tonal relationships in musical contexts. It was hypothesized (1) that perception of tonal centers in music develops from listeners' interpretations of time-dependent contextual (functional) relationships among pitches, rather than primarily through knowledge of psychoacoustical or structural characteristics of the pitch content of sets or scales and (2) that critical perceptual cues to functional relationships among pitches are provided by the manner in which particular intervallic relationships are expressed in musical time. Excerpts of tonal music were chosen to represent familiar harmonic relationships across a spectrum of tonal ambiguity/specificity. The pitch-class sets derived from these excerpts were ordered: (1) to evoke the same tonic response as the corresponding musical excerpt, 2) to evoke another tonal center, and (3) to be tonally ambiguous. The effect of the intervallic contents of musical excerpts and strings of pitches in determining listeners' choices of tonic and the effect of contextual manipulations of tones in the strings in directing subjects' responses were measured and compared. Results showed that the musically trained listeners in the study were very sensitive to tonal implications of temporal orderings of pitches in determining tonal centers. Temporal manipulations of intervallic relationships in stimuli had significant effects on concurrences of tonic responses and on tonal clarity ratings reported by listeners. The interval rarest in the diatonic set, the tritone, was the interval most effective in guiding tonal choices. These data indicate that perception of tonality is too complex a phenomenon to be explained in the time-independent terms of psychoacoustics or pitch- class collections, that perceived tonal relationships are too flexible to be forced into static structural representations, and that a functional interpretation of rare intervals in optimal temporal orderings in musical contexts is a critical feature of tonal listening strategy.},
	language = {en},
	number = {3},
	urldate = {2019-10-09},
	journal = {Music Perception: An Interdisciplinary Journal},
	author = {Brown, Helen},
	month = apr,
	year = {1988},
	keywords = {Comps, Comps\_Q8},
	pages = {219--249}
}

@article{temperley_pitch-class_2008,
	title = {Pitch-{Class} {Distribution} and the {Identification} of {Key}},
	volume = {25},
	copyright = {©© 2008 By the Regents of the University of California},
	issn = {0730-7829, 1533-8312},
	url = {https://mp.ucpress.edu/content/25/3/193},
	doi = {10.1525/mp.2008.25.3.193},
	abstract = {Skip to Next Section
THIS STUDY EXAMINES THE DISTRIBUTIONAL VIEW OF key-finding, which holds that listeners identify key by monitoring the distribution of pitch-classes in a piece and comparing this to an ideal distribution for each key. In our experiment, participants judged the key of melodies generated randomly from pitch-class distributions characteristic of tonal music. Slightly more than half of listeners' judgments matched the generating keys, on both the untimed and the timed conditions. While this performance is much better than chance, it also indicates that the distributional view is far from a complete explanation of human key identification. No difference was found between participants with regard to absolute pitch ability, either in the speed or accuracy of their key judgments. Several key-finding models were tested on the melodies to see which yielded the best match to participants' responses.},
	language = {en},
	number = {3},
	urldate = {2019-09-25},
	journal = {Music Perception: An Interdisciplinary Journal},
	author = {Temperley, David and Marvin, Elizabeth West},
	month = feb,
	year = {2008},
	keywords = {Comps, Comps\_Q3, Comps\_Q8, Comps\_Read, Comps\_Summarized},
	pages = {193--212}
}

@inproceedings{chuan_fuzzy_2005,
	address = {London, United Kingdom},
	title = {Fuzzy {Analysis} in {Pitch}-{Class} {Determination} for {Polyphonic} {Audio} {Key} {Finding}.},
	url = {https://doi.org/10.5281/zenodo.1417297},
	doi = {10.5281/zenodo.1417297},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Chuan, Ching-Hua and Chew, Elaine},
	month = sep,
	year = {2005},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Q4, Comps\_Q4\_Specificities, Comps\_Read, Comps\_Summarized},
	pages = {296--303}
}

@inproceedings{izmirli_localized_2007,
	address = {Vienna, Austria},
	title = {Localized {Key} {Finding} from {Audio} {Using} {Nonnegative} {Matrix} {Factorization} for {Segmentation}.},
	url = {https://doi.org/10.5281/zenodo.1417197},
	doi = {10.5281/zenodo.1417197},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Izmirli, Özgür},
	month = sep,
	year = {2007},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Q6, Comps\_Q6\_MIR, Comps\_Read, Comps\_Summarized},
	pages = {195--200}
}

@inproceedings{chai_detection_2005,
	address = {London, United Kingdom},
	title = {Detection of {Key} {Change} in {Classical} {Piano} {Music}.},
	url = {https://doi.org/10.5281/zenodo.1415538},
	doi = {10.5281/zenodo.1415538},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Chai, Wei and Vercoe, Barry},
	month = sep,
	year = {2005},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_Key, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Q5, Comps\_Q6, Comps\_Q6\_MIR, Comps\_Read, Comps\_Summarized},
	pages = {468--473}
}

@inproceedings{lee_unified_2007,
	address = {Vienna, Austria},
	title = {A {Unified} {System} for {Chord} {Transcription} and {Key} {Extraction} {Using} {Hidden} {Markov} {Models}.},
	url = {https://doi.org/10.5281/zenodo.1415208},
	doi = {10.5281/zenodo.1415208},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Lee, Kyogu and Slaney, Malcolm},
	month = sep,
	year = {2007},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Q6, Comps\_Q6\_MIR, Comps\_Read, Comps\_Summarized},
	pages = {245--250}
}

@inproceedings{catteau_probabilistic_2007,
	series = {Studies in {Classification}, {Data} {Analysis}, and {Knowledge} {Organization}},
	title = {A {Probabilistic} {Framework} for {Audio}-{Based} {Tonal} {Key} and {Chord} {Recognition}},
	isbn = {978-3-540-70981-7},
	abstract = {A unified probabilistic framework for audio-based chord and tonal key recognition is described and evaluated. The proposed framework embodies an acoustic observation likelihood model and key \& chord transition models. It is shown how to conceive these models and how to use music theory to link key/chord transition probabilities to perceptual similarities between keys/chords. The advantage of a theory based model is that it does not require any training, and consequently, that its performance is not affected by the quality of the available training data.},
	language = {en},
	booktitle = {Advances in {Data} {Analysis}},
	publisher = {Springer Berlin Heidelberg},
	author = {Catteau, Benoit and Martens, Jean-Pierre and Leman, Marc},
	editor = {Decker, Reinhold and Lenz, Hans -J.},
	year = {2007},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_Key, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Q6, Comps\_Q6\_MIR, Comps\_Read, Comps\_Summarized},
	pages = {637--644}
}

@article{krumhansl_cognition_2004,
	title = {The {Cognition} of {Tonality}–as {We} {Know} {It} {Today}},
	volume = {33},
	number = {3},
	journal = {Journal of New Music Research},
	author = {Krumhansl, Carol L.},
	year = {2004},
	keywords = {Comps, Comps\_Q5, Comps\_Q8, Comps\_Read, Comps\_Summarized},
	pages = {253--268}
}

@article{muller_towards_2010,
	title = {Towards {Timbre}-{Invariant} {Audio} {Features} for {Harmony}-{Based} {Music}},
	volume = {18},
	doi = {10.1109/TASL.2010.2041394},
	abstract = {Chroma-based audio features are a well-established tool for analyzing and comparing harmony-based Western music that is based on the equal-tempered scale. By identifying spectral components that differ by a musical octave, chroma features possess a considerable amount of robustness to changes in timbre and instrumentation. In this paper, we describe a novel procedure that further enhances chroma features by significantly boosting the degree of timbre invariance without degrading the features' discriminative power. Our idea is based on the generally accepted observation that the lower mel-frequency cepstral coefficients (MFCCs) are closely related to timbre. Now, instead of keeping the lower coefficients, we discard them and only keep the upper coefficients. Furthermore, using a pitch scale instead of a mel scale allows us to project the remaining coefficients onto the 12 chroma bins. We present a series of experiments to demonstrate that the resulting chroma features outperform various state-of-the art features in the context of music matching and retrieval applications. As a final contribution, we give a detailed analysis of our enhancement procedure revealing the musical meaning of certain pitch-frequency cepstral coefficients.},
	number = {3},
	journal = {IEEE Transactions on Audio, Speech, and Language Processing},
	author = {Muller, M. and Ewert, S.},
	month = mar,
	year = {2010},
	keywords = {Comps, Comps\_Q4},
	pages = {649--662}
}

@article{longuet-higgins_interpreting_1971,
	title = {On interpreting bach},
	volume = {6},
	journal = {Machine intelligence},
	author = {Longuet-Higgins, Hugh Christopher},
	year = {1971},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic}
}

@phdthesis{martorell_modelling_2013,
	type = {{PhD} {Thesis}},
	title = {Modelling {Tonal} {Context} {Dynamics} by {Temporal} {Multi}-{Scale} {Analysis}},
	school = {Universitat Pompeu Fabra},
	author = {Martorell, Agustín},
	year = {2013},
	keywords = {Comps, Comps\_Q3, Comps\_Q5}
}

@inproceedings{napoles_lopez_key-finding_2019,
	address = {New York, NY, USA},
	series = {{DLfM} '19},
	title = {Key-{Finding} {Based} on a {Hidden} {Markov} {Model} and {Key} {Profiles}},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Digital} {Libraries} for {Musicology}},
	publisher = {ACM},
	author = {Nápoles López, Néstor and Arthur, Claire and Fujinaga, Ichiro},
	year = {2019},
	keywords = {Internship@Avid, My Publications}
}

@inproceedings{napoles_lopez_encoding_2018,
	address = {New York, NY, USA},
	series = {{DLfM} '18},
	title = {Encoding {Matters}},
	copyright = {All rights reserved},
	isbn = {978-1-4503-6522-2},
	url = {http://doi.acm.org/10.1145/3273024.3273027},
	doi = {10.1145/3273024.3273027},
	abstract = {In this paper, we discuss how different encodings in symbolic music files can have consequences for music analysis, where a truthful representation, not only of the musical score, but of the semantics of the music, can change the results of music analysis tools. We introduce a series of examples in which different encodings effectively modify the content of two---apparently equivalent---symbolic music files. These examples have been obtained from comparing three different encodings of a string quartet movement by Ludwig van Beethoven. We present two scenarios in which encoding discrepancies may be introduced. In the first scenario, they have been introduced during the encoding of the symbolic music file by either the music notation software or the human encoder. The discrepancies introduced in this scenario are typically difficult to notice because they are visually identical to an accurate encoding. In the second scenario, the discrepancies have been introduced during the translation of the original file into other symbolic formats. In this scenario, the discrepancies may be related to propagating errors in the original encoding or to an erroneous translation of certain attributes of the musical content. Finally, we discuss the possibility of using the examples provided here for the mitigation of some of these discrepancies in the future.},
	urldate = {2019-09-26},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Digital} {Libraries} for {Musicology}},
	publisher = {ACM},
	author = {Nápoles López, Néstor and Vigliensoni, Gabriel and Fujinaga, Ichiro},
	year = {2018},
	note = {event-place: Paris, France},
	keywords = {My Publications},
	pages = {69--73}
}

@article{krumhansl_tracing_1982,
	title = {Tracing the dynamic changes in perceived tonal organization in a spatial representation of musical keys},
	volume = {89},
	issn = {1939-1471(Electronic),0033-295X(Print)},
	doi = {10.1037/0033-295X.89.4.334},
	abstract = {Investigated the cognitive representation of harmonic and tonal structure in Western music using a tone-profile technique in 2 experiments with 24 undergraduates and community adults. Listeners rated how well single tones (any one of the 12 tones of the chromatic scale) followed a musical element such as a scale, chord, or cadence. Stable rating profiles reflecting the tonal hierarchies in major and minor keys were obtained, which, when intercorrelated and analyzed using multidimensional scaling, produced a 4-dimensional spatial map of the distances between keys. Listeners integrated harmonic functions over multiple chords, developing a sense of key that needed to be re-evaluated as additional chords were sounded. It is suggested that the perceived relations between chords and keys and between different keys are mediated through an internal representation of the hierarchy of tonal functions of single tones in music. (56 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {4},
	journal = {Psychological Review},
	author = {Krumhansl, Carol L. and Kessler, Edward J.},
	year = {1982},
	keywords = {Comps, Comps\_Q5, Comps\_Q8, Comps\_Read, Comps\_Summarized},
	pages = {334--368}
}

@article{vos_tonality_2000,
	title = {Tonality {Induction}: {Theoretical} {Problems} and {Dilemmas}},
	volume = {17},
	issn = {07307829, 15338312},
	url = {http://www.jstor.org/stable/40285826},
	abstract = {Fundamental problems and dilemmas for the study of tonality induction are reviewed. I focus on two different, although related types of research impediments. The first is the fuzziness of the key notion "tonality" itself, which leads to divergent conceptualizations of tonality induction, such as "key finding," "tonal induction," "tonal center perception," and "tonal feeling." I argue that the fuzziness is largely due to the lack of welldefined historical or otherwise categorical boundaries of "Western tonal music." The second impediment arises from various dualities in music, notably tone versus note representations, tonal versus intervallic representations, horizontal ("leading voice") cues for tonality induction versus vertical ones ("fundamentals"), and tonal versus temporal tonality induction cues. (Dis) advantages of various interpretations of tonality induction and of solutions of the dualities in question are considered. A few recommendations for reconciliation between currently divergent theoretical approaches to tonality induction are suggested.},
	number = {4},
	journal = {Music Perception: An Interdisciplinary Journal},
	author = {Vos, Piet G.},
	year = {2000},
	keywords = {Comps, Comps\_Q5, Comps\_Q8, Comps\_Read, Comps\_Summarized},
	pages = {403--416}
}

@article{thomson_deductions_2001,
	title = {Deductions {Concerning} {Inductions} of {Tonality}},
	volume = {19},
	copyright = {©© Regents of the University of California},
	issn = {0730-7829, 1533-8312},
	url = {http://mp.ucpress.edu/content/19/1/127},
	doi = {10.1525/mp.2001.19.1.127},
	language = {en},
	number = {1},
	urldate = {2019-10-07},
	journal = {Music Perception: An Interdisciplinary Journal},
	author = {Thomson, William},
	month = sep,
	year = {2001},
	keywords = {Comps, Comps\_Q5, Comps\_Q8},
	pages = {127--138}
}

@inproceedings{sutskever_sequence_2014,
	title = {Sequence to {Sequence} {Learning} with {Neural} {Networks}},
	booktitle = {Advances in {Neural} {Information} {Processing} systems},
	author = {Sutskever, Ilya and Vinyals, Oriol and Le, Quoc V.},
	year = {2014},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_RNN, Comps\_Q9},
	pages = {3104--3112}
}

@article{salehinejad_recent_2017,
	title = {Recent {Advances} in {Recurrent} {Neural} {Networks}},
	journal = {arXiv preprint arXiv:1801.01078},
	author = {Salehinejad, Hojjat and Sankar, Sharan and Barfett, Joseph and Colak, Errol and Valaee, Shahrokh},
	year = {2017},
	keywords = {Comps, Comps\_Q2, Comps\_Q9}
}

@article{hochreiter_long_1997,
	title = {Long {Short}-{Term} {Memory}},
	volume = {9},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1997.9.8.1735},
	doi = {10.1162/neco.1997.9.8.1735},
	abstract = {Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, artificial long-time-lag tasks that have never been solved by previous recurrent network algorithms.},
	number = {8},
	urldate = {2019-09-23},
	journal = {Neural Computation},
	author = {Hochreiter, Sepp and Schmidhuber, Jürgen},
	month = nov,
	year = {1997},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_RNN, Comps\_Q9},
	pages = {1735--1780}
}

@inproceedings{pascanu_difficulty_2013,
	series = {{ICML}'13},
	title = {On the {Difficulty} of {Training} {Recurrent} {Neural} {Networks}},
	url = {http://dl.acm.org/citation.cfm?id=3042817.3043083},
	abstract = {There are two widely known issues with properly training recurrent neural networks, the vanishing and the exploding gradient problems detailed in Bengio et al. (1994). In this paper we attempt to improve the understanding of the underlying issues by exploring these problems from an analytical, a geometric and a dynamical systems perspective. Our analysis is used to justify a simple yet effective solution. We propose a gradient norm clipping strategy to deal with exploding gradients and a soft constraint for the vanishing gradients problem. We validate empirically our hypothesis and proposed solutions in the experimental section.},
	urldate = {2019-10-04},
	booktitle = {Proceedings of the 30th {International} {Conference} on {International} {Conference} on {Machine} {Learning} - {Volume} 28},
	publisher = {JMLR.org},
	author = {Pascanu, Razvan and Mikolov, Tomas and Bengio, Yoshua},
	year = {2013},
	note = {event-place: Atlanta, GA, USA},
	keywords = {Comps, Comps\_Q9, Comps\_Read, Comps\_Summarized},
	pages = {III--1310--III--1318}
}
@article{elman_finding_1990,
	title = {Finding structure in time},
	volume = {14},
	issn = {0364-0213},
	url = {http://www.sciencedirect.com/science/article/pii/036402139090002E},
	doi = {10.1016/0364-0213(90)90002-E},
	abstract = {Time underlies many interesting human behaviors. Thus, the question of how to represent time in connectionist models is very important. One approach is to represent time implicitly by its effects on processing rather than explicitly (as in a spatial representation). The current report develops a proposal along these lines first described by Jordan (1986) which involves the use of recurrent links in order to provide networks with a dynamic memory. In this approach, hidden unit patterns are fed back to themselves; the internal representations which develop thus reflect task demands in the context of prior internal states. A set of simulations is reported which range from relatively simple problems (temporal version of XOR) to discovering syntactic/semantic features for words. The networks are able to learn interesting internal representations which incorporate task demands with memory demands; indeed, in this approach the notion of memory is inextricably bound up with task processing. These representations reveal a rich structure, which allows them to be highly context-dependent, while also expressing generalizations across classes of items. These representations suggest a method for representing lexical categories and the type/token distinction.},
	number = {2},
	urldate = {2019-10-05},
	journal = {Cognitive Science},
	author = {Elman, Jeffrey L.},
	month = apr,
	year = {1990},
	keywords = {Comps, Comps\_Q9},
	pages = {179--211}
}

@article{lipton_critical_2015,
	title = {A {Critical} {Review} of {Recurrent} {Neural} {Networks} for {Sequence} {Learning}},
	journal = {arXiv preprint arXiv:1506.00019},
	author = {Lipton, Zachary C. and Berkowitz, John and Elkan, Charles},
	year = {2015},
	keywords = {Comps, Comps\_Q9, Comps\_Read, Comps\_Summarized}
}

@article{schuster_bidirectional_1997,
	title = {Bidirectional recurrent neural networks},
	volume = {45},
	doi = {10.1109/78.650093},
	abstract = {In the first part of this paper, a regular recurrent neural network (RNN) is extended to a bidirectional recurrent neural network (BRNN). The BRNN can be trained without the limitation of using input information just up to a preset future frame. This is accomplished by training it simultaneously in positive and negative time direction. Structure and training procedure of the proposed network are explained. In regression and classification experiments on artificial data, the proposed structure gives better results than other approaches. For real data, classification experiments for phonemes from the TIMIT database show the same tendency. In the second part of this paper, it is shown how the proposed bidirectional structure can be easily modified to allow efficient estimation of the conditional posterior probability of complete symbol sequences without making any explicit assumption about the shape of the distribution. For this part, experiments on real data are reported.},
	number = {11},
	journal = {IEEE Transactions on Signal Processing},
	author = {Schuster, M. and Paliwal, K. K.},
	month = nov,
	year = {1997},
	keywords = {Comps, Comps\_Q9},
	pages = {2673--2681}
}

@incollection{jordan_chapter_1997,
	series = {Neural-{Network} {Models} of {Cognition}},
	title = {Chapter 25 - {Serial} {Order}: {A} {Parallel} {Distributed} {Processing} {Approach}},
	volume = {121},
	shorttitle = {Chapter 25 - {Serial} {Order}},
	url = {http://www.sciencedirect.com/science/article/pii/S0166411597801112},
	abstract = {A theory of learned sequential behavior is presented, with a focus on coarticulatory phenomena in speech. The theory is implemented as a recurrent parallel distributed processing network that is trained via a generalized error-correcting algorithm. The basic idea underlying the theory is that both serial order and coarticulatory overlap can be represented in terms of relative levels of activation in a network if a clear distinction is made between the state of the network and the output of the network.},
	urldate = {2019-10-05},
	booktitle = {Advances in {Psychology}},
	publisher = {North-Holland},
	author = {Jordan, Michael I.},
	editor = {Donahoe, John W. and Packard Dorsel, Vivian},
	month = jan,
	year = {1997},
	doi = {10.1016/S0166-4115(97)80111-2},
	keywords = {Comps, Comps\_Q9},
	pages = {471--495}
}

@article{werbos_backpropagation_1990,
	title = {Backpropagation through time: what it does and how to do it},
	volume = {78},
	shorttitle = {Backpropagation through time},
	doi = {10.1109/5.58337},
	abstract = {Basic backpropagation, which is a simple method now being widely used in areas like pattern recognition and fault diagnosis, is reviewed. The basic equations for backpropagation through time, and applications to areas like pattern recognition involving dynamic systems, systems identification, and control are discussed. Further extensions of this method, to deal with systems other than neural networks, systems involving simultaneous equations, or true recurrent networks, and other practical issues arising with the method are described. Pseudocode is provided to clarify the algorithms. The chain rule for ordered derivatives-the theorem which underlies backpropagation-is briefly discussed. The focus is on designing a simpler version of backpropagation which can be translated into computer code and applied directly by neutral network users.{\textless}{\textgreater}},
	number = {10},
	journal = {Proceedings of the IEEE},
	author = {Werbos, P. J.},
	month = oct,
	year = {1990},
	keywords = {Comps, Comps\_Q9},
	pages = {1550--1560}
}

@inproceedings{teodoru_pitch_2007,
	address = {Vienna, Austria},
	title = {Pitch {Spelling} with {Conditionally} {Independent} {Voices}.},
	url = {https://doi.org/10.5281/zenodo.1414946},
	doi = {10.5281/zenodo.1414946},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Teodoru, Gabi and Raphael, Christopher},
	month = sep,
	year = {2007},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q7, Comps\_Read, Comps\_Summarized},
	pages = {201--206}
}

@inproceedings{meredith_comparing_2005,
	address = {London, United Kingdom},
	title = {Comparing {Pitch} {Spelling} {Algorithms}.},
	url = {https://doi.org/10.5281/zenodo.1416366},
	doi = {10.5281/zenodo.1416366},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Meredith, David and Wiggins, Geraint A.},
	month = sep,
	year = {2005},
	keywords = {Comps, Comps\_Q7, Comps\_Read, Comps\_Summarized},
	pages = {280--287}
}

@phdthesis{korzeniowski_harmonic_2018,
	type = {{PhD} {Thesis}},
	title = {Harmonic {Analysis} of {Musical} {Audio} using {Deep} {Neural} {Networks}},
	school = {Johannes Kepler University Linz},
	author = {Korzeniowski, Filip},
	year = {2018},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_ChordRecognition, Comps\_Q2\_MIR\_Key, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Read, Comps\_Summarized, Comps\_ToDo}
}

@mastersthesis{campbell_automatic_2010,
	title = {Automatic {Key} {Detection} of {Musical} {Excerpts} {From} {Audio}},
	school = {McGill University},
	author = {Campbell, Spencer},
	year = {2010},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Q4, Comps\_Q4\_AudioDegradation, Comps\_Q4\_Specificities, Comps\_Read, Comps\_Summarized}
}

@phdthesis{leman_een_1992,
	type = {{PhD} {Thesis}},
	title = {Een model van toonsemantiek : naar een theorie en discipline van de muzikale verbeelding},
	language = {dut},
	school = {Ghent University},
	author = {Leman, Marc},
	year = {1992},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey}
}

@inproceedings{izmirli_recognition_1994,
	title = {Recognition of musical tonality from sound input},
	doi = {10.1109/MELCON.1994.381110},
	abstract = {Work on the problem of computer based determination of the musical mode and tonality of a melody from sound input is presented. The study proposes a tool for determination of a time dependent tonal context vector for melodies from acoustical input. Each element of this vector, called a tonal component, indicates the extent of a specific scale usage. The system is made up of two stages: The first is involved in digital signal processing and is used to convert sound input of melodies into a sequence of musical note intervals and their associated occurrence times. The second stage uses finite state automats to match patterns of the interval sequences with pre-programmed scale patterns. The output consists of a time dependent tonal context vector whose elements are relative strengths of various tonal components regarding the melody under consideration.{\textless}{\textgreater}},
	booktitle = {Proceedings of {MELECON} '94. {Mediterranean} {Electrotechnical} {Conference}},
	author = {Izmirli, O. and Bilgen, S.},
	month = apr,
	year = {1994},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Skimmed, Comps\_Summarized},
	pages = {269--271 vol.1}
}

@inproceedings{urbano_what_2014,
	address = {Taipei, Taiwan},
	title = {What is the {Effect} of {Audio} {Quality} on the {Robustness} of {MFCCs} and {Chroma} {Features}?},
	url = {https://doi.org/10.5281/zenodo.1416276},
	doi = {10.5281/zenodo.1416276},
	booktitle = {Proceedings of the 15th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Urbano, Julián and Bogdanov, Dmitry and Herrera, Perfecto and Gómez, Emilia and Serra, Xavier},
	month = oct,
	year = {2014},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_AudioDegradation, Comps\_Q4\_Evaluation, Comps\_Q4\_Specificities, Comps\_Read, Comps\_Summarized},
	pages = {573--578}
}

@inproceedings{uemura_effects_2014,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Effects of {Audio} {Compression} on {Chord} {Recognition}},
	isbn = {978-3-319-04117-9},
	abstract = {Feature analysis of audio compression is necessary to achieve high accuracy in musical content recognition and content-based music information retrieval (MIR). Bit rate differences are expected to adversely affect musical content analysis and content-based MIR results because the frequency response might be changed by the encoding. In this paper, we specifically examine its effect on the chroma vector, which is a commonly used feature vector for music signal processing. We analyze sound qualities extracted from encoded music files with different bit rates and compare them with the chroma features of original songs obtained using datasets for chord recognition.},
	language = {en},
	booktitle = {{MultiMedia} {Modeling}},
	publisher = {Springer International Publishing},
	author = {Uemura, Aiko and Ishikura, Kazumasa and Katto, Jiro},
	editor = {Gurrin, Cathal and Hopfgartner, Frank and Hurst, Wolfgang and Johansen, Håvard and Lee, Hyowon and O’Connor, Noel},
	year = {2014},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_AudioDegradation, Comps\_Read, Comps\_Summarized},
	pages = {345--352}
}

@phdthesis{schluter_deep_2017,
	address = {Linz, Austria},
	type = {{PhD} {Thesis}},
	title = {Deep {Learning} for {Event} {Detection}, {Sequence} {Labelling} and {Similarity} {Estimation} in {Music} {Signals}},
	school = {Johannes Kepler University Linz},
	author = {Schlüter, Jan},
	year = {2017},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q4, Comps\_Read, Comps\_Summarized, Comps\_ToDo}
}

@phdthesis{sapp_computational_2011,
	type = {{PhD} {Thesis}},
	title = {Computational {Methods} for the {Analysis} of {Musical} {Structure}},
	abstract = {Music is an art form which is realized in time. This dissertation presents computational methods for examining the temporality of music at multiple time-scales so that both short-term surface features and deeper long-term structures can be studied and related to each other. The methods are applied in particular to musical key analysis (Chapters 2-4) and also adapted for use in performance analysis (Chapters 5-6). The essential methodology is to examine all sequential time-scales within a piece using some analytic process and then arrange a summary of the analytic results into a maximally overlapped arrangement. Chapter 2 defines a two-dimensional plotting domain for displaying musical features at all possible time-scales which forms a basis for further analysis methods. The resulting structures in the plots can be examined subjectively as a navigational aid in the music as illustrated in Chapters 3 and 5. They can also be used to extract musically relevant information as discussed in Chapters 4 and 6.},
	language = {en},
	school = {Stanford University},
	author = {Sapp, Craig Stuart},
	year = {2011},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic, Comps\_Q5, Comps\_Q6, Comps\_Q6\_Theory, Comps\_Read, Comps\_Summarized}
}

@inproceedings{chuan_polyphonic_2005,
	address = {Amsterdam, Netherlands},
	title = {Polyphonic {Audio} {Key} {Finding} {Using} the {Spiral} {Array} {CEG} {Algorithm}},
	doi = {10.1109/ICME.2005.1521350},
	abstract = {Key finding is an integral step in content-based music indexing and retrieval. In this paper, we present an O(n) real-time algorithm for determining key from polyphonic audio. We use the standard Fast Fourier Transform with a local maximum detection scheme to extract pitches and pitch strengths from polyphonic audio. Next, we use Chew's Spiral Array Center of Effect Generator (CEG) algorithm to determine the key from pitch strength information. We test the proposed system using Mozart's Symphonies. The test data is audio generated from MIDI source. The algorithm achieves a maximum correct key recognition rate of 96\% within the first fifteen seconds, and exceeds 90\% within the first three seconds. Starting from the extracted pitch strength information, we compare the CEG algorithm's performance to the classic Krumhansl-Schmuckler (K-S) probe tone profile method and Temperley's modified version of the K-S method. Correct key recognition rates for the K-S and modified K-S methods remain under 50\% in the first three seconds, with maximum values of 80\% and 87\% respectively within the first fifteen seconds for the same test set. The CEG method consistently scores higher throughout the fifteen-second selections.},
	booktitle = {2005 {IEEE} {International} {Conference} on {Multimedia} and {Expo}},
	author = {Chuan, Ching-Hua and Chew, E.},
	month = jul,
	year = {2005},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Q5, Comps\_Skimmed, Comps\_Summarized},
	pages = {21--24}
}

@article{albrecht_use_2013,
	title = {The {Use} of {Large} {Corpora} to {Train} a {New} {Type} of {Key}-{Finding} {Algorithm}: {An} {Improved} {Treatment} of the {Minor} {Mode}},
	volume = {31},
	shorttitle = {The use of large corpora to train a new type of key-finding algorithm},
	number = {1},
	journal = {Music Perception: An Interdisciplinary Journal},
	author = {Albrecht, Joshua and Shanahan, Daniel},
	year = {2013},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic, Comps\_Q5, Comps\_Read, Comps\_Summarized},
	pages = {59--67}
}

@article{temperley_whats_1999,
	title = {What's {Key} for {Key}? {The} {Krumhansl}-{Schmuckler} {Key}-{Finding} {Algorithm} {Reconsidered}},
	volume = {17},
	issn = {07307829, 15338312},
	shorttitle = {What's {Key} for {Key}?},
	url = {http://mp.ucpress.edu/cgi/doi/10.2307/40285812},
	doi = {10.2307/40285812},
	number = {1},
	urldate = {2019-08-02},
	journal = {Music Perception: An Interdisciplinary Journal},
	author = {Temperley, David},
	month = oct,
	year = {1999},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic, Comps\_Q8},
	pages = {65--100}
}

@inproceedings{stoddard_well-tempered_2004,
	address = {Barcelona, Spain},
	title = {Well-{Tempered} {Spelling}: {A} {Key}-{Invariant} {Pitch} {Spelling} {Algorithm}},
	abstract = {In this paper is described a data-driven algorithm for the functionally correct spelling of MIDI pitch values in terms of Western musical notation. Input is in the form of MIDI files containing accurate pitch and rhythmic information with corresponding ground-truth spelling information for training and evaluation. The algorithm recovers harmonic information from the MIDI data and spells pitches according to their relation to the local tonic. The algorithm achieved 94.98\% accuracy on the pitches that required accidentals in the local key and 99.686\% overall. Voice-leading resolution was found to be the best feature of those used to infer the correct spelling. Also, this paper outlines great potential for improvement under this model.},
	language = {en},
	booktitle = {Proceedings of the 5th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	author = {Stoddard, Joshua and Raphael, Christopher and Utgoff, Paul E},
	year = {2004},
	keywords = {Comps, Comps\_Q7, Comps\_Skimmed, Comps\_Summarized},
	pages = {6}
}

@article{sapp_visual_2005,
	title = {Visual {Hierarchical} {Key} {Analysis}},
	volume = {3},
	number = {4},
	journal = {Computers in Entertainment (CIE)},
	author = {Sapp, Craig Stuart},
	year = {2005},
	keywords = {Comps, Comps\_Q5, Comps\_Q6, Comps\_Q6\_Theory},
	pages = {1--19}
}

@inproceedings{knees_two_2015,
	address = {Málaga, Spain},
	title = {Two {Data} {Sets} for {Tempo} {Estimation} and {Key} {Detection} in {Electronic} {Dance} {Music} {Annotated} from {User} {Corrections}.},
	booktitle = {Proceedings of the 16th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	author = {Knees, Peter and Faraldo, Angel and Herrera, Perfecto and Vogl, Richard and Böck, Sebastian and Hörschläger, Florian and Le Goff, Mickael},
	year = {2015},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Dataset},
	pages = {364--370}
}

@article{parncutt_tonic_2011,
	title = {The {Tonic} as {Triad}: {Key} {Profiles} as {Pitch} {Salience} {Profiles} of {Tonic} {Triads}},
	volume = {28},
	shorttitle = {The tonic as triad},
	number = {4},
	journal = {Music Perception: An Interdisciplinary Journal},
	author = {Parncutt, Richard},
	year = {2011},
	keywords = {Comps, Comps\_Q5, Comps\_Q8},
	pages = {333--366}
}

@article{meredith_ps13_2006,
	title = {The {PS13} {Pitch} {Spelling} {Algorithm}},
	volume = {35},
	number = {2},
	journal = {Journal of New Music Research},
	author = {Meredith, David},
	year = {2006},
	keywords = {Comps, Comps\_Q7},
	pages = {121--159}
}

@book{huron_sweet_2007,
	address = {Cambridge, Mass.},
	edition = {1. MIT Press paperb. ed},
	series = {A {Bradford} book},
	title = {Sweet anticipation: music and the psychology of expectation},
	isbn = {978-0-262-58278-0 978-0-262-08345-4},
	shorttitle = {Sweet anticipation},
	language = {eng},
	publisher = {MIT Press},
	author = {Huron, David B.},
	year = {2007},
	keywords = {Comps, Comps\_Q8}
}

@inproceedings{paulus_state_2010,
	address = {Utrecht, Netherlands},
	title = {State of the {Art} {Report}: {Audio}-{Based} {Music} {Structure} {Analysis}.},
	url = {https://doi.org/10.5281/zenodo.1417289},
	doi = {10.5281/zenodo.1417289},
	booktitle = {Proceedings of the 11th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Paulus, Jouni and Müller, Meinard and Klapuri, Anssi},
	month = aug,
	year = {2010},
	keywords = {Comps, Comps\_Q4},
	pages = {625--636}
}

@inproceedings{noland_signal_2007,
	address = {Vienna, Austria},
	title = {Signal {Processing} {Parameters} for {Tonality} {Estimation}},
	url = {http://www.aes.org/e-lib/browse.cfm?elib=14140},
	abstract = {All musical audio feature extraction techniques require some form of signal processing as a first step. However, the choice of low level parameters such as window sizes is often disregarded, and arbitrary values are chosen. We present an investigation into the effects of low level parameter choice on different tonality estimation algorithms, and show that the low level parameters can make a significant difference to the results. We also show that the choice of parameters is algorithm specific,...},
	language = {English},
	urldate = {2019-08-06},
	booktitle = {Audio {Engineering} {Society} {Convention} 122},
	publisher = {Audio Engineering Society},
	author = {Noland, Katy C. and Sandler, Mark B.},
	month = may,
	year = {2007},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_FeatureExtraction}
}

@inproceedings{humphrey_rethinking_2012,
	title = {Rethinking {Automatic} {Chord} {Recognition} with {Convolutional} {Neural} {Networks}},
	volume = {2},
	doi = {10.1109/ICMLA.2012.220},
	abstract = {Despite early success in automatic chord recognition, recent efforts are yielding diminishing returns while basically iterating over the same fundamental approach. Here, we abandon typical conventions and adopt a different perspective of the problem, where several seconds of pitch spectra are classified directly by a convolutional neural network. Using labeled data to train the system in a supervised manner, we achieve state of the art performance through this initial effort in an otherwise unexplored area. Subsequent error analysis provides insight into potential areas of improvement, and this approach to chord recognition shows promise for future harmonic analysis systems.},
	booktitle = {2012 11th {International} {Conference} on {Machine} {Learning} and {Applications}},
	author = {Humphrey, E. J. and Bello, J. P.},
	month = dec,
	year = {2012},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_ChordRecognition},
	pages = {357--362}
}

@article{chew_real-time_2005,
	title = {Real-{Time} {Pitch} {Spelling} {Using} the {Spiral} {Array}},
	volume = {29},
	number = {2},
	journal = {Computer Music Journal},
	author = {Chew, Elaine and Chen, Yun-Ching},
	year = {2005},
	keywords = {Comps, Comps\_Q7},
	pages = {61--76}
}

@article{cambouropoulos_pitch_2003,
	title = {Pitch {Spelling}: {A} {Computational} {Model}},
	volume = {20},
	shorttitle = {Pitch spelling},
	number = {4},
	journal = {Music Perception: An Interdisciplinary Journal},
	author = {Cambouropoulos, Emilios},
	year = {2003},
	keywords = {Comps, Comps\_Q7},
	pages = {411--429}
}

@inproceedings{meredith_pitch_2003,
	address = {Hannover, Germany},
	title = {Pitch {Spelling} {Algorithms}},
	booktitle = {Proceedings of the {Fifth} {Triennial} {ESCOM} {Conference}},
	author = {Meredith, David},
	year = {2003},
	keywords = {Comps, Comps\_Q7},
	pages = {204--207}
}

@article{thompson_perceived_1992,
	title = {Perceived {Key} {Movement} in {Four}-{Voice} {Harmony} and {Single} {Voices}},
	volume = {9},
	issn = {0730-7829},
	url = {http://www.jstor.org/stable/40285563},
	doi = {10.2307/40285563},
	abstract = {Listeners with a moderate amount of musical training rated the distance between the first and final key of short chorale excerpts under one of four presentation conditions. The distance between keys, or modulation distance, was either zero, one, or two steps in either the clockwise or counterclockwise direction on the cycle of fifths. Presentation conditions were four-voice harmonic sequences excerpted from the complete set of Bach chorales, single voices of the latter sequences, four-voice harmonic sequences simplified to block chords, and single voices of the latter sequences. Consistent with earlier findings (Thompson \& Cuddy, 1989), judgments for both four- voice harmonic presentations and single-voice presentations revealed a close correspondence between modulation distance and judged distance. Ratings for harmonic sequences within a given key distance, however, showed influences of direction of modulation and of harmonic progression that were not reflected in ratings for single voices. The findings suggest that harmony and melody follow somewhat different principles in the process of identifying key change.},
	number = {4},
	urldate = {2019-08-04},
	journal = {Music Perception: An Interdisciplinary Journal},
	author = {Thompson, William F. and Cuddy, Lola L.},
	year = {1992},
	keywords = {Comps, Comps\_Q6, Comps\_Q6\_Theory, Comps\_Q8},
	pages = {427--438}
}

@inproceedings{schreiber_musical_2019,
	address = {Málaga, Spain},
	title = {Musical {Tempo} and {Key} {Estimation} using {Convolutional} {Neural} {Networks} with {Directional} {Filters}},
	booktitle = {Proceedings of the 16th {Sound} and {Music} {Computing} {Conference}},
	author = {Schreiber, Hendrik and Müller, Meinard},
	year = {2019},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_TempoKey, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_ToDo}
}

@book{reger_modulation_2007,
	address = {Mineola, N.Y},
	edition = {Dover Ed edition},
	title = {Modulation},
	isbn = {978-0-486-45732-1},
	abstract = {"I consider him a genius," remarked Arnold Schoenberg of the progressive early modernist Max Reger (1873–1916). In addition to his international renown as a teacher, conductor, and pianist, Reger wrote more than 1,000 works in virtually every musical genre. Many scholars and musicians credit him with emancipating dissonance to a level that assisted Schoenberg's development of serialism in the 1920s. Reger's influence extends to other 20th-century composers, including Béla Bártok, Alban Berg, Arthur Honegger, Paul Hindemith, and Sergei Prokofiev.Modulation — the change from one key to another — is a subject of critical importance to performers and composers in their study of harmony. Reger wrote this concise guide to modulation while teaching composition at Leipzig Conservatory, and the work continues to provide valuable insights and instruction for musicians at all levels. This new edition features newly engraved musical examples.},
	language = {English},
	publisher = {Dover Publications},
	author = {Reger, Max},
	month = jun,
	year = {2007},
	keywords = {Comps, Comps\_Q6, Comps\_Q6\_Theory}
}

@inproceedings{papadopoulos_local_2009,
	address = {Como, Italy},
	title = {Local {Key} {Estimation} {Based} on {Harmonic} and {Metric} {Structures}},
	url = {https://hal.archives-ouvertes.fr/hal-00511452},
	abstract = {In this paper, we present a method for estimating the local keys of an audio signal. We propose to address the problem of local key ﬁnding by investigating the possible combination and extension of different previous proposed global key estimation approaches. The speciﬁcity of our approach is that we introduce key dependency on the harmonic and the metric structures. In this work, we focus on the relationship between the chord progression and the local key progression in a piece of music. A contribution of our work is that we address the problem of ﬁnding a good analysis window length for local key estimation by introducing information related to the metric structure in our model. Key estimation is not performed on empirical-chosen segment length but on segments that are adapted to the analyzed piece and independent from the tempo. We evaluate and analyze our results on a new database composed of classical music pieces.},
	urldate = {2019-08-05},
	booktitle = {12th {Int}. {Conference} on {Digital} {Audio} {Effects} ({DAFx}-09)},
	author = {Papadopoulos, Hélène and Peeters, Geoffroy},
	month = sep,
	year = {2009},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Q6, Comps\_Q6\_MIR},
	pages = {408--415}
}

@inproceedings{noland_key_2006,
	address = {Victoria, Canada},
	title = {Key {Estimation} {Using} a {Hidden} {Markov} {Model}.},
	booktitle = {Proceedings of the 7th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	author = {Noland, Katy C. and Sandler, Mark B.},
	year = {2006},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_Key, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_ToDo},
	pages = {121--126}
}

@inproceedings{faraldo_key_2016,
	address = {Padua, Italy},
	title = {Key {Estimation} in {Electronic} {Dance} {Music}},
	booktitle = {Proceedings of the 38th {European} {Conference} on {Information} {Retrieval}},
	publisher = {Springer},
	author = {Faraldo, Ángel and Gómez, Emilia and Jordà, Sergi and Herrera, Perfecto},
	year = {2016},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Dataset, Comps\_Q3\_Survey},
	pages = {335--347}
}

@article{white_feedback_2018,
	title = {Feedback and {Feedforward} {Models} of {Musical} {Key}},
	volume = {24},
	number = {2},
	journal = {Music Theory Online},
	author = {White, Christopher Wm},
	year = {2018},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic, Comps\_Q3\_Unidentified, Comps\_Q5, Comps\_Q8}
}

@inproceedings{mckinney_features_2003,
	address = {Washington, USA},
	title = {Features for {Audio} and {Music} {Classification}},
	abstract = {Four audio feature sets are evaluated in their ability to classify five general audio classes and seven popular music genres. The feature sets include low-level signal properties, mel-frequency spectral coefficients, and two new sets based on perceptual models of hearing. The temporal behavior of the features is analyzed and parameterized and these parameters are included as additional features. Using a standard Gaussian framework for classification, results show that the temporal behavior of features is important for both music and audio classification. In addition, classification is better, on average, if based on features from models of auditory perception rather than on standard features.},
	booktitle = {Proceedings of the 4th {International} {Symposium} on {Music} {Information} {Retrieval}},
	author = {Mckinney, Martin and Breebaart, Jeroen},
	year = {2003},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_FeatureExtraction},
	pages = {151--158}
}

@inproceedings{dieleman_end--end_2014,
	address = {Florence, Italy},
	title = {End-to-end learning for music audio},
	doi = {10.1109/ICASSP.2014.6854950},
	abstract = {Content-based music information retrieval tasks have traditionally been solved using engineered features and shallow processing architectures. In recent years, there has been increasing interest in using feature learning and deep architectures instead, thus reducing the required engineering effort and the need for prior knowledge. However, this new approach typically still relies on mid-level representations of music audio, e.g. spectrograms, instead of raw audio signals. In this paper, we investigate whether it is possible to apply feature learning directly to raw audio signals. We train convolutional neural networks using both approaches and compare their performance on an automatic tagging task. Although they do not outperform a spectrogram-based approach, the networks are able to autonomously discover frequency decompositions from raw audio, as well as phase-and translation-invariant feature representations.},
	booktitle = {2014 {IEEE} {International} {Conference} on {Acoustics}, {Speech} and {Signal} {Processing} ({ICASSP})},
	author = {Dieleman, Sander and Schrauwen, Benjamin},
	month = may,
	year = {2014},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Q4},
	pages = {6964--6968}
}

@phdthesis{aarden_dynamic_2003,
	type = {{PhD} {Thesis}},
	title = {Dynamic {Melodic} {Expectancy}},
	school = {The Ohio State University},
	author = {Aarden, Bret J.},
	year = {2003},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic, Comps\_Q5, Comps\_Q8, Comps\_Summarized}
}

@inproceedings{chuan_creating_2012,
	address = {Porto, Portugal},
	title = {Creating {Ground} {Truth} for {Audio} {Key} {Finding}: {When} the {Title} {Key} {May} {Not} {Be} the {Key}.},
	shorttitle = {Creating {Ground} {Truth} for {Audio} {Key} {Finding}},
	booktitle = {Proceedings of the 13th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {Citeseer},
	author = {Chuan, Ching-Hua and Chew, Elaine},
	year = {2012},
	keywords = {Comps, Comps\_Q5, Comps\_Q8},
	pages = {247--252}
}

@article{quinn_corpus-derived_2017,
	title = {Corpus-{Derived} {Key} {Profiles} {Are} {Not} {Transpositionally} {Equivalent}},
	volume = {34},
	copyright = {© 2017 by The Regents of the University of California},
	issn = {0730-7829, 1533-8312},
	url = {https://mp.ucpress.edu/content/34/5/531},
	doi = {10.1525/mp.2017.34.5.531},
	abstract = {Skip to Next Section
A fundamental assumption of distributional key-finding methods is that the frequency distributions of pitch classes in all keys are transpositionally equivalent. We tested this assumption with three experiments. First, using data from the openings of 995 major-key pieces and 596 minor-key pieces in the Yale-Classical Archives Corpus, we found that scale-degree distributions differ significantly from one key to another, and further analysis revealed that pieces keys with signatures having relatively more accidentals exhibit significantly more chromaticism than keys with fewer accidentals. Second, we examined whether these data might be accounted for by different keys’ varying modulation tendencies, and found this to be the case: keys with more accidentals modulate more frequently to more distant keys. Finally, we attempted to exclude modulatory passages from our data using a key profile analysis to identify key and mode within our dataset; however, the results of Experiment 1 still held. In sum, even when using a method that assumes transpositional equivalence, we found a difference between key profiles of different keys.},
	language = {en},
	number = {5},
	urldate = {2019-08-07},
	journal = {Music Perception: An Interdisciplinary Journal},
	author = {Quinn, Ian and White, Christopher Wm},
	month = jun,
	year = {2017},
	keywords = {Comps, Comps\_Q5, Comps\_Q8},
	pages = {531--540}
}

@article{pauwels_combining_2014,
	title = {Combining {Musicological} {Knowledge} {About} {Chords} and {Keys} in a {Simultaneous} {Chord} and {Local} {Key} {Estimation} {System}},
	volume = {43},
	issn = {0929-8215},
	url = {https://doi.org/10.1080/09298215.2014.917684},
	doi = {10.1080/09298215.2014.917684},
	abstract = {In this paper, we present a probabilistic framework for the simultaneous estimation of chords and keys from audio. The framework is formulated in terms of acoustic models for both keys and chords, and a prior model that contains musicological knowledge about chords and keys. The latter consists of a compound of four components: a duration and a change model for both keys and chords. This division allows us to modify each of the components separately and to choose the most appropriate sources of knowledge for each of them. Furthermore, this makes it easier to interpret their role and their relevance in the estimation procedure. We compared multiple configurations of our system, increasing in complexity. This has permitted us to explore the relation between keys and chords, and the importance of integrating prior musicological knowledge into an automatic estimation system. It was found that chord estimation scores mostly depend on the integration of durational knowledge, while key estimation also requires prior information about the broader context.},
	number = {3},
	urldate = {2019-08-04},
	journal = {Journal of New Music Research},
	author = {Pauwels, Johan and Martens, Jean-Pierre},
	month = jul,
	year = {2014},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Q5, Comps\_Q6, Comps\_Q6\_MIR},
	pages = {318--330}
}

@article{mcvicar_automatic_2014,
	title = {Automatic {Chord} {Estimation} from {Audio}: {A} {Review} of the {State} of the {Art}},
	volume = {22},
	issn = {2329-9290},
	shorttitle = {Automatic {Chord} {Estimation} from {Audio}},
	doi = {10.1109/TASLP.2013.2294580},
	abstract = {In this overview article, we review research on the task of Automatic Chord Estimation (ACE). The major contributions from the last 14 years of research are summarized, with detailed discussions of the following topics: feature extraction, modeling strategies, model training and datasets, and evaluation strategies. Results from the annual benchmarking evaluation Music Information Retrieval Evaluation eXchange (MIREX) are also discussed as well as developments in software implementations and the impact of ACE within MIR. We conclude with possible directions for future research.},
	number = {2},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	author = {McVicar, Matt and Santos-Rodríguez, Raul and Ni, Yizhao and Bie, Tijl De},
	month = feb,
	year = {2014},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey},
	pages = {556--575}
}

@inproceedings{vaswani_attention_2017,
	address = {Long Beach, CA},
	title = {Attention {Is} {All} {You} {Need}},
	url = {http://arxiv.org/abs/1706.03762},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
	urldate = {2019-08-05},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 30 ({NIPS} 2017)},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
	month = jun,
	year = {2017},
	keywords = {Comps, Comps\_Q2}
}

@inproceedings{mauch_approximate_2010,
	address = {Utrecht, Netherlands},
	title = {Approximate {Note} {Transcription} for the {Improved} {Identification} of {Difficult} {Chords}},
	abstract = {The automatic detection and transcription of musical chords from audio is an established music computing task. The choice of chord profiles and higher-level time-series modelling have received a lot of attention, resulting in methods with an overall performance of more than 70\% in the MIREX Chord Detection task 2009. Research on the front end of chord transcription algorithms has often concentrated on finding good chord templates to fit the chroma features. In this paper we reverse this approach and seek to find chroma features that are more suitable for usage in a musically-motivated model. We do so by performing a prior approximate transcription using an existing technique to solve non-negative least squares problems (NNLS). The resulting NNLS chroma features are tested by using them as an input to an existing state-of-the-art high-level model for chord transcription. We achieve very good results of 80\% accuracy using the song collection and metric of the 2009 MIREX Chord Detection tasks. This is a significant increase over the top result (74\%) in MIREX 2009. The nature of some chords makes their identification particularly susceptible to confusion between fundamental frequency and partials. We show that the recognition of these diffcult},
	booktitle = {Proceedings of the 11th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	author = {Mauch, Matthias and Dixon, Simon},
	year = {2010},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_FeatureExtraction}
}

@inproceedings{burgoyne_expert_2011,
	address = {Miami, USA},
	title = {An {Expert} {Ground} {Truth} {Set} for {Audio} {Chord} {Recognition} and {Music} {Analysis}},
	volume = {11},
	booktitle = {Proceedings of the 12th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	author = {Burgoyne, John Ashley and Wild, Jonathan and Fujinaga, Ichiro},
	year = {2011},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Dataset},
	pages = {633--638}
}

@article{sigtia_end--end_2016,
	title = {An {End}-to-end {Neural} {Network} for {Polyphonic} {Piano} {Music} {Transcription}},
	volume = {24},
	issn = {2329-9290},
	url = {https://doi.org/10.1109/TASLP.2016.2533858},
	doi = {10.1109/TASLP.2016.2533858},
	abstract = {We present a supervised neural network model for polyphonic piano music transcription. The architecture of the proposed model is analogous to speech recognition systems and comprises an acoustic model and a music language model. The acoustic model is a neural network used for estimating the probabilities of pitches in a frame of audio. The language model is a recurrent neural network that models the correlations between pitch combinations over time. The proposed model is general and can be used to transcribe polyphonic music without imposing any constraints on the polyphony. The acoustic and language model predictions are combined using a probabilistic graphical model. Inference over the output variables is performed using the beam search algorithm. We perform two sets of experiments. We investigate various neural network architectures for the acoustic models and also investigate the effect of combining acoustic and music language model predictions using the proposed architecture. We compare performance of the neural network-based acoustic models with two popular unsupervised acoustic models. Results show that convolutional neural network acoustic models yield the best performance across all evaluation metrics. We also observe improved performance with the application of the music language models. Finally, we present an efficient variant of beam search that improves performance and reduces run-times by an order of magnitude, making the model suitable for real-time applications.},
	number = {5},
	urldate = {2019-08-06},
	journal = {IEEE/ACM Transactions on Audio, Speech and Language Processing},
	author = {Sigtia, Siddharth and Benetos, Emmanouil and Dixon, Simon},
	month = may,
	year = {2016},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_PianoTranscription, Comps\_ToDo},
	pages = {927--939}
}

@article{lee_acoustic_2008,
	title = {Acoustic {Chord} {Transcription} and {Key} {Extraction} {From} {Audio} {Using} {Key}-{Dependent} {HMMs} {Trained} on {Synthesized} {Audio}},
	volume = {16},
	issn = {1558-7916},
	doi = {10.1109/TASL.2007.914399},
	abstract = {We describe an acoustic chord transcription system that uses symbolic data to train hidden Markov models and gives best-of-class frame-level recognition results. We avoid the extremely laborious task of human annotation of chord names and boundaries-which must be done to provide machine learning models with ground truth-by performing automatic harmony analysis on symbolic music files. In parallel, we synthesize audio from the same symbolic files and extract acoustic feature vectors which are in perfect alignment with the labels. We, therefore, generate a large set of labeled training data with a minimal amount of human labor. This allows for richer models. Thus, we build 24 key-dependent HMMs, one for each key, using the key information derived from symbolic data. Each key model defines a unique state-transition characteristic and helps avoid confusions seen in the observation vector. Given acoustic input, we identify a musical key by choosing a key model with the maximum likelihood, and we obtain the chord sequence from the optimal state path of the corresponding key model, both of which are returned by a Viterbi decoder. This not only increases the chord recognition accuracy, but also gives key information. Experimental results show the models trained on synthesized data perform very well on real recordings, even though the labels automatically generated from symbolic data are not 100\% accurate. We also demonstrate the robustness of the tonal centroid feature, which outperforms the conventional chroma feature.},
	number = {2},
	journal = {IEEE Transactions on Audio, Speech, and Language Processing},
	author = {Lee, K. and Slaney, M.},
	month = feb,
	year = {2008},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_Key, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_ToDo},
	pages = {291--301}
}

@inproceedings{ycart_-maps:_2018,
	address = {Paris, France},
	title = {A-{MAPS}: {Augmented} {Maps} {Dataset} with {Rhythm} and {Key} {Annotations}},
	abstract = {The MAPS dataset is the most used benchmark dataset for automatic music transcription (AMT). We propose here an updated version of the ground truth, containing precise beat, time signature, and key signature annotations.},
	language = {en},
	booktitle = {19th {International} {Society} for {Music} {Information} {Retrieval} {Conference} {Late}-{Breaking} {Demos} {Session}},
	author = {Ycart, Adrien and Benetos, Emmanouil},
	year = {2018},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Dataset},
	pages = {2}
}

@incollection{krumhansl_theory_2010,
	address = {New York, NY},
	series = {Springer {Handbook} of {Auditory} {Research}},
	title = {A {Theory} of {Tonal} {Hierarchies} in {Music}},
	isbn = {978-1-4419-6114-3},
	url = {https://doi.org/10.1007/978-1-4419-6114-3_3},
	abstract = {One of the most pervasive structural principles found in music historically and cross-culturally is a hierarchy of tones. Certain tones serve as reference pitches; they are stable, repeated frequently, are emphasized rhythmically, and appear at structurally important positions in musical phrases. The details of the hierarchies differ across styles and cultures. Variation occurs in the particular intervals formed by pitches in the musical scale and the hierarchical levels assigned to pitches within the scale. This variability suggests that an explanation for how these hierarchies are formed cannot be derived from invariant acoustic facts, such as the harmonic structure (overtones) of complex tones. Rather, the evidence increasingly suggests that these hierarchies are products of cognition and, moreover, that they rely on fundamental psychological principles shared by other domains of perception and cognition.},
	language = {en},
	urldate = {2019-08-06},
	booktitle = {Music {Perception}},
	publisher = {Springer New York},
	author = {Krumhansl, Carol L. and Cuddy, Lola L.},
	editor = {Riess Jones, Mari and Fay, Richard R. and Popper, Arthur N.},
	year = {2010},
	keywords = {Comps, Comps\_Q8},
	pages = {51--87}
}

@inproceedings{hu_probabilistic_2009,
	address = {Kobe, Japan},
	title = {A {Probabilistic} {Topic} {Model} for {Unsupervised} {Learning} of {Musical} {Key}-{Profiles}.},
	booktitle = {Proceedings of the 10th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	author = {Hu, Diane and Saul, Lawrence K.},
	year = {2009},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Q4, Comps\_Q4\_AudioKey},
	pages = {441--446}
}

@inproceedings{faraldo_multi-profile_2017,
	address = {Erlangen, Germany},
	title = {A {Multi}-{Profile} {Method} for {Key} {Estimation} in {EDM}},
	url = {http://www.aes.org/e-lib/browse.cfm?elib=18775},
	abstract = {Key detection in electronic dance music is important for producers and DJ's who want to mix their tracks harmonically or organise their music collection by tonal content. In this paper, we present an algorithm that improves the performance of an existing method by introducing a system of multiple profiles, addressing difficult minor tracks as well as possibly amodal ones. After the explanation of our method, we use three independent datasets of electronic dance music to evaluate its...},
	language = {English},
	urldate = {2019-08-06},
	booktitle = {Audio {Engineering} {Society} {Conference}: 2017 {AES} {International} {Conference} on {Semantic} {Audio}},
	publisher = {Audio Engineering Society},
	author = {Faraldo, Ángel and Jordà, Sergi and Herrera, Perfecto},
	month = jun,
	year = {2017},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey}
}

@inproceedings{white_corpus-sensitive_2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Corpus}-{Sensitive} {Algorithm} for {Automated} {Tonal} {Analysis}},
	isbn = {978-3-319-20603-5},
	abstract = {A corpus-sensitive algorithm for tonal analysis is described. The algorithm learns a tonal vocabulary and syntax by grouping together chords that share scale degrees and occur in the same contexts and then compiling a transition matrix between these chord groups. When trained on a common-practice corpus, the resulting vocabulary of chord groups approximates traditional diatonic Roman numerals. These parameters are then used to determine the key and vocabulary items used in an unanalyzed piece of music. Such a corpus-based method highlights the properties of common-practice music on which traditional analysis is based, while offering the opportunity for analytical and pedagogical methods more sensitive to the characteristics of individual repertories.},
	language = {en},
	booktitle = {Mathematics and {Computation} in {Music}},
	publisher = {Springer International Publishing},
	author = {White, Christopher Wm.},
	editor = {Collins, Tom and Meredith, David and Volk, Anja},
	year = {2015},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic, Comps\_Q5},
	pages = {115--121}
}

@article{clercq_corpus_2011,
	title = {A {Corpus} {Analysis} of {Rock} {Harmony}},
	volume = {30},
	issn = {0261-1430, 1474-0095},
	url = {https://www.cambridge.org/core/journals/popular-music/article/corpus-analysis-of-rock-harmony/C5210A8EC985DDF170B53124F4464DA4},
	doi = {10.1017/S026114301000067X},
	abstract = {In this study, we report a corpus analysis of rock harmony. As a corpus, we used Rolling Stone magazine's list of the ‘500 Greatest Songs of All Time’; we took the 20 top-ranked songs from each decade (the 1950s through the 1990s), creating a set of 100 songs. Both authors analysed all 100 songs by hand, using conventional Roman numeral symbols. Agreement between the two sets of analyses was over 90 per cent. The analyses were encoded using a recursive notation, similar to a context-free grammar, allowing repeating sections to be encoded succinctly. The aggregate data was then subjected to a variety of statistical analyses. We examined the frequency of different chords and chord transitions. The results showed that IV is the most common chord after I and is especially common preceding the tonic. Other results concern the frequency of different root motions, patterns of co-occurrence between chords, and changes in harmonic practice across time.},
	language = {en},
	number = {1},
	urldate = {2019-08-05},
	journal = {Popular Music},
	author = {Clercq, Trevor de and Temperley, David},
	month = jan,
	year = {2011},
	keywords = {Comps, Comps\_Q5},
	pages = {47--70}
}

@inproceedings{temperley_bayesian_2002,
	address = {Edinburgh, Scotland},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {A {Bayesian} {Approach} to {Key}-{Finding}},
	isbn = {978-3-540-45722-0},
	abstract = {The key-profile model (originally proposed by Krumhansl and Schmuckler, and modified by Temperley) has proven to be a highly successful approach to key-finding. It appears that the key-profile model can be reinterpreted, with a few small modifications, as a Bayesian probabilistic model. This move sheds interesting light on a number of issues, including the psychological motivation for the key-profile model, other aspects of musical cognition such as metrical analysis, and issues such as ambiguity and expectation.},
	language = {en},
	booktitle = {Music and {Artificial} {Intelligence}},
	publisher = {Springer Berlin Heidelberg},
	author = {Temperley, David},
	editor = {Anagnostopoulou, Christina and Ferrand, Miguel and Smaill, Alan},
	year = {2002},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic, Comps\_Q5, Comps\_Summarized},
	pages = {195--206}
}

@inproceedings{gururani_instrument_2018,
	address = {Paris, France},
	title = {Instrument {Activity} {Detection} in {Polyphonic} {Music} using {Deep} {Neural} {Networks}},
	url = {https://doi.org/10.5281/zenodo.1492479},
	doi = {10.5281/zenodo.1492479},
	booktitle = {Proceedings of the 19th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Gururani, Siddharth and Summers, Cameron and Lerch, Alexander},
	month = sep,
	year = {2018},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_InstrumentActivity, Comps\_ToDo},
	pages = {569--576}
}

@inproceedings{delbouys_music_2018,
	address = {Paris, France},
	title = {Music {Mood} {Detection} {Based} on {Audio} and {Lyrics} with {Deep} {Neural} {Net}},
	url = {https://doi.org/10.5281/zenodo.1492427},
	doi = {10.5281/zenodo.1492427},
	booktitle = {Proceedings of the 19th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Delbouys, Rémi and Hennequin, Romain and Piccoli, Francesco and Royo-Letelier, Jimena and Moussallam, Manuel},
	month = sep,
	year = {2018},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_MoodDetection, Comps\_ToDo},
	pages = {370--375}
}

@inproceedings{stoller_wave-u-net:_2018,
	address = {Paris, France},
	title = {Wave-{U}-{Net}: {A} {Multi}-{Scale} {Neural} {Network} for {End}- to-{End} {Audio} {Source} {Separation}},
	url = {https://doi.org/10.5281/zenodo.1492417},
	doi = {10.5281/zenodo.1492417},
	booktitle = {Proceedings of the 19th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Stoller, Daniel and Ewert, Sebastian and Dixon, Simon},
	month = sep,
	year = {2018},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_SourceSeparation, Comps\_Q2\_UNet, Comps\_ToDo},
	pages = {334--340}
}

@inproceedings{valk_deep_2018,
	address = {Paris, France},
	title = {Deep {Neural} {Networks} with {Voice} {Entry} {Estimation} {Heuristics} for {Voice} {Separation} in {Symbolic} {Music} {Representations}},
	url = {https://doi.org/10.5281/zenodo.1492403},
	doi = {10.5281/zenodo.1492403},
	booktitle = {Proceedings of the 19th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Valk, Reinier de and Weyde, Tillman},
	month = sep,
	year = {2018},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_VoiceSeparation, Comps\_ToDo},
	pages = {281--288}
}

@inproceedings{korzeniowski_genre-agnostic_2018,
	address = {Paris, France},
	title = {Genre-{Agnostic} {Key} {Classification} {With} {Convolutional} {Neural} {Networks}},
	url = {https://doi.org/10.5281/zenodo.1492399},
	doi = {10.5281/zenodo.1492399},
	booktitle = {Proceedings of the 19th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Korzeniowski, Filip and Widmer, Gerhard},
	month = sep,
	year = {2018},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_Key, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_ToDo},
	pages = {264--270}
}

@inproceedings{castellanos_document_2018,
	address = {Paris, France},
	title = {Document {Analysis} of {Music} {Score} {Images} with {Selectional} {Auto}-{Encoders}},
	url = {https://doi.org/10.5281/zenodo.1492397},
	doi = {10.5281/zenodo.1492397},
	booktitle = {Proceedings of the 19th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Castellanos, Francisco and Calvo-Zaragoza, Jorge and Vigliensoni, Gabriel and Fujinaga, Ichiro},
	month = sep,
	year = {2018},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_Autoencoders, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_OMR, Comps\_ToDo},
	pages = {256--263}
}

@inproceedings{calvo-zaragoza_camera-primus:_2018,
	address = {Paris, France},
	title = {Camera-{PrIMuS}: {Neural} {End}-to-{End} {Optical} {Music} {Recognition} on {Realistic} {Monophonic} {Scores}},
	url = {https://doi.org/10.5281/zenodo.1492395},
	doi = {10.5281/zenodo.1492395},
	booktitle = {Proceedings of the 19th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Calvo-Zaragoza, Jorge and Rizo, David},
	month = sep,
	year = {2018},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_OMR, Comps\_ToDo},
	pages = {248--255}
}

@inproceedings{pacha_optical_2018,
	address = {Paris, France},
	title = {Optical {Music} {Recognition} in {Mensural} {Notation} with {Region}-based {Convolutional} {Neural} {Networks}},
	url = {https://doi.org/10.5281/zenodo.1492393},
	doi = {10.5281/zenodo.1492393},
	booktitle = {Proceedings of the 19th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Pacha, Alexander and Calvo-Zaragoza, Jorge},
	month = sep,
	year = {2018},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_OMR, Comps\_ToDo},
	pages = {240--247}
}
@inproceedings{sears_evaluating_2018,
	address = {Paris, France},
	title = {Evaluating {Language} {Models} of {Tonal} {Harmony}},
	url = {https://doi.org/10.5281/zenodo.1492385},
	doi = {10.5281/zenodo.1492385},
	booktitle = {Proceedings of the 19th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Sears, David and Korzeniowski, Filip and Widmer, Gerhard},
	month = sep,
	year = {2018},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_Harmony, Comps\_ToDo},
	pages = {211--217}
}

@inproceedings{schreiber_single-step_2018,
	address = {Paris, France},
	title = {A {Single}-step {Approach} to {Musical} {Tempo} {Estimation} using a {Convolutional} {Neural} {Network}},
	url = {https://doi.org/10.5281/zenodo.1492353},
	doi = {10.5281/zenodo.1492353},
	booktitle = {Proceedings of the 19th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Schreiber, Hendrik and Müller, Meinard},
	month = sep,
	year = {2018},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_TempoEstimation, Comps\_ToDo},
	pages = {98--105}
}

@inproceedings{basaran_main_2018,
	address = {Paris, France},
	title = {Main {Melody} {Estimation} with {Source}-{Filter} {NMF} and {CRNN}},
	url = {https://doi.org/10.5281/zenodo.1492349},
	doi = {10.5281/zenodo.1492349},
	booktitle = {Proceedings of the 19th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Basaran, Dogac and Essid, Slim and Peeters, Geoffroy},
	month = sep,
	year = {2018},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_MelodyTranscription, Comps\_ToDo},
	pages = {82--89}
}

@inproceedings{jansson_singing_2017,
	address = {Suzhou, China},
	title = {Singing {Voice} {Separation} with {Deep} {U}-{Net} {Convolutional} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1414934},
	doi = {10.5281/zenodo.1414934},
	booktitle = {Proceedings of the 18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Jansson, Andreas and Humphrey, Eric J. and Montecchio, Nicola and Bittner, Rachel M. and Kumar, Aparna and Weyde, Tillman},
	month = oct,
	year = {2017},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_SourceSeparation, Comps\_Q2\_UNet, Comps\_ToDo},
	pages = {745--751}
}

@inproceedings{wel_optical_2017,
	address = {Suzhou, China},
	title = {Optical {Music} {Recognition} with {Convolutional} {Sequence}-to-{Sequence} {Models}.},
	url = {https://doi.org/10.5281/zenodo.1415664},
	doi = {10.5281/zenodo.1415664},
	booktitle = {Proceedings of the 18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Wel, Eelco van der and Ullrich, Karen},
	month = oct,
	year = {2017},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_OMR, Comps\_ToDo},
	pages = {731--737}
}

@inproceedings{calvo-zaragoza_one-step_2017,
	address = {Suzhou, China},
	title = {One-{Step} {Detection} of {Background}, {Staff} {Lines}, and {Symbols} in {Medieval} {Music} {Manuscripts} with {Convolutional} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1417493},
	doi = {10.5281/zenodo.1417493},
	booktitle = {Proceedings of the 18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Calvo-Zaragoza, Jorge and Vigliensoni, Gabriel and Fujinaga, Ichiro},
	month = oct,
	year = {2017},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_OMR, Comps\_ToDo},
	pages = {724--730}
}

@inproceedings{lim_chord_2017,
	address = {Suzhou, China},
	title = {Chord {Generation} from {Symbolic} {Melody} {Using} {BLSTM} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1417327},
	doi = {10.5281/zenodo.1417327},
	booktitle = {Proceedings of the 18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Lim, Hyungui and Rhyu, Seungyeon and Lee, Kyogu},
	month = oct,
	year = {2017},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_MusicGeneration, Comps\_ToDo},
	pages = {621--627}
}

@inproceedings{southall_automatic_2017,
	address = {Suzhou, China},
	title = {Automatic {Drum} {Transcription} for {Polyphonic} {Recordings} {Using} {Soft} {Attention} {Mechanisms} and {Convolutional} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1415616},
	doi = {10.5281/zenodo.1415616},
	booktitle = {Proceedings of the 18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Southall, Carl and Stables, Ryan and Hockman, Jason},
	month = oct,
	year = {2017},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_DrumTranscription, Comps\_ToDo},
	pages = {606--612}
}

@inproceedings{cazau_improving_2017,
	address = {Suzhou, China},
	title = {Improving {Note} {Segmentation} in {Automatic} {Piano} {Music} {Transcription} {Systems} with a {Two}-{State} {Pitch}-{Wise} {HMM} {Method}.},
	url = {https://doi.org/10.5281/zenodo.1417929},
	doi = {10.5281/zenodo.1417929},
	booktitle = {Proceedings of the 18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Cazau, Dorian and Wang, Yuancheng and Adam, Olivier and Wang, Qiao and Nuel, Grégory},
	month = oct,
	year = {2017},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_NoteSegmentation, Comps\_ToDo},
	pages = {523--530}
}

@inproceedings{calvo-zaragoza_end--end_2017,
	address = {Suzhou, China},
	title = {End-to-{End} {Optical} {Music} {Recognition} {Using} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1418333},
	doi = {10.5281/zenodo.1418333},
	booktitle = {Proceedings of the 18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Calvo-Zaragoza, Jorge and Valero-Mas, Jose J. and Pertusa, Antonio},
	month = oct,
	year = {2017},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_OMR, Comps\_ToDo},
	pages = {472--477}
}

@inproceedings{liang_automatic_2017,
	address = {Suzhou, China},
	title = {Automatic {Stylistic} {Composition} of {Bach} {Chorales} with {Deep} {LSTM}.},
	url = {https://doi.org/10.5281/zenodo.1416208},
	doi = {10.5281/zenodo.1416208},
	booktitle = {Proceedings of the 18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Liang, Feynman T. and Gotham, Mark and Johnson 0003, Matthew and Shotton, Jamie},
	month = oct,
	year = {2017},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_MusicGeneration, Comps\_ToDo},
	pages = {449--456}
}

@inproceedings{ycart_study_2017,
	address = {Suzhou, China},
	title = {A {Study} on {LSTM} {Networks} for {Polyphonic} {Music} {Sequence} {Modelling}.},
	url = {https://doi.org/10.5281/zenodo.1415018},
	doi = {10.5281/zenodo.1415018},
	booktitle = {Proceedings of the 18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Ycart, Adrien and Benetos, Emmanouil},
	month = oct,
	year = {2017},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_SequenceModelling, Comps\_ToDo},
	pages = {421--427}
}

@inproceedings{pons_score-informed_2017,
	address = {Suzhou, China},
	title = {Score-{Informed} {Syllable} {Segmentation} for {A} {Cappella} {Singing} {Voice} with {Convolutional} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1415632},
	doi = {10.5281/zenodo.1415632},
	booktitle = {Proceedings of the 18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Pons, Jordi and Gong, Rong and Serra, Xavier},
	month = oct,
	year = {2017},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_SyllableSegmentation, Comps\_ToDo},
	pages = {383--389}
}

@inproceedings{nishikimi_scale-_2017,
	address = {Suzhou, China},
	title = {Scale- and {Rhythm}-{Aware} {Musical} {Note} {Estimation} for {Vocal} {F0} {Trajectories} {Based} on a {Semi}-{Tatum}- {Synchronous} {Hierarchical} {Hidden} {Semi}-{Markov} {Model}.},
	url = {https://doi.org/10.5281/zenodo.1416330},
	doi = {10.5281/zenodo.1416330},
	booktitle = {Proceedings of the 18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Nishikimi, Ryo and Nakamura, Eita and Goto, Masataka and Itoyama, Katsutoshi and Yoshii, Kazuyoshi},
	month = oct,
	year = {2017},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_NoteEstimation, Comps\_ToDo},
	pages = {376--382}
}

@inproceedings{yang_midinet:_2017,
	address = {Suzhou, China},
	title = {{MidiNet}: {A} {Convolutional} {Generative} {Adversarial} {Network} for {Symbolic}-{Domain} {Music} {Generation}.},
	url = {https://doi.org/10.5281/zenodo.1415990},
	doi = {10.5281/zenodo.1415990},
	booktitle = {Proceedings of the 18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Yang, Li-Chia and Chou, Szu-Yu and Yang, Yi-Hsuan},
	month = oct,
	year = {2017},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_MusicGeneration, Comps\_ToDo},
	pages = {324--331}
}

@inproceedings{gkiokas_convolutional_2017,
	address = {Suzhou, China},
	title = {Convolutional {Neural} {Networks} for {Real}-{Time} {Beat} {Tracking}: {A} {Dancing} {Robot} {Application}.},
	url = {https://doi.org/10.5281/zenodo.1417737},
	doi = {10.5281/zenodo.1417737},
	booktitle = {Proceedings of the 18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Gkiokas, Aggelos and Katsouros, Vassilios},
	month = oct,
	year = {2017},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_BeatTracking, Comps\_ToDo},
	pages = {286--293}
}

@inproceedings{pauwels_confidence_2017,
	address = {Suzhou, China},
	title = {Confidence {Measures} and {Their} {Applications} in {Music} {Labelling} {Systems} {Based} on {Hidden} {Markov} {Models}.},
	url = {https://doi.org/10.5281/zenodo.1418155},
	doi = {10.5281/zenodo.1418155},
	booktitle = {Proceedings of the 18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Pauwels, Johan and O'Hanlon, Ken and Fazekas, György and Sandler, Mark B.},
	month = oct,
	year = {2017},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_MusicLabelling, Comps\_ToDo},
	pages = {279--285}
}

@inproceedings{masada_chord_2017,
	address = {Suzhou, China},
	title = {Chord {Recognition} in {Symbolic} {Music} {Using} {Semi}- {Markov} {Conditional} {Random} {Fields}.},
	url = {https://doi.org/10.5281/zenodo.1418343},
	doi = {10.5281/zenodo.1418343},
	booktitle = {Proceedings of the 18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Masada, Kristen and Bunescu, Razvan C.},
	month = oct,
	year = {2017},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_ChordRecognition, Comps\_ToDo},
	pages = {272--278}
}

@inproceedings{vogl_drum_2017,
	address = {Suzhou, China},
	title = {Drum {Transcription} via {Joint} {Beat} and {Drum} {Modeling} {Using} {Convolutional} {Recurrent} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1415136},
	doi = {10.5281/zenodo.1415136},
	booktitle = {Proceedings of the 18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Vogl, Richard and Dorfer, Matthias and Widmer, Gerhard and Knees, Peter},
	month = oct,
	year = {2017},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_ToDo},
	pages = {150--157}
}

@inproceedings{miron_monaural_2017,
	address = {Suzhou, China},
	title = {Monaural {Score}-{Informed} {Source} {Separation} for {Classical} {Music} {Using} {Convolutional} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1416498},
	doi = {10.5281/zenodo.1416498},
	booktitle = {Proceedings of the 18th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Miron, Marius and Janer, Jordi and Gómez, Emilia},
	month = oct,
	year = {2017},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_SourceSeparation, Comps\_ToDo},
	pages = {55--62}
}

@inproceedings{kum_melody_2016,
	address = {New York City, United States},
	title = {Melody {Extraction} on {Vocal} {Segments} {Using} {Multi}- {Column} {Deep} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1414788},
	doi = {10.5281/zenodo.1414788},
	booktitle = {Proceedings of the 17th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Kum, Sangeun and Oh, Changheun and Nam, Juhan},
	month = aug,
	year = {2016},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_MelodyTranscription, Comps\_ToDo},
	pages = {819--825}
}

@inproceedings{choi_automatic_2016,
	address = {New York City, United States},
	title = {Automatic {Tagging} {Using} {Deep} {Convolutional} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1416254},
	doi = {10.5281/zenodo.1416254},
	booktitle = {Proceedings of the 17th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Choi, Keunwoo and Fazekas, György and Sandler, Mark B.},
	month = aug,
	year = {2016},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_AutomaticTagging, Comps\_ToDo},
	pages = {805--811}
}

@inproceedings{rigaud_singing_2016,
	address = {New York City, United States},
	title = {Singing {Voice} {Melody} {Transcription} {Using} {Deep} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1418051},
	doi = {10.5281/zenodo.1418051},
	booktitle = {Proceedings of the 17th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Rigaud, François and Radenen, Mathieu},
	month = aug,
	year = {2016},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_MelodyTranscription, Comps\_ToDo},
	pages = {737--743}
}

@inproceedings{vogl_recurrent_2016,
	address = {New York City, United States},
	title = {Recurrent {Neural} {Networks} for {Drum} {Transcription}.},
	url = {https://doi.org/10.5281/zenodo.1417613},
	doi = {10.5281/zenodo.1417613},
	booktitle = {Proceedings of the 17th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Vogl, Richard and Dorfer, Matthias and Knees, Peter},
	month = aug,
	year = {2016},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_DrumTranscription, Comps\_ToDo},
	pages = {730--736}
}

@inproceedings{lostanlen_deep_2016,
	address = {New York City, United States},
	title = {Deep {Convolutional} {Networks} on the {Pitch} {Spiral} {For} {Music} {Instrument} {Recognition}.},
	url = {https://doi.org/10.5281/zenodo.1416928},
	doi = {10.5281/zenodo.1416928},
	booktitle = {Proceedings of the 17th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Lostanlen, Vincent and Cella, Carmine-Emanuele},
	month = aug,
	year = {2016},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_InstrumentRecognition, Comps\_ToDo},
	pages = {612--618}
}

@inproceedings{southall_automatic_2016,
	address = {New York City, United States},
	title = {Automatic {Drum} {Transcription} {Using} {Bi}-{Directional} {Recurrent} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1416244},
	doi = {10.5281/zenodo.1416244},
	booktitle = {Proceedings of the 17th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Southall, Carl and Stables, Ryan and Hockman, Jason},
	month = aug,
	year = {2016},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_DrumTranscription, Comps\_ToDo},
	pages = {591--597}
}

@inproceedings{hori_minimax_2016,
	address = {New York City, United States},
	title = {Minimax {Viterbi} {Algorithm} for {HMM}-{Based} {Guitar} {Fingering} {Decision}.},
	url = {https://doi.org/10.5281/zenodo.1417639},
	doi = {10.5281/zenodo.1417639},
	booktitle = {Proceedings of the 17th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Hori, Gen and Sagayama, Shigeki},
	month = aug,
	year = {2016},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_GuitarFingering, Comps\_ToDo},
	pages = {448--453}
}

@inproceedings{bock_joint_2016,
	address = {New York City, United States},
	title = {Joint {Beat} and {Downbeat} {Tracking} with {Recurrent} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1415836},
	doi = {10.5281/zenodo.1415836},
	booktitle = {Proceedings of the 17th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Böck, Sebastian and Krebs, Florian and Widmer, Gerhard},
	month = aug,
	year = {2016},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_Downbeat, Comps\_ToDo},
	pages = {255--261}
}

@inproceedings{driedger_template-based_2016,
	address = {New York City, United States},
	title = {Template-{Based} {Vibrato} {Analysis} in {Complex} {Music} {Signals}.},
	url = {https://doi.org/10.5281/zenodo.1417006},
	doi = {10.5281/zenodo.1417006},
	booktitle = {Proceedings of the 17th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Driedger, Jonathan and Balke, Stefan and Ewert, Sebastian and Müller, Meinard},
	month = aug,
	year = {2016},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Specificities},
	pages = {239--245}
}

@inproceedings{liu_predicting_2016,
	address = {New York City, United States},
	title = {Predicting {Missing} {Music} {Components} with {Bidirectional} {Long} {Short}-{Term} {Memory} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1417239},
	doi = {10.5281/zenodo.1417239},
	booktitle = {Proceedings of the 17th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Liu, I.-Ting and Randall, Richard},
	month = aug,
	year = {2016},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_MissingMusic, Comps\_ToDo},
	pages = {225--231}
}

@inproceedings{krebs_downbeat_2016,
	address = {New York City, United States},
	title = {Downbeat {Tracking} {Using} {Beat} {Synchronous} {Features} with {Recurrent} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1417819},
	doi = {10.5281/zenodo.1417819},
	booktitle = {Proceedings of the 17th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Krebs, Florian and Böck, Sebastian and Dorfer, Matthias and Widmer, Gerhard},
	month = aug,
	year = {2016},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_Downbeat, Comps\_ToDo},
	pages = {129--135}
}

@inproceedings{yang_ava:_2016,
	address = {New York City, United States},
	title = {{AVA}: {An} {Interactive} {System} for {Visual} and {Quantitative} {Analyses} of {Vibrato} and {Portamento} {Performance} {Styles}.},
	url = {https://doi.org/10.5281/zenodo.1415592},
	doi = {10.5281/zenodo.1415592},
	booktitle = {Proceedings of the 17th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Yang, Luwei and Rajab, Khalid Z. and Chew, Elaine},
	month = aug,
	year = {2016},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Specificities},
	pages = {108--114}
}

@inproceedings{allik_ontology_2016,
	address = {New York City, United States},
	title = {An {Ontology} for {Audio} {Features}.},
	url = {https://doi.org/10.5281/zenodo.1416226},
	doi = {10.5281/zenodo.1416226},
	booktitle = {Proceedings of the 17th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Allik, Alo and Fazekas, György and Sandler, Mark B.},
	month = aug,
	year = {2016},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_FeatureExtraction},
	pages = {73--79}
}

@inproceedings{lambert_adaptive_2016,
	address = {New York City, United States},
	title = {Adaptive {Frequency} {Neural} {Networks} for {Dynamic} {Pulse} and {Metre} {Perception}.},
	url = {https://doi.org/10.5281/zenodo.1418305},
	doi = {10.5281/zenodo.1418305},
	booktitle = {Proceedings of the 17th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Lambert, Andrew John and Weyde, Tillman and Armstrong, Newton},
	month = aug,
	year = {2016},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_PulseMetre, Comps\_ToDo},
	pages = {60--66}
}

@article{korzeniowski_feature_2016,
	title = {Feature {Learning} for {Chord} {Recognition}: {The} {Deep} {Chroma} {Extractor}},
	shorttitle = {Feature learning for chord recognition},
	journal = {arXiv preprint arXiv:1612.05065},
	author = {Korzeniowski, Filip and Widmer, Gerhard},
	year = {2016},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_FeatureExtraction}
}

@inproceedings{abeser_score-informed_2015,
	address = {Málaga, Spain},
	title = {Score-{Informed} {Analysis} of {Intonation} and {Pitch} {Modulation} in {Jazz} {Solos}.},
	url = {https://doi.org/10.5281/zenodo.1416836},
	doi = {10.5281/zenodo.1416836},
	booktitle = {Proceedings of the 16th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Abeßer, Jakob and Cano, Estefanía and Frieler, Klaus and Pfleiderer, Martin and Zaddach, Wolf-Georg},
	month = oct,
	year = {2015},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Specificities},
	pages = {823--829}
}

@inproceedings{jancovic_automatic_2015,
	address = {Málaga, Spain},
	title = {Automatic {Transcription} of {Ornamented} {Irish} {Traditional} {Flute} {Music} {Using} {Hidden} {Markov} {Models}.},
	url = {https://doi.org/10.5281/zenodo.1415116},
	doi = {10.5281/zenodo.1415116},
	booktitle = {Proceedings of the 16th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Jancovic, Peter and Köküer, Münevver and Baptiste, Wrena},
	month = oct,
	year = {2015},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_Transcription, Comps\_ToDo},
	pages = {756--762}
}

@inproceedings{bock_accurate_2015,
	address = {Málaga, Spain},
	title = {Accurate {Tempo} {Estimation} {Based} on {Recurrent} {Neural} {Networks} and {Resonating} {Comb} {Filters}.},
	url = {https://doi.org/10.5281/zenodo.1416026},
	doi = {10.5281/zenodo.1416026},
	booktitle = {Proceedings of the 16th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Böck, Sebastian and Krebs, Florian and Widmer, Gerhard},
	month = oct,
	year = {2015},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_TempoEstimation, Comps\_ToDo},
	pages = {625--631}
}

@inproceedings{grill_music_2015,
	address = {Málaga, Spain},
	title = {Music {Boundary} {Detection} {Using} {Neural} {Networks} on {Combined} {Features} and {Two}-{Level} {Annotations}.},
	url = {https://doi.org/10.5281/zenodo.1417461},
	doi = {10.5281/zenodo.1417461},
	booktitle = {Proceedings of the 16th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Grill, Thomas and Schlüter, Jan},
	month = oct,
	year = {2015},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_BoundaryDetection, Comps\_ToDo},
	pages = {531--537}
}

@inproceedings{inskip_their_2015,
	address = {Málaga, Spain},
	title = {In {Their} {Own} {Words}: {Using} {Text} {Analysis} to {Identify} {Musicologists}' {Attitudes} towards {Technology}.},
	url = {https://doi.org/10.5281/zenodo.1416422},
	doi = {10.5281/zenodo.1416422},
	booktitle = {Proceedings of the 16th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Inskip, Charles and Wiering, Frans},
	month = oct,
	year = {2015},
	keywords = {Comps, Comps\_Q5},
	pages = {455--461}
}

@inproceedings{nakamura_autoregressive_2015,
	address = {Málaga, Spain},
	title = {Autoregressive {Hidden} {Semi}-{Markov} {Model} of {Symbolic} {Music} {Performance} for {Score} {Following}.},
	url = {https://doi.org/10.5281/zenodo.1417030},
	doi = {10.5281/zenodo.1417030},
	booktitle = {Proceedings of the 16th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Nakamura, Eita and Cuvillier, Philippe and Cont, Arshia and Ono, Nobutaka and Sagayama, Shigeki},
	month = oct,
	year = {2015},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_ScoreFollowing, Comps\_ToDo},
	pages = {392--398}
}

@inproceedings{liang_content-aware_2015,
	address = {Málaga, Spain},
	title = {Content-{Aware} {Collaborative} {Music} {Recommendation} {Using} {Pre}-trained {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1416308},
	doi = {10.5281/zenodo.1416308},
	booktitle = {Proceedings of the 16th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Liang, Dawen and Zhan, Minshu and Ellis, Daniel P. W.},
	month = oct,
	year = {2015},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_MusicRecommendation, Comps\_ToDo},
	pages = {295--301}
}

@inproceedings{sigtia_audio_2015,
	address = {Málaga, Spain},
	title = {Audio {Chord} {Recognition} with a {Hybrid} {Recurrent} {Neural} {Network}.},
	url = {https://doi.org/10.5281/zenodo.1416594},
	doi = {10.5281/zenodo.1416594},
	booktitle = {Proceedings of the 16th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Sigtia, Siddharth and Boulanger-Lewandowski, Nicolas and Dixon, Simon},
	month = oct,
	year = {2015},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_ChordRecognition, Comps\_ToDo},
	pages = {127--133}
}

@inproceedings{zhou_chord_2015,
	address = {Málaga, Spain},
	title = {Chord {Detection} {Using} {Deep} {Learning}.},
	url = {https://doi.org/10.5281/zenodo.1416968},
	doi = {10.5281/zenodo.1416968},
	booktitle = {Proceedings of the 16th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Zhou, Xinquan and Lerch, Alexander},
	month = oct,
	year = {2015},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_ChordRecognition, Comps\_ToDo},
	pages = {52--58}
}

@inproceedings{weis_impact_2015,
	address = {Málaga, Spain},
	title = {On the {Impact} of {Key} {Detection} {Performance} for {Identifying} {Classical} {Music} {Styles}.},
	url = {https://doi.org/10.5281/zenodo.1416246},
	doi = {10.5281/zenodo.1416246},
	booktitle = {Proceedings of the 16th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Weiß, Christof and Schaab, Maximilian},
	month = oct,
	year = {2015},
	keywords = {Comps, Comps\_Q5},
	pages = {45--51}
}

@inproceedings{ringwalt_image_2015,
	address = {Málaga, Spain},
	title = {Image {Quality} {Estimation} for {Multi}-{Score} {OMR}.},
	url = {https://doi.org/10.5281/zenodo.1414890},
	doi = {10.5281/zenodo.1414890},
	booktitle = {Proceedings of the 16th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Ringwalt, Dan and Dannenberg, Roger B.},
	month = oct,
	year = {2015},
	keywords = {ReadLater},
	pages = {17--23}
}

@inproceedings{downie_ten_2014,
	address = {Taipei, Taiwan},
	title = {Ten {Years} of {MIREX} ({Music} {Information} {Retrieval} {Evaluation} {eXchange}): {Reflections}, {Challenges} and {Opportunities}.},
	url = {https://doi.org/10.5281/zenodo.1417181},
	doi = {10.5281/zenodo.1417181},
	booktitle = {Proceedings of the 15th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Downie, J. Stephen and Hu 0001, Xiao and Lee, Jin Ha and Choi, Kahyun and Cunningham, Sally Jo and Hao, Yun},
	month = oct,
	year = {2014},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Evaluation, Comps\_Q4\_Evaluation},
	pages = {657--662}
}

@inproceedings{nakamura_merged-output_2014,
	address = {Taipei, Taiwan},
	title = {Merged-{Output} {HMM} for {Piano} {Fingering} of {Both} {Hands}.},
	url = {https://doi.org/10.5281/zenodo.1415152},
	doi = {10.5281/zenodo.1415152},
	booktitle = {Proceedings of the 15th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Nakamura, Eita and Ono, Nobutaka and Sagayama, Shigeki},
	month = oct,
	year = {2014},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_PianoFingering, Comps\_ToDo},
	pages = {531--536}
}
@inproceedings{lam_automatic_2014,
	address = {Taipei, Taiwan},
	title = {Automatic {Key} {Partition} {Based} on {Tonal} {Organization} {Information} of {Classical} {Music}.},
	url = {https://doi.org/10.5281/zenodo.1414748},
	doi = {10.5281/zenodo.1414748},
	booktitle = {Proceedings of the 15th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Lam, Wang-Kong and Lee, Tan},
	month = oct,
	year = {2014},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic, Comps\_Q6, Comps\_Q6\_MIR},
	pages = {501--506}
}

@inproceedings{huang_singing-voice_2014,
	address = {Taipei, Taiwan},
	title = {Singing-{Voice} {Separation} from {Monaural} {Recordings} using {Deep} {Recurrent} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1415678},
	doi = {10.5281/zenodo.1415678},
	booktitle = {Proceedings of the 15th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Huang, Po-Sen and Kim, Minje and Hasegawa-Johnson, Mark and Smaragdis, Paris},
	month = oct,
	year = {2014},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_SourceSeparation, Comps\_ToDo},
	pages = {477--482}
}

@inproceedings{ullrich_boundary_2014,
	address = {Taipei, Taiwan},
	title = {Boundary {Detection} in {Music} {Structure} {Analysis} using {Convolutional} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1415886},
	doi = {10.5281/zenodo.1415886},
	booktitle = {Proceedings of the 15th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Ullrich, Karen and Schlüter, Jan and Grill, Thomas},
	month = oct,
	year = {2014},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_MusicalStructure, Comps\_ToDo},
	pages = {417--422}
}

@inproceedings{chacon_developing_2014,
	address = {Taipei, Taiwan},
	title = {Developing {Tonal} {Perception} through {Unsupervised} {Learning}.},
	url = {https://doi.org/10.5281/zenodo.1416058},
	doi = {10.5281/zenodo.1416058},
	booktitle = {Proceedings of the 15th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Chacón, Carlos Eduardo Cancino and Lattner, Stefan and Grachten, Maarten},
	month = oct,
	year = {2014},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_TonalPerception, Comps\_Q8, Comps\_ToDo},
	pages = {195--200}
}

@inproceedings{cherla_multiple_2014,
	address = {Taipei, Taiwan},
	title = {Multiple {Viewpiont} {Melodic} {Prediction} with {Fixed}- {Context} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1416944},
	doi = {10.5281/zenodo.1416944},
	booktitle = {Proceedings of the 15th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Cherla, Srikanth and Weyde, Tillman and Garcez, Artur S. d'Avila},
	month = oct,
	year = {2014},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_MelodicPrediction, Comps\_ToDo},
	pages = {101--106}
}

@inproceedings{sigtia_rnn-based_2014,
	address = {Taipei, Taiwan},
	title = {An {RNN}-based {Music} {Language} {Model} for {Improving} {Automatic} {Music} {Transcription}.},
	url = {https://doi.org/10.5281/zenodo.1416792},
	doi = {10.5281/zenodo.1416792},
	booktitle = {Proceedings of the 15th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Sigtia, Siddharth and Benetos, Emmanouil and Cherla, Srikanth and Weyde, Tillman and Garcez, Artur S. d'Avila and Dixon, Simon},
	month = oct,
	year = {2014},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_MusicTranscription, Comps\_ToDo},
	pages = {53--58}
}

@inproceedings{herwaarden_predicting_2014,
	address = {Taipei, Taiwan},
	title = {Predicting {Expressive} {Dynamics} in {Piano} {Performances} using {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1416678},
	doi = {10.5281/zenodo.1416678},
	booktitle = {Proceedings of the 15th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Herwaarden, Sam van and Grachten, Maarten and Haas, W. Bas de},
	month = oct,
	year = {2014},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_Dynamics, Comps\_ToDo},
	pages = {47--52}
}

@inproceedings{bock_local_2013,
	address = {Curitiba, Brazil},
	title = {Local {Group} {Delay} {Based} {Vibrato} and {Tremolo} {Suppression} for {Onset} {Detection}.},
	url = {https://doi.org/10.5281/zenodo.1416460},
	doi = {10.5281/zenodo.1416460},
	booktitle = {Proceedings of the 14th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Böck, Sebastian and Widmer, Gerhard},
	month = nov,
	year = {2013},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Specificities},
	pages = {361--366}
}

@inproceedings{boulanger-lewandowski_audio_2013,
	address = {Curitiba, Brazil},
	title = {Audio {Chord} {Recognition} with {Recurrent} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1418319},
	doi = {10.5281/zenodo.1418319},
	booktitle = {Proceedings of the 14th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Boulanger-Lewandowski, Nicolas and Bengio, Yoshua and Vincent, Pascal},
	month = nov,
	year = {2013},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_ChordRecognition},
	pages = {335--340}
}

@inproceedings{benetos_explicit_2013,
	address = {Curitiba, Brazil},
	title = {Explicit {Duration} {Hidden} {Markov} {Models} for {Multiple}-{Instrument} {Polyphonic} {Music} {Transcription}.},
	url = {https://doi.org/10.5281/zenodo.1416088},
	doi = {10.5281/zenodo.1416088},
	booktitle = {Proceedings of the 14th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Benetos, Emmanouil and Weyde, Tillman},
	month = nov,
	year = {2013},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_MusicTranscription, Comps\_ToDo},
	pages = {269--274}
}

@inproceedings{schmidt_learning_2013,
	address = {Curitiba, Brazil},
	title = {Learning {Rhythm} {And} {Melody} {Features} {With} {Deep} {Belief} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1417185},
	doi = {10.5281/zenodo.1417185},
	booktitle = {Proceedings of the 14th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Schmidt, Erik M. and Kim, Youngmoo},
	month = nov,
	year = {2013},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_RhythmMelody},
	pages = {21--26}
}

@inproceedings{chen_chord_2012,
	address = {Porto, Portugal},
	title = {Chord {Recognition} {Using} {Duration}-explicit {Hidden} {Markov} {Models}.},
	url = {https://doi.org/10.5281/zenodo.1417077},
	doi = {10.5281/zenodo.1417077},
	booktitle = {Proceedings of the 13th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Chen, Ruofeng and Shen, Weibin and Srinivasamurthy, Ajay and Chordia, Parag},
	month = oct,
	year = {2012},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_ChordRecognition, Comps\_ToDo},
	pages = {445--450}
}

@inproceedings{papadopoulos_modeling_2012,
	address = {Porto, Portugal},
	title = {Modeling {Chord} and {Key} {Structure} with {Markov} {Logic}.},
	url = {https://doi.org/10.5281/zenodo.1416724},
	doi = {10.5281/zenodo.1416724},
	booktitle = {Proceedings of the 13th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Papadopoulos, Hélène and Tzanetakis, George},
	month = oct,
	year = {2012},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_ToDo},
	pages = {127--132}
}

@inproceedings{battenberg_analyzing_2012,
	address = {Porto, Portugal},
	title = {Analyzing {Drum} {Patterns} {Using} {Conditional} {Deep} {Belief} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1417955},
	doi = {10.5281/zenodo.1417955},
	booktitle = {Proceedings of the 13th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Battenberg, Eric and Wessel, David},
	month = oct,
	year = {2012},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_DrumPatterns},
	pages = {37--42}
}

@inproceedings{dieleman_audio-based_2011,
	address = {Miami, United States},
	title = {Audio-based {Music} {Classification} with a {Pretrained} {Convolutional} {Network}.},
	url = {https://doi.org/10.5281/zenodo.1415188},
	doi = {10.5281/zenodo.1415188},
	booktitle = {Proceedings of the 12th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Dieleman, Sander and Brakel, Philemon and Schrauwen, Benjamin},
	month = oct,
	year = {2011},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_MusicClassification},
	pages = {669--674}
}

@inproceedings{bugge_using_2011,
	address = {Miami, United States},
	title = {Using {Sequence} {Alignment} and {Voting} to {Improve} {Optical} {Music} {Recognition} from {Multiple} {Recognizers}.},
	url = {https://doi.org/10.5281/zenodo.1418175},
	doi = {10.5281/zenodo.1418175},
	booktitle = {Proceedings of the 12th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Bugge, Esben Paul and Juncher, Kim Lundsteen and Mathiasen, Brian Søborg and Simonsen, Jakob Grue},
	month = oct,
	year = {2011},
	keywords = {ReadLater},
	pages = {405--410}
}

@inproceedings{dixon_temperament_2011,
	address = {Miami, United States},
	title = {The {Temperament} {Police}: {The} {Truth}, the {Ground} {Truth}, and {Nothing} but the {Truth}.},
	url = {https://doi.org/10.5281/zenodo.1418197},
	doi = {10.5281/zenodo.1418197},
	booktitle = {Proceedings of the 12th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Dixon, Simon and Tidhar, Dan and Benetos, Emmanouil},
	month = oct,
	year = {2011},
	keywords = {ReadLater},
	pages = {281--286}
}

@inproceedings{muller_chroma_2011,
	address = {Miami, United States},
	title = {Chroma {Toolbox}: {Matlab} {Implementations} for {Extracting} {Variants} of {Chroma}-{Based} {Audio} {Features}.},
	url = {https://doi.org/10.5281/zenodo.1416032},
	doi = {10.5281/zenodo.1416032},
	booktitle = {Proceedings of the 12th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Müller, Meinard and Ewert, Sebastian},
	month = oct,
	year = {2011},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_FeatureExtraction},
	pages = {215--220}
}

@inproceedings{six_tarsos_2011,
	address = {Miami, United States},
	title = {Tarsos - a {Platform} to {Explore} {Pitch} {Scales} in {Non}-{Western} and {Western} {Music}.},
	url = {https://doi.org/10.5281/zenodo.1418355},
	doi = {10.5281/zenodo.1418355},
	booktitle = {Proceedings of the 12th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Six, Joren and Cornelis, Olmo},
	month = oct,
	year = {2011},
	keywords = {Comps, Comps\_Q5},
	pages = {169--174}
}

@inproceedings{haas_harmtrace:_2011,
	address = {Miami, United States},
	title = {{HarmTrace}: {Improving} {Harmonic} {Similarity} {Estimation} {Using} {Functional} {Harmony} {Analysis}.},
	url = {https://doi.org/10.5281/zenodo.1417063},
	doi = {10.5281/zenodo.1417063},
	booktitle = {Proceedings of the 12th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Haas, W. Bas de and Magalhães, José Pedro and Veltkamp, Remco C. and Wiering, Frans},
	month = oct,
	year = {2011},
	keywords = {ReadLater},
	pages = {67--72}
}

@inproceedings{eyben_universal_2010,
	address = {Utrecht, Netherlands},
	title = {Universal {Onset} {Detection} with {Bidirectional} {Long} {Short}-{Term} {Memory} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1417131},
	doi = {10.5281/zenodo.1417131},
	booktitle = {Proceedings of the 11th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Eyben, Florian and Böck, Sebastian and Schuller, Björn W. and Graves, Alex},
	month = aug,
	year = {2010},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_OnsetDetection},
	pages = {589--594}
}

@inproceedings{gkiokas_tempo_2010,
	address = {Utrecht, Netherlands},
	title = {Tempo {Induction} {Using} {Filterbank} {Analysis} and {Tonal} {Features}.},
	url = {https://doi.org/10.5281/zenodo.1415210},
	doi = {10.5281/zenodo.1415210},
	booktitle = {Proceedings of the 11th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Gkiokas, Aggelos and Katsouros, Vassilios and Carayannis, George},
	month = aug,
	year = {2010},
	keywords = {Comps, Comps\_Q5},
	pages = {555--558}
}

@inproceedings{honingh_pitch_2010,
	address = {Utrecht, Netherlands},
	title = {Pitch {Class} {Set} {Categories} as {Analysis} {Tools} for {Degrees} of {Tonality}.},
	url = {https://doi.org/10.5281/zenodo.1417533},
	doi = {10.5281/zenodo.1417533},
	booktitle = {Proceedings of the 11th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Honingh, Aline K. and Bod, Rens},
	month = aug,
	year = {2010},
	keywords = {Comps, Comps\_Q5},
	pages = {459--464}
}

@inproceedings{mathieu_yaafe_2010,
	address = {Utrecht, Netherlands},
	title = {{YAAFE}, an {Easy} to {Use} and {Efficient} {Audio} {Feature} {Extraction} {Software}.},
	url = {https://doi.org/10.5281/zenodo.1418321},
	doi = {10.5281/zenodo.1418321},
	booktitle = {Proceedings of the 11th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Mathieu, Benoît and Essid, Slim and Fillon, Thomas and Prado, Jacques and Richard, Gaël},
	month = aug,
	year = {2010},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_FeatureExtraction},
	pages = {441--446}
}

@inproceedings{raczynski_multiple_2010,
	address = {Utrecht, Netherlands},
	title = {Multiple {Pitch} {Transcription} using {DBN}-based {Musicological} {Models}.},
	url = {https://doi.org/10.5281/zenodo.1415198},
	doi = {10.5281/zenodo.1415198},
	booktitle = {Proceedings of the 11th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Raczynski, Stanislaw Andrzej and Vincent, Emmanuel and Bimbot, Frédéric and Sagayama, Shigeki},
	month = aug,
	year = {2010},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_PitchTranscription},
	pages = {363--368}
}

@inproceedings{hamel_learning_2010,
	address = {Utrecht, Netherlands},
	title = {Learning {Features} from {Music} {Audio} with {Deep} {Belief} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1414970},
	doi = {10.5281/zenodo.1414970},
	booktitle = {Proceedings of the 11th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Hamel, Philippe and Eck, Douglas},
	month = aug,
	year = {2010},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR, Comps\_Q2\_MIR\_FeatureExtraction},
	pages = {339--344}
}

@inproceedings{paulus_improving_2010,
	address = {Utrecht, Netherlands},
	title = {Improving {Markov} {Model} {Based} {Music} {Piece} {Structure} {Labelling} with {Acoustic} {Information}.},
	url = {https://doi.org/10.5281/zenodo.1416732},
	doi = {10.5281/zenodo.1416732},
	booktitle = {Proceedings of the 11th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Paulus, Jouni},
	month = aug,
	year = {2010},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_MusicStructure, Comps\_ToDo},
	pages = {303--308}
}

@inproceedings{rocher_concurrent_2010,
	address = {Utrecht, Netherlands},
	title = {Concurrent {Estimation} of {Chords} and {Keys} from {Audio}.},
	url = {https://doi.org/10.5281/zenodo.1417485},
	doi = {10.5281/zenodo.1417485},
	booktitle = {Proceedings of the 11th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Rocher, Thomas and Robine, Matthias and Hanna, Pierre and Oudre, Laurent},
	month = aug,
	year = {2010},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey},
	pages = {141--146}
}

@inproceedings{khadkevich_use_2009,
	address = {Kobe, Japan},
	title = {Use of {Hidden} {Markov} {Models} and {Factored} {Language} {Models} for {Automatic} {Chord} {Recognition}.},
	url = {https://doi.org/10.5281/zenodo.1415930},
	doi = {10.5281/zenodo.1415930},
	booktitle = {Proceedings of the 10th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Khadkevich, Maksim and Omologo, Maurizio},
	month = oct,
	year = {2009},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_ChordRecognition, Comps\_ToDo},
	pages = {561--566}
}

@inproceedings{law_evaluation_2009,
	address = {Kobe, Japan},
	title = {Evaluation of {Algorithms} {Using} {Games}: {The} {Case} of {Music} {Tagging}.},
	url = {https://doi.org/10.5281/zenodo.1417647},
	doi = {10.5281/zenodo.1417647},
	booktitle = {Proceedings of the 10th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {ISMIR},
	author = {Law, Edith and West, Kris and Mandel, Michael I. and Bay, Mert and Downie, J. Stephen},
	month = oct,
	year = {2009},
	keywords = {ReadLater},
	pages = {387--392}
}

@inproceedings{liu_clustering_2008,
	address = {Philadelphia, United States},
	title = {Clustering {Music} {Recordings} by {Their} {Keys}.},
	url = {https://doi.org/10.5281/zenodo.1417375},
	doi = {10.5281/zenodo.1417375},
	booktitle = {Proceedings of the 9th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Liu, Yuxiang and Wang, Ye and Shenoy, Arun and Tsai, Wei-Ho and Cai, Lianhong},
	month = sep,
	year = {2008},
	keywords = {Comps, Comps\_Q5},
	pages = {319--324}
}

@inproceedings{turnbull_game-based_2007,
	address = {Vienna, Austria},
	title = {A {Game}-{Based} {Approach} for {Collecting} {Semantic} {Annotations} of {Music}.},
	url = {https://doi.org/10.5281/zenodo.1416464},
	doi = {10.5281/zenodo.1416464},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Turnbull, Douglas and Liu, Ruoran and Barrington, Luke and Lanckriet, Gert R. G.},
	month = sep,
	year = {2007},
	keywords = {ReadLater},
	pages = {535--538}
}

@inproceedings{pugin_map_2007,
	address = {Vienna, Austria},
	title = {{MAP} {Adaptation} to {Improve} {Optical} {Music} {Recognition} of {Early} {Music} {Documents} {Using} {Hidden} {Markov} {Models}.},
	url = {https://doi.org/10.5281/zenodo.1415922},
	doi = {10.5281/zenodo.1415922},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Pugin, Laurent and Burgoyne, John Ashley and Fujinaga, Ichiro},
	month = sep,
	year = {2007},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_Unidentified, Comps\_ToDo},
	pages = {513--516}
}

@inproceedings{ellis_classifying_2007,
	address = {Vienna, Austria},
	title = {Classifying {Music} {Audio} with {Timbral} and {Chroma} {Features}.},
	url = {https://doi.org/10.5281/zenodo.1416906},
	doi = {10.5281/zenodo.1416906},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Ellis, Daniel P. W.},
	month = sep,
	year = {2007},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Unidentified},
	pages = {339--340}
}

@inproceedings{kilian_voice_2002,
	address = {Paris, France},
	title = {Voice {Separation} - {A} {Local} {Optimization} {Approach}.},
	url = {https://doi.org/10.5281/zenodo.1417645},
	doi = {10.5281/zenodo.1417645},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Kilian, Jürgen and Hoos, Holger H.},
	month = oct,
	year = {2002},
	keywords = {ReadLater}
}

@inproceedings{mcpherson_introducing_2002,
	address = {Paris, France},
	title = {Introducing {Feedback} into an {Optical} {Music} {Recogniition} {System}.},
	url = {https://doi.org/10.5281/zenodo.1417725},
	doi = {10.5281/zenodo.1417725},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {McPherson, John R.},
	month = oct,
	year = {2002},
	keywords = {ReadLater}
}

@inproceedings{mullensiefen_evaluating_2007,
	address = {Vienna, Austria},
	title = {Evaluating a {Chord}-{Labelling} {Algorithm}.},
	url = {https://doi.org/10.5281/zenodo.1417779},
	doi = {10.5281/zenodo.1417779},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Müllensiefen, Daniel and Lewis 0001, David and Rhodes, Christophe and Wiggins, Geraint A.},
	month = sep,
	year = {2007},
	keywords = {ReadLater},
	pages = {317--318}
}

@inproceedings{van_der_par_musical_2006,
	address = {Victoria, Canada},
	title = {Musical {Key} {Extraction} from {Audio} {Using} {Profile} {Training}.},
	booktitle = {Proceedings of the 7th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	author = {van der Par, Steven and McKinney, Martin F. and Redert, André},
	year = {2006},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey},
	pages = {328--329}
}

@inproceedings{mardirossian_music_2006,
	address = {Victoria, Canada},
	title = {Music {Summarization} {Via} {Key} {Distributions}: {Analyses} of {Similarity} {Assessment} {Across} {Variations}.},
	url = {https://doi.org/10.5281/zenodo.1418295},
	doi = {10.5281/zenodo.1418295},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Mardirossian, Arpi and Chew, Elaine},
	month = oct,
	year = {2006},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Q3\_Symbolic, Comps\_Q3\_Unidentified},
	pages = {234--239}
}

@inproceedings{izmirli_audio_2006,
	address = {Victoria, Canada},
	title = {Audio {Key} {Finding} {Using} {Low}-{Dimensional} {Spaces}.},
	url = {https://doi.org/10.5281/zenodo.1415858},
	doi = {10.5281/zenodo.1415858},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Izmirli, Özgür},
	month = oct,
	year = {2006},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey},
	pages = {127--132}
}

@inproceedings{peeters_chroma-based_2006,
	address = {Victoria, Canada},
	title = {Chroma-based estimation of musical key from audio- signal analysis.},
	url = {https://doi.org/10.5281/zenodo.1416420},
	doi = {10.5281/zenodo.1416420},
	booktitle = {Proceedings of the 7th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Peeters, Geoffroy},
	month = oct,
	year = {2006},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_MIR, Comps\_Q1\_MIR\_Key, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Skimmed, Comps\_Summarized, Comps\_ToDo},
	pages = {115--120}
}

@inproceedings{mcennis_jaudio:_2005,
	address = {London, United Kingdom},
	title = {{jAudio}: {An} {Feature} {Extraction} {Library}.},
	url = {https://doi.org/10.5281/zenodo.1416648},
	doi = {10.5281/zenodo.1416648},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {McEnnis, Daniel and McKay, Cory and Fujinaga, Ichiro and Depalle, Philippe},
	month = sep,
	year = {2005},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_FeatureExtraction},
	pages = {600--603}
}

@inproceedings{bray_distributed_2005,
	address = {London, United Kingdom},
	title = {Distributed {Audio} {Feature} {Extraction} for {Music}.},
	url = {https://doi.org/10.5281/zenodo.1417563},
	doi = {10.5281/zenodo.1417563},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Bray, Stuart and Tzanetakis, George},
	month = sep,
	year = {2005},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_FeatureExtraction},
	pages = {434--437}
}

@inproceedings{meredith_comparing_2005,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Comparing {Pitch} {Spelling} {Algorithms} on a {Large} {Corpus} of {Tonal} {Music}},
	isbn = {978-3-540-31807-1},
	abstract = {This paper focuses on the problem of constructing a reliable pitch spelling algorithm—that is, an algorithm that computes the correct pitch names (e.g., C♯♯{\textbackslash}sharp4, B♭♭{\textbackslash}flat5 etc.) of the notes in a passage of tonal music, when given only the onset-time, MIDI note number and possibly the duration of each note. The author’s ps13 algorithm and the pitch spelling algorithms of Cambouropoulos, Temperley and Longuet-Higgins were run on a corpus of tonal music containing 1.73 million notes. ps13 spelt significantly more of the notes in this corpus correctly than the other algorithms (99.33\% correct). However, Temperley’s algorithm spelt significantly more intervals between consecutive notes correctly than the other algorithms (99.45\% correct). All the algorithms performed less well on classical music than baroque music. However, ps13 performed more consistently across the various composers and styles than the other algorithms.},
	language = {en},
	booktitle = {Computer {Music} {Modeling} and {Retrieval}},
	publisher = {Springer Berlin Heidelberg},
	author = {Meredith, David},
	editor = {Wiil, Uffe Kock},
	year = {2005},
	keywords = {Comps, Comps\_Q7},
	pages = {173--192}
}

@inproceedings{lidy_evaluation_2005,
	address = {London, United Kingdom},
	title = {Evaluation of {Feature} {Extractors} and {Psycho}- {Acoustic} {Transformations} for {Music} {Genre} {Classification}.},
	url = {https://doi.org/10.5281/zenodo.1416856},
	doi = {10.5281/zenodo.1416856},
	booktitle = {Proceedings of the 6th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Lidy, Thomas and Rauber, Andreas},
	month = sep,
	year = {2005},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_FeatureExtraction},
	pages = {34--41}
}
@inproceedings{pauws_musical_2004,
	address = {Barcelona, Spain},
	title = {Musical key extraction from audio.},
	url = {https://doi.org/10.5281/zenodo.1416326},
	doi = {10.5281/zenodo.1416326},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Pauws, Steffen},
	month = oct,
	year = {2004},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey}
}

@inproceedings{pachet_automatic_2004,
	address = {Barcelona, Spain},
	title = {Automatic extraction of music descriptors from acoustic signals.},
	url = {https://doi.org/10.5281/zenodo.1416106},
	doi = {10.5281/zenodo.1416106},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Pachet, François and Zils, Aymeric},
	month = oct,
	year = {2004},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_FeatureExtraction}
}

@inproceedings{hanna_audio_2004,
	address = {Barcelona, Spain},
	title = {Audio {Features} for {Noisy} {Sound} {Segmentation}.},
	url = {https://doi.org/10.5281/zenodo.1415214},
	doi = {10.5281/zenodo.1415214},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Hanna, Pierre and Louis, Nicolas and Desainte-Catherine, Myriam and Benois-Pineau, Jenny},
	month = oct,
	year = {2004},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_AudioDegradation}
}

@inproceedings{gomez_estimating_2004,
	address = {Barcelona, Spain},
	title = {Estimating {The} {Tonality} {Of} {Polyphonic} {Audio} {Files}: {Cognitive} {Versus} {Machine} {Learning} {Modelling} {Strategies}.},
	url = {https://doi.org/10.5281/zenodo.1418007},
	doi = {10.5281/zenodo.1418007},
	booktitle = {Proceedings of the 5th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Gómez, Emilia and Herrera, Perfecto},
	month = oct,
	year = {2004},
	keywords = {Comps, Comps\_Q3, Comps\_Q3\_Audio, Comps\_Q3\_Survey, Comps\_Skimmed, Comps\_Summarized}
}

@inproceedings{harford_automatic_2003,
	address = {Baltimore, United States},
	title = {Automatic segmentation, learning and retrieval of melodies using a self-organizing neural network.},
	url = {https://doi.org/10.5281/zenodo.1416182},
	doi = {10.5281/zenodo.1416182},
	booktitle = {Proceedings of the 4th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Harford, S.},
	month = oct,
	year = {2003},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR}
}

@inproceedings{chew_determining_2003,
	address = {Baltimore, United States},
	title = {Determining context-defining windows: {Pitch} spelling using the spiral array.},
	url = {https://doi.org/10.5281/zenodo.1418037},
	doi = {10.5281/zenodo.1418037},
	booktitle = {Proceedings of the 4th {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Chew, Elaine and Chen, Yun-Ching},
	month = oct,
	year = {2003},
	keywords = {Comps, Comps\_Q7}
}

@inproceedings{vinet_cuidado_2002,
	address = {Paris, France},
	title = {The {CUIDADO} {Project}.},
	url = {https://doi.org/10.5281/zenodo.1416940},
	doi = {10.5281/zenodo.1416940},
	booktitle = {Proceedings of the 3rd {International} {Conference} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Vinet, Hugues and Herrera, Perfecto and Pachet, François},
	month = oct,
	year = {2002},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_FeatureExtraction}
}

@inproceedings{allamanche_content-based_2001,
	address = {Bloomington, United States},
	title = {Content-based {Identification} of {Audio} {Material} {Using} {MPEG}-7 {Low} {Level} {Description}.},
	url = {https://doi.org/10.5281/zenodo.1417853},
	doi = {10.5281/zenodo.1417853},
	booktitle = {Proceedings of the 2nd {International} {Symposium} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Allamanche, Eric},
	month = oct,
	year = {2001},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_FeatureExtraction}
}

@inproceedings{kiernan_score-based_2000,
	address = {Plymouth, United States},
	title = {Score-based {Style} {Recognition} {Using} {Artificial} {Neural} {Networks}.},
	url = {https://doi.org/10.5281/zenodo.1416626},
	doi = {10.5281/zenodo.1416626},
	booktitle = {Proceedings of the 1st {International} {Symposium} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Kiernan, Francis J.},
	month = oct,
	year = {2000},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_MIR}
}

@inproceedings{bendor_time_2000,
	address = {Plymouth, United States},
	title = {Time {Domain} {Extraction} of {Vibrato} from {Monophonic} {Instruments}},
	url = {https://doi.org/10.5281/zenodo.1416810},
	doi = {10.5281/zenodo.1416810},
	booktitle = {Proceedings of the 1st {International} {Symposium} on {Music} {Information} {Retrieval}},
	publisher = {ISMIR},
	author = {Bendor, Daniel and Sandler, Mark B.},
	month = oct,
	year = {2000},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Vibrato}
}

@article{doersch_tutorial_2016,
	title = {Tutorial on {Variational} {Autoencoders}},
	url = {http://arxiv.org/abs/1606.05908},
	abstract = {In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, CIFAR images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
	urldate = {2019-09-23},
	journal = {arXiv:1606.05908 [cs, stat]},
	author = {Doersch, Carl},
	month = jun,
	year = {2016},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_VAE}
}

@article{rosenblatt_perceptron:_1958,
	title = {The {Perceptron}: {A} {Probabilistic} {Model} for {Information} {Storage} and {Organization} in the {Brain}},
	volume = {65},
	issn = {1939-1471(Electronic),0033-295X(Print)},
	shorttitle = {The perceptron},
	doi = {10.1037/h0042519},
	abstract = {To answer the questions of how information about the physical world is sensed, in what form is information remembered, and how does information retained in memory influence recognition and behavior, a theory is developed for a hypothetical nervous system called a perceptron. The theory serves as a bridge between biophysics and psychology. It is possible to predict learning curves from neurological variables and vice versa. The quantitative statistical approach is fruitful in the understanding of the organization of cognitive systems. 18 references. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {6},
	journal = {Psychological Review},
	author = {Rosenblatt, F.},
	year = {1958},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_ANN},
	pages = {386--408}
}

@incollection{krizhevsky_imagenet_2012,
	title = {{ImageNet} {Classification} with {Deep} {Convolutional} {Neural} {Networks}},
	url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf},
	urldate = {2019-09-23},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 25},
	publisher = {Curran Associates, Inc.},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
	editor = {Pereira, F. and Burges, C. J. C. and Bottou, L. and Weinberger, K. Q.},
	year = {2012},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_CNN},
	pages = {1097--1105}
}

@inproceedings{ronneberger_u-net:_2015,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {U-{Net}: {Convolutional} {Networks} for {Biomedical} {Image} {Segmentation}},
	isbn = {978-3-319-24574-4},
	shorttitle = {U-{Net}},
	abstract = {There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net .},
	language = {en},
	booktitle = {Medical {Image} {Computing} and {Computer}-{Assisted} {Intervention} – {MICCAI} 2015},
	publisher = {Springer International Publishing},
	author = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	editor = {Navab, Nassir and Hornegger, Joachim and Wells, William M. and Frangi, Alejandro F.},
	year = {2015},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_UNet},
	pages = {234--241}
}

@article{schmidhuber_deep_2015,
	title = {Deep {Learning} in {Neural} {Networks}: {An} {Overview}},
	volume = {61},
	issn = {0893-6080},
	shorttitle = {Deep learning in neural networks},
	url = {http://www.sciencedirect.com/science/article/pii/S0893608014002135},
	doi = {10.1016/j.neunet.2014.09.003},
	abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \& evolutionary computation, and indirect search for short programs encoding deep and large networks.},
	urldate = {2019-09-23},
	journal = {Neural Networks},
	author = {Schmidhuber, Jürgen},
	month = jan,
	year = {2015},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_ANN},
	pages = {85--117}
}

@article{lecun_backpropagation_1989,
	title = {Backpropagation {Applied} to {Handwritten} {Zip} {Code} {Recognition}},
	volume = {1},
	issn = {0899-7667},
	url = {https://doi.org/10.1162/neco.1989.1.4.541},
	doi = {10.1162/neco.1989.1.4.541},
	abstract = {The ability of learning networks to generalize can be greatly enhanced by providing constraints from the task domain. This paper demonstrates how such constraints can be integrated into a backpropagation network through the architecture of the network. This approach has been successfully applied to the recognition of handwritten zip code digits provided by the U.S. Postal Service. A single network learns the entire recognition operation, going from the normalized image of the character to the final classification.},
	number = {4},
	urldate = {2019-09-23},
	journal = {Neural Computation},
	author = {LeCun, Y. and Boser, B. and Denker, J. S. and Henderson, D. and Howard, R. E. and Hubbard, W. and Jackel, L. D.},
	month = dec,
	year = {1989},
	keywords = {Comps, Comps\_Q2, Comps\_Q2\_ANN},
	pages = {541--551}
}

@article{rabiner_introduction_1986,
	title = {An {Introduction} to {Hidden} {Markov} {Models}},
	volume = {3},
	doi = {10.1109/MASSP.1986.1165342},
	abstract = {The basic theory of Markov chains has been known to mathematicians and engineers for close to 80 years, but it is only in the past decade that it has been applied explicitly to problems in speech processing. One of the major reasons why speech models, based on Markov chains, have not been developed until recently was the lack of a method for optimizing the parameters of the Markov model to match observed signal patterns. Such a method was proposed in the late 1960's and was immediately applied to speech processing in several research institutions. Continued refinements in the theory and implementation of Markov modelling techniques have greatly enhanced the method, leading to a wide range of applications of these models. It is the purpose of this tutorial paper to give an introduction to the theory of Markov models, and to illustrate how they have been applied to problems in speech recognition.},
	number = {1},
	journal = {IEEE ASSP Magazine},
	author = {Rabiner, Lawrence R. and Juang, Biing H.},
	month = jan,
	year = {1986},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_HMM, Comps\_Read, Comps\_Summarized},
	pages = {4--16}
}

@article{viterbi_error_1967,
	title = {Error {Bounds} for {Convolutional} {Codes} and an {Asymptotically} {Optimum} {Decoding} {Algorithm}},
	volume = {13},
	doi = {10.1109/TIT.1967.1054010},
	abstract = {The probability of error in decoding an optimal convolutional code transmitted over a memoryless channel is bounded from above and below as a function of the constraint length of the code. For all but pathological channels the bounds are asymptotically (exponentially) tight for rates aboveR\_0, the computational cutoff rate of sequential decoding. As a function of constraint length the performance of optimal convolutional codes is shown to be superior to that of block codes of the same length, the relative improvement increasing with rate. The upper bound is obtained for a specific probabilistic nonsequential decoding algorithm which is shown to be asymptotically optimum for rates aboveR\_0and whose performance bears certain similarities to that of sequential decoding algorithms.},
	number = {2},
	journal = {IEEE Transactions on Information Theory},
	author = {Viterbi, Andrew},
	month = apr,
	year = {1967},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_Viterbi},
	pages = {260--269}
}

@article{rabiner_tutorial_1989,
	title = {A {Tutorial} on {Hidden} {Markov} {Models} and {Selected} {Applications} in {Speech} {Recognition}},
	volume = {77},
	doi = {10.1109/5.18626},
	abstract = {This tutorial provides an overview of the basic theory of hidden Markov models (HMMs) as originated by L.E. Baum and T. Petrie (1966) and gives practical details on methods of implementation of the theory along with a description of selected applications of the theory to distinct problems in speech recognition. Results from a number of original sources are combined to provide a single source of acquiring the background required to pursue further this area of research. The author first reviews the theory of discrete Markov chains and shows how the concept of hidden states, where the observation is a probabilistic function of the state, can be used effectively. The theory is illustrated with two simple examples, namely coin-tossing, and the classic balls-in-urns system. Three fundamental problems of HMMs are noted and several practical techniques for solving these problems are given. The various types of HMMs that have been studied, including ergodic as well as left-right models, are described.{\textless}{\textgreater}},
	number = {2},
	journal = {Proceedings of the IEEE},
	author = {Rabiner, Lawrence R.},
	month = feb,
	year = {1989},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_HMM},
	pages = {257--286}
}

@article{forney_viterbi_1973,
	title = {The {Viterbi} {Algorithm}},
	volume = {61},
	doi = {10.1109/PROC.1973.9030},
	abstract = {The Viterbi algorithm (VA) is a recursive optimal solution to the problem of estimating the state sequence of a discrete-time finite-state Markov process observed in memoryless noise. Many problems in areas such as digital communications can be cast in this form. This paper gives a tutorial exposition of the algorithm and of how it is implemented and analyzed. Applications to date are reviewed. Increasing use of the algorithm in a widening variety of areas is foreseen.},
	number = {3},
	journal = {Proceedings of the IEEE},
	author = {Forney, David},
	month = mar,
	year = {1973},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_Viterbi},
	pages = {268--278}
}

@article{markov_rasprostranenie_1906,
	title = {Rasprostranenie zakona bol’shih chisel na velichiny, zavisyaschie drug ot druga},
	volume = {15},
	number = {135-156},
	journal = {Izvestiya Fiziko-matematicheskogo obschestva pri Kazanskom universitete},
	author = {Markov, Andrei Andreevich},
	year = {1906},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_Markov},
	pages = {18}
}

@article{bernstein_sur_1927,
	title = {Sur l'extension du théoréme limite du calcul des probabilités aux sommes de quantités dépendantes},
	volume = {97},
	issn = {1432-1807},
	url = {https://doi.org/10.1007/BF01447859},
	doi = {10.1007/BF01447859},
	language = {fr},
	number = {1},
	urldate = {2019-09-23},
	journal = {Mathematische Annalen},
	author = {Bernstein, Serge},
	month = dec,
	year = {1927},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_Markov, Comps\_Skimmed},
	pages = {1--59}
}

@article{basharin_life_2004,
	series = {Special {Issue} on the {Conference} on the {Numerical} {Solution} of {Markov} {Chains} 2003},
	title = {The {Life} and {Work} of {A}.{A}. {Markov}},
	volume = {386},
	issn = {0024-3795},
	url = {http://www.sciencedirect.com/science/article/pii/S0024379504000357},
	doi = {10.1016/j.laa.2003.12.041},
	abstract = {The Russian mathematician A.A. Markov (1856–1922) is known for his work in number theory, analysis, and probability theory. He extended the weak law of large numbers and the central limit theorem to certain sequences of dependent random variables forming special classes of what are now known as Markov chains. For illustrative purposes Markov applied his chains to the distribution of vowels and consonants in A.S. Pushkin’s poem “Eugeny Onegin”. At present, much more important applications of Markov chains have been discovered. Here we present an overview of Markov’s life and his work on the chains.},
	urldate = {2019-09-23},
	journal = {Linear Algebra and its Applications},
	author = {Basharin, Gely P. and Langville, Amy N. and Naumov, Valeriy A.},
	month = jul,
	year = {2004},
	keywords = {Comps, Comps\_Q1, Comps\_Q1\_Markov, Comps\_Read, Comps\_Summarized},
	pages = {3--26}
}

@inproceedings{matthias_mauch_audio_2013,
	address = {Curitiba, Brazil},
	title = {The {Audio} {Degradation} {Toolbox} and {Its} {Application} to {Robustness} {Evaluation}.},
	url = {https://zenodo.org/record/1415862#.XX_3tZNKjmE},
	urldate = {2019-09-16},
	booktitle = {Proceedings of the 14th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	author = {Matthias Mauch and Sebastian Ewert},
	month = nov,
	year = {2013},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_AudioDegradation},
	pages = {83--88}
}

@article{downie_scientific_2004,
	title = {The {Scientific} {Evaluation} of {Music} {Information} {Retrieval} {Systems}: {Foundations} and {Future}},
	volume = {28},
	issn = {0148-9267},
	shorttitle = {The {Scientific} {Evaluation} of {Music} {Information} {Retrieval} {Systems}},
	url = {http://dx.doi.org/10.1162/014892604323112211},
	doi = {10.1162/014892604323112211},
	number = {2},
	urldate = {2019-09-16},
	journal = {Comput. Music J.},
	author = {Downie, J. Stephen},
	month = jun,
	year = {2004},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Evaluation},
	pages = {12--23}
}

@phdthesis{gomez_tonal_2006,
	type = {{PhD} {Thesis}},
	title = {Tonal {Description} of {Music} {Audio} {Signals}},
	school = {Universitat Pompeu Fabra},
	author = {Gómez, Emilia},
	year = {2006},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_AudioKey}
}

@inproceedings{herrera_vibrato_1998,
	title = {Vibrato extraction and parameterization in the spectral modeling synthesis framework},
	volume = {99},
	booktitle = {Proceedings of the {Digital} {Audio} {Effects} {Workshop}},
	author = {Herrera, Perfecto and Bonada, Jordi},
	year = {1998},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Specificities}
}

@inproceedings{rossignol_vibrato:_1999,
	title = {Vibrato: detection, estimation, extraction, modification},
	booktitle = {Proceedings of the {Digital} {Audio} {Effects} {Workshop}},
	author = {Rossignol, Stéphane and Depalle, Philippe and Soumagne, Joel and Rodet, Xavier and Collette, Jean-Luc},
	year = {1999},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Specificities},
	pages = {1--4}
}

@article{toiviainen_visualization_2007,
	title = {Visualization of {Tonal} {Content} in the {Symbolic} and {Audio} {Domains}},
	volume = {15},
	journal = {Computing in Musicology},
	author = {Toiviainen, Petri},
	year = {2007},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_AudioVsSymbolic},
	pages = {187--199}
}

@article{lindsay_mpeg-7_2001,
	title = {{MPEG}-7 and {MPEG}-7 {Audio}'{An} {Overview}},
	volume = {49},
	url = {http://www.aes.org/e-lib/browse.cfm?elib=10186},
	abstract = {For more than 10 years the term MPEG (Moving Picture Experts Group) has been synonymous with successful standardization in the field of audiovisual coding. The well-known standards MPEG-1, MPEG-2, and MPEG-4 have defined the state of the art in the perceptual coding of multimedia content. More recently the MPEG standards group (ISO/IEC JTC1/SC29/WG11) has extended its traditional scope by initiating the MPEG-7 standardization process, which aims to define a unified interface for the...},
	language = {English},
	number = {7/8},
	urldate = {2019-09-17},
	journal = {Journal of the Audio Engineering Society},
	author = {Lindsay, Adam T. and Herre, Jürgen},
	month = jul,
	year = {2001},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Taxonomies},
	pages = {589--594}
}

@incollection{mitrovic_features_2010,
	title = {Features for {Content}-{Based} {Audio} {Retrieval}},
	volume = {78},
	booktitle = {Advances in computers},
	publisher = {Elsevier},
	author = {Mitrović, Dalibor and Zeppelzauer, Matthias and Breiteneder, Christian},
	year = {2010},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Taxonomies},
	pages = {71--150}
}

@techreport{peeters_large_2004,
	title = {A {Large} {Set} of {Audio} {Features} for {Sound} {Description} ({Similarity} and {Classification}) in the {CUIDADO} {Project}},
	author = {Peeters, Geoffroy},
	year = {2004},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Taxonomies},
	pages = {1--25}
}

@inproceedings{verfaille_perceptual_2005,
	address = {Montréal, Canada},
	title = {Perceptual {Evaluation} of {Vibrato} {Models}},
	booktitle = {Proceedings of the {Conference} on {Interdisciplinary} {Musicology}},
	author = {Verfaille, Vincent and Guastavino, Catherine and Depalle, Philippe},
	year = {2005},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Specificities}
}

@article{nwe_exploring_2007,
	title = {Exploring {Vibrato}-{Motivated} {Acoustic} {Features} for {Singer} {Identification}},
	volume = {15},
	doi = {10.1109/TASL.2006.876756},
	abstract = {Vibrato is a slightly tremulous effect imparted to vocal or instrumental tone for added warmth and expressiveness through slight variation in pitch. It corresponds to a periodic fluctuation of the fundamental frequency. It is common for a singer to develop a vibrato function to personalize his/her singing style. In this paper, we explore the acoustic features that reflect vibrato information in order to identify singers of popular music. We start with an enhanced vocal detection method that allows us to select vocal segments with high confidence. From the selected vocal segments, the cepstral coefficients which reflect the vibrato characteristics are computed. These coefficients are derived using bandpass filters, such as parabolic and cascaded bandpass filters, spread according to the octave frequency scale. The strategy of our classifier formulation is to utilize the high level musical knowledge of song structure in singer modeling. Singer identification is validated on a database containing 84 popular songs from commercially available CD recordings from 12 singers. We achieve an average error rate of 16.2\% in segment level identification},
	number = {2},
	journal = {IEEE Transactions on Audio, Speech, and Language Processing},
	author = {Nwe, T. L. and Li, H.},
	month = feb,
	year = {2007},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Specificities},
	pages = {519--530}
}

@inproceedings{eyben_opensmile:_2010,
	address = {New York, NY, USA},
	series = {{MM} '10},
	title = {Opensmile: {The} {Munich} {Versatile} and {Fast} {Open}-source {Audio} {Feature} {Extractor}},
	isbn = {978-1-60558-933-6},
	shorttitle = {Opensmile},
	url = {http://doi.acm.org/10.1145/1873951.1874246},
	doi = {10.1145/1873951.1874246},
	abstract = {We introduce the openSMILE feature extraction toolkit, which unites feature extraction algorithms from the speech processing and the Music Information Retrieval communities. Audio low-level descriptors such as CHROMA and CENS features, loudness, Mel-frequency cepstral coefficients, perceptual linear predictive cepstral coefficients, linear predictive coefficients, line spectral frequencies, fundamental frequency, and formant frequencies are supported. Delta regression and various statistical functionals can be applied to the low-level descriptors. openSMILE is implemented in C++ with no third-party dependencies for the core functionality. It is fast, runs on Unix and Windows platforms, and has a modular, component based architecture which makes extensions via plug-ins easy. It supports on-line incremental processing for all implemented features as well as off-line and batch processing. Numeric compatibility with future versions is ensured by means of unit tests. openSMILE can be downloaded from http://opensmile.sourceforge.net/.},
	urldate = {2019-09-16},
	booktitle = {Proceedings of the 18th {ACM} {International} {Conference} on {Multimedia}},
	publisher = {ACM},
	author = {Eyben, Florian and Wöllmer, Martin and Schuller, Björn},
	year = {2010},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_FeatureExtraction},
	pages = {1459--1462}
}

@inproceedings{bogdanov_essentia:_2013,
	address = {Curitiba, Brazil},
	title = {Essentia: {An} audio analysis library for music information retrieval},
	shorttitle = {Essentia},
	booktitle = {Proceedings of the 14th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	publisher = {International Society for Music Information Retrieval (ISMIR)},
	author = {Bogdanov, Dmitry and Wack, Nicolas and Gómez Gutiérrez, Emilia and Gulati, Sankalp and Boyer, Herrera and Mayor, Oscar and Roma Trepat, Gerard and Salamon, Justin and Zapata González, José Ricardo and Serra, Xavier},
	year = {2013},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_FeatureExtraction},
	pages = {493--8}
}

@inproceedings{moffat_evaluation_2015,
	address = {Trondheim, Norway},
	title = {An {Evaluation} of {Audio} {Feature} {Extraction} {Toolboxes}},
	booktitle = {Proceedings of the 18th {International} {Conference} on {Digital} {Audio} {Effects}},
	author = {Moffat, David and Ronan, David and Reiss, Joshua D.},
	year = {2015},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_FeatureExtraction}
}

@inproceedings{lartillot_matlab_2007,
	address = {Bordeaux, France},
	title = {A {Matlab} {Toolbox} for {Musical} {Feature} {Extraction} {From} {Audio}},
	booktitle = {International {Conference} on {Digital} {Audio} {Effects}},
	author = {Lartillot, Olivier and Toiviainen, Petri},
	year = {2007},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_FeatureExtraction},
	pages = {237--244}
}

@article{casey_content-based_2008,
	title = {Content-{Based} {Music} {Information} {Retrieval}: {Current} {Directions} and {Future} {Challenges}},
	volume = {96},
	shorttitle = {Content-{Based} {Music} {Information} {Retrieval}},
	doi = {10.1109/JPROC.2008.916370},
	abstract = {The steep rise in music downloading over CD sales has created a major shift in the music industry away from physical media formats and towards online products and services. Music is one of the most popular types of online information and there are now hundreds of music streaming and download services operating on the World-Wide Web. Some of the music collections available are approaching the scale of ten million tracks and this has posed a major challenge for searching, retrieving, and organizing music content. Research efforts in music information retrieval have involved experts from music perception, cognition, musicology, engineering, and computer science engaged in truly interdisciplinary activity that has resulted in many proposed algorithmic and methodological solutions to music search using content-based methods. This paper outlines the problems of content-based music information retrieval and explores the state-of-the-art methods using audio cues (e.g., query by humming, audio fingerprinting, content-based music retrieval) and other cues (e.g., music notation and symbolic representation), and identifies some of the major challenges for the coming years.},
	number = {4},
	journal = {Proceedings of the IEEE},
	author = {Casey, M. A. and Veltkamp, R. and Goto, M. and Leman, M. and Rhodes, C. and Slaney, M.},
	month = apr,
	year = {2008},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Evaluation},
	pages = {668--696}
}

@inproceedings{raffel_mir_eval:_2014,
	address = {Taipei, Taiwan},
	title = {mir\_eval: {A} {Transparent} {Implementation} of {Common} {MIR} {Metrics}},
	booktitle = {Proceedings of the 15th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	author = {Raffel, Colin and Mcfee, Brian and Humphrey, Eric and Salamon, Justin and Nieto, Oriol and Liang, Dawen and Ellis, Daniel},
	year = {2014},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Evaluation}
}

@inproceedings{franck_performance_2011,
	title = {Performance {Evaluation} of {Algorithms} for {Arbitrary} {Sample} {Rate} {Conversion}},
	url = {http://www.aes.org/e-lib/online/browse.cfm?elib=16078},
	abstract = {Arbitrary sample rate conversion (ASRC) enables changes of the sampling frequency by flexible, time-varying ratios. It can be utilized advantageously in many applications of audio signal processing. Consequently, numerous algorithms for ASRC have been proposed. However, it is often difficult to choose a minimal-cost algorithm that meets the requirements of a specific application. In this paper, several approaches to ASRC are reviewed. Special emphasis is placed on algorithms that enable...},
	language = {English},
	urldate = {2019-09-16},
	booktitle = {Audio {Engineering} {Society} {Convention} 131},
	publisher = {Audio Engineering Society},
	author = {Franck, Andreas},
	month = oct,
	year = {2011},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_AudioDegradation}
}

@inproceedings{tzanetakis_pitch_2002,
	title = {Pitch {Histograms} in {Audio} and {Symbolic} {Music} {Information} {Retrieval}},
	doi = {10.1076/jnmr.32.2.143.16743},
	abstract = {In order to represent musical content, pitch and timing information is utilized in the majority of existing work in Symbolic Music Information Retrieval (MIR). Symbolic representations such as MIDI allow the easy calculation of such information and its manipulation. In contrast, most of the existing work in Audio MIR uses timbral and beat information, which can be calculated using automatic computer audition techniques. In this paper, Pitch Histograms are defined and proposed as a way to represent the pitch content of music signals both in symbolic and audio form. This representation is evaluated in the context of automatic musical genre classification. A multiple-pitch detection algorithm for polyphonic signals is used to calculate Pitch Histograms for audio signals. In order to evaluate the extent and significance of errors resulting from the automatic multiple-pitch detection, automatic musical genre classification results from symbolic and audio data are compared. The comparison indicates that Pitch H...},
	booktitle = {Proceedings of the 3rd {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	author = {Tzanetakis, George and Ermolinskiy, Andrey and Cook, Perry R.},
	year = {2002},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_AudioVsSymbolic}
}

@inproceedings{wang_music_2015,
	address = {Málaga, Spain},
	title = {Music {Pattern} {Discovery} with {Variable} {Markov} {Oracle}: {A} {Unified} {Approach} to {Symbolic} and {Audio} {Representations}},
	shorttitle = {Music {Pattern} {Discovery} with {Variable} {Markov} {Oracle}},
	abstract = {This paper presents a framework for automatically discovering patterns in a polyphonic music piece. The proposed framework is capable of handling both symbolic and audio representations. Chroma features are post-processed with heuristics stemming from musical knowledge and fed into the pattern discovery framework. The pattern-finding algorithm is based on Variable Markov Oracle. The Variable Markov Oracle data structure is capable of locating repeated suffixes within a time series, thus making it an appropriate tool for the pattern discovery task. Evaluation of the proposed framework is performed on the JKU Patterns Development Dataset with state of the art performance.},
	booktitle = {Proceedings of the 16th {International} {Society} for {Music} {Information} {Retrieval} {Conference}},
	author = {Wang, Cheng-i and Hsu, Jennifer and Dubnov, Shlomo},
	year = {2015},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_AudioVsSymbolic}
}

@inproceedings{collins_bridging_2014,
	title = {Bridging the {Audio}-{Symbolic} {Gap}: {The} {Discovery} of {Repeated} {Note} {Content} {Directly} from {Polyphonic} {Music} {Audio}},
	shorttitle = {Bridging the {Audio}-{Symbolic} {Gap}},
	url = {http://www.aes.org/e-lib/browse.cfm?elib=17096},
	abstract = {Algorithms for the discovery of musical repetition have been developed in audio and symbolic domains more or less independently for over a decade. In this paper we combine algorithms for multiple F0 estimation, beat tracking, quantisation, and pattern discovery, so that for the first time, the note content of motifs, themes, and repeated sections can be discovered directly from polyphonic music audio. Testing on deadpan and expressive piano renditions of pieces, we compared pattern discovery...},
	language = {English},
	urldate = {2019-09-16},
	booktitle = {Audio {Engineering} {Society} {Conference}: 53rd {International} {Conference}: {Semantic} {Audio}},
	publisher = {Audio Engineering Society},
	author = {Collins, Tom and Böck, Sebastian and Krebs, Florian and Widmer, Gerhard},
	month = jan,
	year = {2014},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_AudioVsSymbolic}
}

@book{cook_beyond_2014,
	title = {Beyond the {Score}: {Music} as {Performance}},
	isbn = {978-0-19-935742-0},
	shorttitle = {Beyond the {Score}},
	url = {http://www.oxfordscholarship.com/view/10.1093/acprof:oso/9780199357406.001.0001/acprof-9780199357406},
	abstract = {It is as performance that music is loved, understood, and consumed, yet musicologists have traditionally treated it as a kind of text. They have seen meaning as written into the music, implying that performance merely reproduces what is already there: this paradigm of reproduction has prevented musicology from adequately engaging with performance. Beyond the Score is a thoroughgoing attempt to reconceive music as performance, in other words as a real-time practice that affords the production of meaning. That means rethinking familiar assumptions and developing new approaches. Focusing primarily but not exclusively on the Western “art” tradition, the book explores perspectives that range from close listening to computational analysis, from ethnography to the study of recordings, and from the social relations constructed through performance to the performing (and listening) body. It also has a strong historical emphasis, extending from the early days of recording to contemporary digital culture, and a number of themes weave through it. These include the relationship between the written and the oral in musical culture, and the need to move on from thinking based on the paradigm of reproduction to a semiotic approach grounded on the production of meaning. While the principal claim of the book is that thinking based on the idea of music as text has hampered the academic understanding of music, the book argues that it has also made the practices of performance less creative than they might be, and the book explores how we might escape from the textualist straitjacket.},
	language = {en\_US},
	urldate = {2019-09-17},
	publisher = {Oxford University Press},
	author = {Cook, Nicholas},
	month = jan,
	year = {2014},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_AudioVsSymbolic}
}

@article{velarde_convolution-based_2018,
	title = {Convolution-{Based} {Classification} of {Audio} and {Symbolic} {Representations} of {Music}},
	volume = {47},
	issn = {0929-8215},
	url = {https://doi.org/10.1080/09298215.2018.1458885},
	doi = {10.1080/09298215.2018.1458885},
	abstract = {We present a novel convolution-based method for classification of audio and symbolic representations of music, which we apply to classification of music by style. Pieces of music are first sampled to pitch–time representations (spectrograms or piano-rolls) and then convolved with a Gaussian filter, before being classified by a support vector machine or by k-nearest neighbours in an ensemble of classifiers. On the well-studied task of discriminating between string quartet movements by Haydn and Mozart, we obtain accuracies that equal the state of the art on two data-sets. However, in multi-class composer identification, methods specialised for classifying symbolic representations of music are more effective. We also performed experiments on symbolic representations, synthetic audio and two different recordings of The Well-Tempered Clavier by J. S. Bach to study the method’s capacity to distinguish preludes from fugues. Our experimental results show that our approach performs similarly on symbolic representations, synthetic audio and audio recordings, setting our method apart from most previous studies that have been designed for use with either audio or symbolic data, but not both.},
	number = {3},
	urldate = {2019-09-16},
	journal = {Journal of New Music Research},
	author = {Velarde, Gissel and Chacón, Carlos Cancino and Meredith, David and Weyde, Tillman and Grachten, Maarten},
	month = may,
	year = {2018},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Unidentified},
	pages = {191--205}
}

@inproceedings{lidy_improving_2007,
	title = {Improving {Genre} {Classification} by {Combination} of {Audio} and {Symbolic} {Descriptors} {Using} a {Transcription} {System}},
	booktitle = {Proceedings of the 8th {International} {Conference} on {Music} {Information} {Retrieval}},
	author = {Lidy, Thomas and Rauber, Andreas and Pertusa, Antonio and Quereda, José Manuel Inesta},
	year = {2007},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Unidentified},
	pages = {61--66}
}

@inproceedings{mckay_combining_2008,
	address = {Philadelphia, USA},
	title = {Combining {Features} {Extracted} from {Audio}, {Symbolic} and {Cultural} {Sources}.},
	abstract = {This paper experimentally investigates the classification utility of combining features extracted from separate au- dio, symbolic and cultural sources of musical information. This was done via a series of genre classification experi- ments performed using all seven possible combinations and subsets of the three corresponding types of features. These experiments were performed using jMIR, a soft- ware suite designed for use both as a toolset for perform- ing MIR research and as a platform for developing and sharing new algorithms. The experimental results indicate that combining fea- ture types can indeed substantively improve classification accuracy. Accuracies of 96.8\% and 78.8\% were attained respectively on 5 and 10-class genre taxonomies when all three feature types were combined, compared to average respective accuracies of 85.5\% and 65.1\% when features extracted from only one of the three sources of data were used. It was also found that combining feature types de- creased the seriousness of those misclassifications that were made, on average, particularly when cultural features were included.},
	booktitle = {Proceedings of the  9th {International} {Conference} on {Music} {Information} {Retrieval}},
	author = {McKay, Cory and Fujinaga, Ichiro},
	month = jan,
	year = {2008},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Unidentified},
	pages = {597--602}
}

@article{raphael_aligning_2006,
	title = {Aligning music audio with symbolic scores using a hybrid graphical model},
	volume = {65},
	issn = {1573-0565},
	url = {https://doi.org/10.1007/s10994-006-8415-3},
	doi = {10.1007/s10994-006-8415-3},
	abstract = {We present a new method for establishing an alignment between a polyphonic musical score and a corresponding sampled audio performance. The method uses a graphical model containing both latent discrete variables, corresponding to score position, as well as a latent continuous tempo process. We use a simple data model based only on the pitch content of the audio signal. The data interpretation is defined to be the most likely configuration of the hidden variables, given the data, and we develop computational methodology to identify or approximate this configuration using a variant of dynamic programming involving parametrically represented continuous variables. Experiments are presented on a 55-minute hand-marked orchestral test set.},
	language = {en},
	number = {2},
	urldate = {2019-09-16},
	journal = {Machine Learning},
	author = {Raphael, Christopher},
	month = dec,
	year = {2006},
	keywords = {Comps, Comps\_Q4, Comps\_Q4\_Unidentified},
	pages = {389--409}
}

