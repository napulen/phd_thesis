%%
%% This is file `sample-sigconf.tex',
%% generated with the docstrip utility.
%%
%% The original source files were:
%%
%% samples.dtx  (with options: `sigconf')
%% 
%% IMPORTANT NOTICE:
%% 
%% For the copyright see the source file.
%% 
%% Any modified versions of this file must be renamed
%% with new filenames distinct from sample-sigconf.tex.
%% 
%% For distribution of the original source see the terms
%% for copying and modification in the file samples.dtx.
%% 
%% This generated file may be distributed as long as the
%% original source files, as listed above, are part of the
%% same distribution. (The sources need not necessarily be
%% in the same archive or directory.)
%%
%% The first command in your LaTeX source must be the \documentclass command.

\documentclass[sigconf]{acmart}

% \usepackage{geometry}
% \geometry{a4paper, total={6in, 8in}}

%%%% As of March 2017, [siggraph] is no longer used. Please use sigconf (above) for SIGGRAPH conferences.

%%%% As of May 2020, [sigchi] and [sigchi-a] are no longer used. Please use sigconf (above) for SIGCHI conferences.

%%%% Proceedings format for SIGPLAN conferences 
% \documentclass[sigplan, anonymous, review]{acmart}

%%%% Proceedings format for conferences using one-column small layout
% \documentclass[acmsmall,review]{acmart}

%%
%% \BibTeX command to typeset BibTeX logo in the docs
\AtBeginDocument{%
  \providecommand\BibTeX{{%
    \normalfont B\kern-0.5em{\scshape i\kern-0.25em b}\kern-0.8em\TeX}}}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
% \setcopyright{acmlicensed}
% \copyrightyear{2020}
% \acmYear{2020}
% \acmDOI{10.1145/1122445.1122456}

% %% These commands are for a PROCEEDINGS abstract or paper.
% \acmConference[DLfM '20]{DLfM'20: Digital Libraries for Musicology}{October 16, 2020}{Montréal, QC}
% \acmBooktitle{DLfM '20: Digital Libraries for Musicology, 2020, Montréal, QC}
% \acmPrice{15.00}
% \acmISBN{978-1-4503-XXXX-X/18/06}

\setcopyright{acmlicensed}
\copyrightyear{2020}
\acmYear{2020}
\acmDOI{10.1145/3424911.3425515}
\acmConference[DLfM '20]{7th International Conference on Digital Libraries for Musicology}{October 16, 2020}{Montréal, QC, Canada}
\acmBooktitle{7th International Conference on Digital Libraries for Musicology (DLfM '20), October 16, 2020, Montréal, QC, Canada}
\acmPrice{15.00}
\acmISBN{978-1-4503-8760-6/20/10}

%%
%% Submission ID.
%% Use this when submitting an article to a sponsored event. You'll
%% receive a unique submission ID from the organizers
%% of the event, and this ID should be used as the parameter to this command.
%%\acmSubmissionID{123-A56-BU3}

%%
%% The majority of ACM publications use numbered citations and
%% references.  The command \citestyle{authoryear} switches to the
%% "author year" style.
%%
%% If you are preparing content for an event
%% sponsored by ACM SIGGRAPH, you must use the "author year" style of
%% citations and references.
%% Uncommenting
%% the next command will enable that style.
%%\citestyle{acmauthoryear}


%%
%% end of the preamble, start of the body of the document source.
\begin{document}

%%
%% The "title" command has an optional parameter,
%% allowing the author to define a "short title" to be used in page headers.
\title{On Local Keys, Modulations, and Tonicizations}
\subtitle{A Dataset and Methodology for Evaluating Changes of Key}

%%
%% The "author" command and its associated commands are used to define
%% the authors and their affiliations.
%% Of note is the shared affiliation of the first two authors, and the
%% "authornote" and "authornotemark" commands
%% used to denote shared contribution to the research.

\author{N\'estor N\'apoles L\'opez}
\email{nestor.napoleslopez@mail.mcgill.ca}
\authornote{Both authors contributed equally to this work.}
\affiliation{%
  \institution{McGill University, CIRMMT}
  \city{Montr\'eal}
  \country{Canada}
}

\author{Laurent Feisthauer}
\authornotemark[1]
\email{laurent.feisthauer@univ-lille.fr}
\affiliation{%
  \institution{CRIStAL, UMR 9189, CNRS, Université de Lille, Algomus}
  \city{Lille}
  \country{France}
}

\author{Florence Lev\'e}
\email{florence.leve@u-picardie.fr}
\affiliation{%
  \institution{Universit\'e de Picardie Jules Verne, MIS, Algomus}
  \city{Amiens}
  \country{France}
}

% \orcid{1234-5678-9012}
\author{Ichiro Fujinaga}
\email{ichiro.fujinaga@mcgill.ca}
\affiliation{%
  \institution{McGill University, CIRMMT}
%   \streetaddress{P.O. Box 1212}
  \city{Montr\'eal}
  \country{Canada}
%   \postcode{43017-6221}
}

%%
%% By default, the full list of authors will be used in the page
%% headers. Often, this list is too long, and will overlap
%% other information printed in the page headers. This command allows
%% the author to define a more concise list
%% of authors' names for this purpose.
% \renewcommand{\shortauthors}{Trovato and Tobin, et al.}

%%
%% The abstract is a short summary of the work to be presented in the
%% article.
\begin{abstract}
Throughout the common-practice period (1650--1900), it is customary to find changes of musical key within a piece of music. In current music theory terminology, the concepts of \emph{modulation} and \emph{tonicization} are helpful to explain many of these changes of key. Conversely, in computational musicology and music information retrieval, the preferred way to denote changes of key are \emph{local key} features, which are oftentimes predicted by computational models. Therefore, the three concepts, local keys, modulations, and tonicizations describe changes of key. What is, however, the relationship between the local keys, modulations, and tonicizations of the same musical fragment?

In this paper, we contribute to this research question by 1) reviewing the current methods of local-key estimation, 2) providing a new dataset with annotated modulations and tonicizations, and 3) applying all the annotations (i.e., local keys, modulations, and tonicizations) in an experiment that connects the three concepts together. In our experiment, instead of assuming the music-theoretical meaning of the local keys predicted by an algorithm, we evaluate whether these coincide better with the modulation or tonicization annotations of the same musical fragment. Three existing models of symbolic local-key estimation, together with the annotated modulations and tonicizations of five music theory textbooks are considered during our evaluation.

We provide the methodology of our experiment and our dataset (available at~\url{https://github.com/DDMAL/key_modulation_dataset}) to motivate future research in the relationship between local keys, modulations, and tonicizations.
\end{abstract}

%%
%% The code below is generated by the tool at http://dl.acm.org/ccs.cfm.
%% Please copy and paste the code instead of the example below.
%%
\begin{CCSXML}
<ccs2012>
   <concept>
       <concept_id>10010405.10010469.10010475</concept_id>
       <concept_desc>Applied computing~Sound and music computing</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
   <concept>
       <concept_id>10010405.10010469.10010470</concept_id>
       <concept_desc>Applied computing~Fine arts</concept_desc>
       <concept_significance>300</concept_significance>
       </concept>
   <concept>
       <concept_id>10002951.10003317.10003347</concept_id>
       <concept_desc>Information systems~Retrieval tasks and goals</concept_desc>
       <concept_significance>500</concept_significance>
       </concept>
 </ccs2012>
\end{CCSXML}

\ccsdesc[500]{Applied computing~Sound and music computing}
\ccsdesc[300]{Applied computing~Fine arts}
\ccsdesc[500]{Information systems~Retrieval tasks and goals}

%%
%% Keywords. The author(s) should pick words that accurately describe
%% the work being presented. Separate the keywords with commas.
\keywords{computational music theory, local key estimation, music information retrieval, roman numeral analysis, tonality, harmony}

%% A "teaser" image appears between the author and affiliation
%% information and the body of the document, and typically spans the
%% page.
% \begin{teaserfigure}
%   \includegraphics[width=\textwidth]{sampleteaser}
%   \caption{Seattle Mariners at Spring Training, 2010.}
%   \Description{Enjoying the baseball game from the third-base
%   seats. Ichiro Suzuki preparing to bat.}
%   \label{fig:teaser}
% \end{teaserfigure}

%%
%% This command processes the author and affiliation and title
%% information and builds the first part of the formatted document.
\maketitle

\section{Introduction}
Key identification is a fundamental task in the analysis of tonal music. 
It is often a preliminary or concurrent step to other common musicological tasks like harmonic analysis and cadence detection. 
In particular, the knowledge of the musical key can help a music analyst to find boundaries in a musical piece, interpret the role of notes and chords, or suggest a musical form to which the analyzed piece conforms.
Due to its importance, key estimation is a well-studied research topic in Music Information Retrieval (MIR), and multiple key-analysis algorithms have emerged during the last decades. 
Broadly, there are two types of key-estimation algorithms: those that find the \emph{main key} of the piece (often called \emph{global-key-estimation} models in the context of computational musicology and MIR), and those that find the changes of key \emph{within} the piece (often called \emph{local-key-estimation} models). The annotations provided by these models have found applications in music technologies.

%%%%%%%% DLfM relevance %%%%%%%%%
In some contexts such as guitar tablatures \cite{ultimateguitar} and electronic dance music \cite{beatport}, global-key annotations are useful as one of the search parameters of a digital music library. 
Local-key annotations, however, have not yet been used for this purpose. 
It would be useful to complement key-related searches with local-key annotations, using them to search for musical pieces, based on their underlying changes of key. 
% As modulation are powerful tools to change the mood of a score, indexing local keys within the score could help the musicologist make bridges between lyrics and the tonal path. 
However, the ``interpretability'' of local-key annotations requires some attention first. 

Changes of key may belong to different categories. 
In music theory, terms like \emph{modulation} and \emph{tonicization} are helpful for interpreting the context of a change of key. 
Yet, most local-key-estimation research omits an investigation of the relationship between local-key annotations and these categories of changes of key. 
Therefore, as they stand, local-key annotations lack the characteristics that would make them useful in real applications, such as searching for the musical pieces in a large database that showcase similar modulation or tonicization patterns. 
One could think that these queries would be interesting, and quite different to, for example, searching for pieces of music that share the same global key. 

The ideas presented in this paper may be useful to improve the interpretability of the annotations provided by these models.
%%%%%%%% DLfM context %%%%%%%%%


%\cite{longuet1971tonality,  krumhansl1990cognitive, lerdahl88tps, vos96keyfinding, Temperley99:tonality, temperley2006,Zhu2003MusicSM}). 
%In this paper, however, rather than global-key estimation, we focus on the algorithms that model the changes of key \emph{within} a piece of music (often called \emph{local keys} in the context of computational musicology and music information retrieval).

\subsection{Global-Key-Estimation Models}
Researchers have designed a number of global-key-estimation algorithms throughout the years. 
The first one, to our knowledge, is the one by Longuet-Higgins~\cite{longuet1971tonality} from 1971.
Starting from the beginning of a score, the algorithm considers each pitch in order of occurrence and discards the keys that do not include that pitch within their diatonic scale degrees. 
This process is repeated until only one key remains, and some heuristics are applied afterward to help with the most difficult cases. This algorithm was able to retrieve the key of the fugues in J. S. Bach's \emph{Well-tempered Clavier}. 
It also served as a reference for later models, such as the one by Vos and van Geenen~\cite{vos96keyfinding}.

With the introduction of the \emph{probe-tone} technique and \emph{key profiles} in 1979 \cite{krumhansl_quantification_1979}, and their later application to the design of a global-key-estimation algorithm in 1990 \cite{krumhansl_cognitive_1990}, research regarding global-key-estimation models saw a shift toward more \emph{distributional} approaches \cite{temperley2008pitch}. 
Key profiles, originally introduced as listener ratings by Krumhansl et al. \cite{krumhansl_quantification_1979, krumhansl_tracing_1982}, have transitioned into probability distributions that can be used to predict the key of a musical piece.
Alternative key-profile distributions---and techniques for applying them---have been proposed over the years.
% Some of these are shown in Figure \ref{fig:ppro}. 

% and the histogram of pitches extracted from the musical score~\cite{krumhansl1990cognitive} called the \emph{probe tone method}. At about the same time, Lerdahl introduced tonal pitch space~\cite{lerdahl88tps} which can be used as a pitch profile with key finding algorithms.

% \begin{figure}[ht]
%   \includegraphics[width=\columnwidth]{figs/key_prof.png}
%   \caption{Various key profiles proposed by Krumhansl-Kessler \cite{krumhansl_tracing_1982}, Aarden-Essen \cite{aarden03:tonality}, Sapp \cite{saap11:tonality}, Bellman-Budge \cite{Bellmann06tonality}, Temperley \cite{Temperley99:tonality}, and Albrecht-Shanahan \cite{albrecht13:fugue}. Presented as probability distributions. Figure taken from~\cite{napoleslopez2019key} with permission.}
%   \label{fig:ppro}
% \end{figure}

Key profiles are the basis of many global-key-estimation models for symbolic music files and, starting from the 2000s, audio files as well. More exhaustive surveys of modern global-key-estimation techniques, with a focus on audio, are available \cite{korzeniowski_harmonic_2018, campbell_automatic_2010}. Key profiles have also been useful in the design of local-key estimation models.

\subsection{Local Keys, Modulation, and Tonicization}\label{ssec:terminology}

In MIR, it is common to describe algorithms that model \emph{changes of key} as local-key-estimation algorithms. 
The \emph{local keys} being the predictions that these models generate. Conversely, in music theory, the concepts of \emph{modulation} and \emph{tonicization} are often the manner in which changes of key are explained, and the term \emph{local key} is virtually non-existent.

Therefore, the three concepts, local keys, modulations, and tonicizations describe changes of key. 
Yet, what is the meaning of these terms? And what is the relationship between the local keys, modulations, and tonicizations of the same musical fragment?

According to the Grove Music Online dictionary, a modulation ``refers to a firmly established change of key, as opposed to a passing reference to another key, known as a `tonicization' ''~\cite{saslawgrovemodulation}. Moreover, a tonicization is ``the act of establishing a new key centre, or of giving a degree other than the first the role of tonic''~\cite{drabkintonicization}.

A formal definition of local keys is difficult to find. According to Papadopoulos et al.~\cite{papadopoulos_local_2009}, a local key is the ``key of each segment'' of a ``[segmented] musical piece [...] according to the points of modulation''. 

However, after these definitions, it is still difficult to understand the distinction between modulations and tonicizations. Kostka and Payne have suggested that such distinction is not possible: ``The line between modulation and tonicization is not clearly defined in tonal music, nor is it meant to be'' \cite{kostka2008tonal}. 

Regarding local keys, most researchers, as Papadopoulos et al. \cite{papadopoulos_local_2009}, associate them with modulations, however, this relationship has not been explored sufficiently. It would certainly benefit the computational musicology and MIR communities to engage in this exploration, in order to understand what is it that local-key-estimation algorithms predict.

For the scope of this work, we define these terms as follows:

\subsubsection{Modulation} 
Is the change from one key to another. We refer to the initial key as the \emph{departure} key, and the second key as the \emph{destination} key.

\subsubsection{Tonicization} 
Is a brief deviation to a different key, usually with the intention of emphasizing a certain scale degree or harmony. 
The tonicization often returns to the original key briefly after the deviation.

\subsubsection{Local keys}
Are the predictions of the musical key provided by a local-key-estimation algorithm. 
These predictions are given at a finer level of granularity than the entire piece (e.g., notes, onsets, fixed-duration timesteps, audio frames, etc.).
In principle, no music-theoretical meaning is inferred from them. They may coincide with modulations or tonicizations.

\subsection{Local-Key-Estimation Models}\label{ssec:localkey}

Contrary to the global-key estimation approaches, local-key estimation models have a relatively recent history.

% Audio
Purwins et al. introduced a method for tracking changes of key in audio signals %using cq-profiles, which are calculated with the constant Q filter bank
\cite{purwins_new_2000}. 
Their goal is to track the tone center and its variation during the piece. Their references annotate both modulations and tonicizations but consider that the ground truth is the one indicated by the tonicizations.

% symbolic
Chew~\cite{chew2002key} measured the distance from a sequence of pitches to a key using the \emph{spiral array} ~\cite{Chew2000TowardsAM}. 
The succession of keys is then modeled as a sequence of \emph{boundaries} dividing the score in different key areas.

% Audio
Chai and Vercoe designed a model based on a Hidden Markov Model (HMM) to detect changes of key~\cite{chai_detection_2005}. 
They describe the term \emph{modulation} as ``the change of key at some point''. 
Their model detects, at first, the tonal center, and then, the mode of the key.

% Audio 
Catteau et al.~\cite{Catteau07tonalkey} introduced a model for scale and chord recognition, assuming that there is a correspondence between a major scale and a major key, and between a harmonic minor scale and a minor key. Their model is based on the key profiles by Temperley \cite{Temperley99:tonality} and Lerdahl's \emph{tonal pitch spaces} \cite{lerdahl88tps}.

Izmirli introduced a model to find local keys from audio sources, based on non-negative matrix factorization for segmentation~\cite{izmirli_localized_2007}. 
Izmirli also attempted to disambiguate modulations and tonicizations in the following manner: ``Secondary functions and tonicizations are heard as short deviations from the well-grounded key in which they appear---although the boundary between modulation and tonicization is not clear cut. A modulation unambiguously instigates a shift in the key center''. 
% This work is also, to our knowledge, the first time that the term \emph{local keys} has been mentioned in an MIR publication.

Papadopoulos and Peeters adopted a similar approach to Izmirli for audio local-key estimation \cite{papadopoulos_local_2009}.
Their model attempts to segment the score based on the points of modulation. 
They introduced key dependencies on the harmonic and metric structures of global-key-finding methods, in order to convert them into local-key-finding ones. 
% They also discussed the need for more data in chords and local key.

Rocher et al. introduced a model that provides (chord, key) duples for each audio frame of an input excerpt. 
The model is based on a graph and the \emph{best-path} estimation method~\cite{thomas_rocher_2010_1417485}. 
For evaluating key distances, they used the key profiles by Temperley~\cite{Temperley99:tonality}. The authors alluded to the term modulation when discussing their key predictions.

Mearns et al. used an HMM to estimate modulations over audio transcriptions of Bach chorales~\cite{mearns2011automatically}. 
The HMM is trained with chord progressions. 
The emission probability distributions are obtained from two tables with the probabilities of chords existing in a given key. 
These tables are based on the work by Schoenberg and Krumhansl. 
Applied chords (i.e., tonicizations) are not described in these charts, therefore, the authors do not deal with tonicizations.

In 2014, Pauwels and Martens present a probabilistic framework for the simultaneous estimation of chords and keys from audio~\cite{pauwels_combining_2014}. 
They mention the importance of ``integrating prior musical knowledge'' into a local-key-estimation system, however, they do not allude to the terms modulation and tonicization. 
The same year, Weiss et al. proposed an audio scale estimator~\cite{weiss2014chroma}. 
They argue that this estimator can help to determine the local tonality based on G\'{a}rdonyi's scale analysis method. 
They did not use the term tonicization, however, they discussed ``short-time local modulations'', which resemble tonicizations.

Machine learning approaches, especially using neural networks, have recently gained popularity in MIR research, including key estimation. 
Independently, Chen et al. \cite{chen18harmony,chen19harmony} and Micchi et al.~\cite{Micchi20:roman} designed models that estimate local keys as well as roman numeral analysis annotations. Tonicization information is implied by the roman numeral analysis annotations. 

N\'apoles L\'opez et al. introduced a model to find changes of key (local-key estimation) as well as the main key of a piece (global-key estimation), using an HMM \cite{napoleslopez2019key}. 
The model is also capable of working with symbolic and audio data. They do not allude to the terms modulation or tonicization, always referring to their predictions as \emph{local keys}.

One of the most recent models for finding changes of key is by Feisthauer et al.~\cite{feisthauer2020smc}, which has been designed to detect modulations in Classical music. 
It uses three proximity measures established from pitch compatibility, tonality anchoring, and tonality proximity. 
The model computes the cost of being in a key on a given beat, and estimates the succession of keys using dynamic programming techniques.

% As modulations, tonicizations, and local keys all have different representations, they are difficult to compare. We propose a methodology to turn modulations and tonicizations into sequences of labels, a structure that is more compatible with local keys and facilitates the comparison between the music-theoretical concepts and the MIR annotations. 

% Most of them are audio-based ... 

%\subsection{Evaluation and datasets}
\subsection{Existing Datasets to Evaluate Local-Key-Estimation Models}

Most of the models discussed have been evaluated using different datasets, which are presented in Table~\ref{tab:corpus}.

\begin{table}
  \caption{Datasets used to evaluate local-key-estimation models.}
  \label{tab:corpus}
  \begin{tabular}{lcl}
    \toprule
    Model&Files&Dataset\\
    \midrule
    Catteau~\cite{Catteau07tonalkey} & 10 & Manually-built\\
    & & chord sequences\\
    Chai~\cite{chai_detection_2005} & 10 & Various (Classical)\\
    Chen~\cite{chen18harmony,chen19harmony}, Micchi~\cite{Micchi20:roman} & 23 & Beethoven\\
    Chew~\cite{chew2002key} & 2 & Bach\\
    Feisthauer~\cite{feisthauer2020smc} & 38 & Mozart (Classical) \\
    Izmirli~\cite{izmirli_localized_2007} & 17 & Pop songs\\
    & 152 & Naxos set (Classical)\\
    & 17 & Kostka-Payne (Classical)\\
    Mearns~\cite{mearns2011automatically} & 12 & Bach Chorales \\
    Micchi~\cite{Micchi20:roman} &  27 &  TAVERN (Classical)\\
    & 70 & ABC (Beethoven)\\ 
    & 72 & Roman Text (Classical)\\
    Papadopoulos~\cite{papadopoulos_local_2009} & 5 & Mozart\\
    Pauwels~\cite{pauwels_combining_2014} & 142 & SEMA Set (Pop)\\
    & 210 & MIREX 2009\\
    Purwins~\cite{purwins_new_2000} and & 1 & Chopin\\
    Napol\'{e}s Lop\'{e}z~\cite{napoleslopez2019key} & & \\
    Rocher~\cite{thomas_rocher_2010_1417485} & 174 & Beatles\\
    Weiss~\cite{weiss2014chroma} & 10 & Various (Classical) \\
  \bottomrule
\end{tabular}
\end{table}

The datasets used for evaluating local-key-estimation algorithms are typically small. 
Additionally, each dataset has often been used to evaluate a single model, which makes the comparison between models somewhat dubious. 
In this paper, we contribute further discussion around this topic by focusing on the following question: \emph{What is the relationship between the local keys, modulations, and tonicizations of the same musical fragment?} 
For this purpose, we describe: (1) our methodology for comparing annotations of local keys, modulations, and tonicizations, (2) a dataset that we collected from five music theory textbooks, and (3) an experiment where we evaluated three existing local-key-estimation models.

\section{Local keys and music theory}\label{sec:prob}

It is challenging to compare, in principle, local key annotations---intrinsically subject to computational considerations (e.g., input constraints or training data)---to modulations and tonicizations, which are rooted in music theory.

In order to achieve a comparison, an initial step involves finding a common representation between local keys, modulations, and tonicizations.
For this purpose, we convert an annotated score with the three classes of annotations into a sequence of key labels that share the same level of granularity. 
There are multiple ways to determine the ``slicing'' of the musical excerpt or level of granularity. 
We opted for \emph{onsets}.\footnote{The precise moment when a note (or simultaneously-sounding group of notes) is played ~\cite{bello05onset}.} 
That is, for every note \emph{onset} in the score, we have a corresponding annotation of the key. 
This level of granularity is especially convenient for encoding roman numeral analysis annotations, the way in which we encode the modulations and tonicizations in our dataset.

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figs/example-w-ambiguity}
  \caption{Example 3-17b in Rimsky-Korsakov's \emph{Practical Manual of Harmony} \cite{rimskitonality}.
  Roman numeral annotations describe the harmonies on each onset of the score and have been written by the theorist. Some of the roman numeral annotations also indicate tonicizations. These have been framed.}
  \label{fig:example}
  \Description{A sample score from Rimsky-Korsakov's Practical Manual of Harmony.}
\end{figure}

In Figure \ref{fig:example}, we introduce a musical score with annotated modulations and tonicizations. 
Two modulations are observed. 
The first one, departing from C major and arriving to F major (measure 4). 
The second one, departing from F major and returning to C major. Between the two modulation events, the \emph{destination} key of one modulation becomes the \emph{departure} key of the next modulation.

Throughout the excerpt, there are also six tonicizations, identified by the presence of at least one forward slash symbol (``/'') in the roman numeral annotation.\footnote{The slash is a conventional notation in roman numeral analysis ~\cite{Tymoczko2019, huron_representation}. The roman numeral before the slash symbol denotes a chord, and the roman numeral after the slash symbol denotes a tonicized key.} 
The tonicizations that occur during the first modulation (\emph{departure} key), deviate briefly from C major to D minor (measure 1) and F major (measures 2 and 3); the ones in the second modulation deviate from F major to C major (measures 5 and 7).

Table \ref{tab:annotations} shows the generated modulation-and-tonicization labels of every onset. 
There are several conventions for digitally encoding roman numeral annotations \cite{huron_representation, Tymoczko2019, napoleslopez20harmalysis}. 
We opted for \emph{harmalysis} \cite{napoleslopez20harmalysis}, an extension of \emph{**harm} \cite{huron_representation}.
Once the roman numeral annotations have been digitally encoded within the scores, it is fairly simple to retrieve the sequence of key labels.

\begin{table}[h]
  \caption{Computer representation of the roman numeral annotations of the excerpt in Figure \ref{fig:example}. The modulation and tonicization columns are auto-generated based on the roman numeral annotations. Each row is an onset in the score. The position of the onset is indicated at the first column of the table, as quarter notes from the beginning of the score.}
  \label{tab:annotations}
  \begin{tabular}{c|lcc}
    \toprule
    Position&Annotation&Modulation&Tonicization\\
    \midrule
    0 & C=>:I & C major & C major \\
    2 & viio7/ii & C major & D minor \\
    4 & ii & C major & C major \\
    6 & IV/IV & C major & F major \\
    8 & V/IV & C major & F major \\
    10 & V7/IV & C major & F major \\
    12 & F=>:I6 & F major & F major \\
    14 & V43 & F major & F major \\
    16 & I & F major & F major \\
    18 & V2/V & F major & C major \\
    20 & V6 & F major & F major \\
    22 & V & F major & F major \\
    24 & I6 & F major & F major \\
    26 & V7/V & F major & C major \\
    28 & C=>:I & C major & C major \\
   \bottomrule
\end{tabular}
\end{table}

\subsection{Encoding Modulations}
We derive the ground-truth keys of the modulation column based on the \emph{departure} keys. 
For every onset slice before a \emph{destination} key is reached, the \emph{departure} key is written as the ground-truth label of that particular onset. 
Once a \emph{destination} key is reached, it is considered to be the new \emph{departure} key, and the process repeats. 

In Table~\ref{tab:annotations}, the departure keys are indicated by a key spelling followed by the token ``\texttt{=>:}''. 
Every modulation annotation is considered in that key until a new one is indicated.

\subsection{Encoding Tonicizations}~\label{sec:tonicization}
We derive the ground-truth keys of the tonicization column based on the keys implied by the roman numeral annotations.
When there is no tonicization indication, the key is copied from the modulation column.
When the roman numeral implies a different---tonicized---key, the ground-truth label is the key implied by the roman numeral annotation. Using this encoding strategy, we are able to compare local-key predictions to modulation and tonicization annotations. 

\subsection{Key and Chord Ambiguity}~\label{sec:ambiguity}
Although we have centered the discussion around changes of key, the line between an analysis of key changes and harmonic analysis may be blurry. 
This is especially true for tonicizations, which have a shorter temporal scope and often emphasize a scale degree or even a specific harmony. 
Our decision to encode tonicizations as roman numeral annotations reflects this relationship.

There are datasets available with encoded roman numeral analysis annotations \cite{neuwirth_annotated_2018, devaney2015tavern, Tymoczko2019}, which could be used for studying changes of key in the manner that we have presented here. 
However, it is important to acknowledge that roman numeral annotations are subject to issues such as ambiguity and disagreement \cite{condit-schultz2018, koops19, selway2020, arthur2017harmony}, which may have implications for determining \emph{where} the changes of key occur. 
For example, the dashed regions in Figure \ref{fig:example} show the areas where the key is ambiguous. The exact position of the ``arrival'' key within an ambiguous zone could, potentially, vary from one analyst to another. This may have implications for the modulation and tonicization annotations.

In this work, we have tried to reduce the implications related to the complexity of harmonic analysis by utilizing a collection of scores that have been written or displayed specifically to demonstrate modulations, mostly in the manner of instructional or ``cherry-picked'' examples by the authors of five music theory textbooks. 

Most of the examples in the dataset are: (1) very short (4--8 measures), (2) including at least one modulation, and (3) often accompanied by text explanations written by the theorists, which describe the modulation thoroughly.

We consider that these additional characteristics make this dataset slightly more robust to the issues related to disagreement and ambiguity. 
Therefore, they could be more suitable for studying changes of key than existing roman numeral analysis datasets.

% The annotations of the examples respected the theorist's key regions. We also utilized the text explanations to guide our encoding process.

% We followed this encoding procedure systematically across all the pieces of our dataset.

\section{Dataset}~\label{sec:dataset}
All the labels in the dataset have been obtained from the modulation excerpts of five music theory textbooks, written by different music theorists and/or composers (whom we simply refer to as ``theorists'' for the rest of this paper).

The dataset contains, in total, 201 excerpts of music with annotated modulations and tonicizations. 
The annotations are encoded in the form of roman numerals of all the chords in the dataset, which can be helpful for utilizing the dataset for other purposes beside the one presented here (e.g., chord labeling or cadence detection).
Each file has been encoded in Humdrum (**kern) symbolic music representations ~\cite{Huron02:humdrum}. 
As mentioned, the roman numeral annotations have been digitally encoded \cite{napoleslopez20harmalysis} within the scores.

When the theorists provided roman numeral annotations, those have been preserved in our digital transcriptions. 
Otherwise, we furnished them. All the annotations related to modulations have been obtained exclusively from the textbooks. 
Tonicizations rely on the roman numeral annotations of the chords and these were not always provided in the textbooks, therefore, we supplied some of them.

The issues of ambiguity discussed in Section \ref{sec:ambiguity} might have implications mostly for tonicizations (the ones we sometimes contributed ourselves).
However, modulations have always been provided by the theorists, and we expect this to reduce the impact of these issues. 
For some onsets, multiple key annotations were provided by the theorists. For these excerpts, we decided to encode the keys in chronological order. 
An example is shown in Figure \ref{fig:multiplekeys}.\footnote{Whenever a new key was established according to the theorists' annotations, we considered that to be the only key in the modulation column, until a new one appeared to replace it. 
We applied this process systematically throughout the dataset. %Despite the loss of informations, this unique annotation line is more easily processed by local key estimation models.
}

\begin{figure}[h]
  \centering
  \includegraphics[width=\linewidth]{figs/multiplekey2}
  \caption{Example 18-3 in Kostka-Payne's Tonal Harmony~\cite{kostka2008tonal}. Two concurrent keys (G Major and F Major) are annotated in the fourth beat of measure 1. We considered the key label of this onset to be ``F Major'' for the modulation column.}
  \Description{Example 18-3 in Kostka-Payne's Tonal Harmony. Two concurrent keys appear in the same onset.}
  \label{fig:multiplekeys}
\end{figure}

We describe the five textbooks and their abbreviations, which we use throughout the experiment section.

\subsection{Sources of the Annotations}

	\subsubsection{Aldwell, Schachter, and Cadwallader~(ASC) [USA, contemporary]}
	The modulation excerpts are taken from chapter 27 \emph{Diatonic Modulations} of the \emph{Harmony and Voice Leading} ~\cite{aldwell2018harmony}.
	This textbook provided seven excerpts to the dataset, the smallest amount among all textbooks. 
	These excerpts are extracts from Bach Chorales (4), Mozart's Trio for Clarinet (1), and two original examples.  
	
	\subsubsection{Kostka and Payne~(KP) [USA, contemporary]}
	The modulation excerpts are taken from the 18th and 19th chapters of \emph{Tonal Harmony}~\cite{kostka2008tonal}. 
	We took fifteen excerpts from this book, which are fragments of pieces written by Classical and Romantic composers. 
	Previously, the annotated audio excerpts of the accompanying workbook were used for another local-key estimation study \cite{izmirli_localized_2007}, however, we encoded the score excerpts of the main textbook.
	
	\subsubsection{Reger~(Reg) [Germany, 1904]}
	A hundred modulation excerpts are taken from \emph{On the Theory of Modulation}\footnote{The book we used is the republication by \emph{Dover} with the title \emph{Modulation} (2007).}~\cite{regermodulation}. 
	The excerpts are very short and they are all written by Reger himself. 
	Reger's goal was to provide cadence-like examples of modulation from two keys (C major and A minor) to almost every other possible key. 
	
	Seventeen of the examples had two terminations: one in a major key and one in a minor key.\footnote{Usually parallel keys that shared a closing dominant harmony and resolved to either the major or minor mode, with the same tonic.} 
	We separated these examples into two files, one for each of the terminations.
	This increased the total number of examples from 100 to 117.
	
	\subsubsection{Rimsky-Korsakov~(Rim) [Russia, 1886]}
	The modulation excerpts are taken from the third section of the \emph{Practical Manual of Harmony}~\cite{rimskitonality}. 
	As with Reger, all the thirty-seven examples in this textbook are written by the author himself. 
	Some of the examples, however, are more detailed and longer in duration than the ones by Reger.
	
	\subsubsection{Tchaikovsky~(Tch) [Russia, 1872]}
	The modulation examples considered are taken from the third section of the \emph{Guide to the Practical Study of Harmony}~\cite{tchaikovsky1872guide}.
	All twenty-five examples were written by Tchaikovsky himself.

\subsection{Statistics About the Dataset}\label{ssec:stats}

Some statistics about the dataset are presented in Table~\ref{tab:dataset}. 
We report, for each of the textbooks: the number of files (excerpts), the number of modulations, the number of tonicizations, and the number of labels (which is equivalent to the number of onsets, as we supplied one label per onset).

\begin{table}
  \caption{Summary of the dataset. Each value indicates the number of occurrences in the corresponding textbook.}
% The column ``Tonicized'' denotes the number of labels with a tonicization label that differs from the key of the modulation (e.g., Offset 2 in Table \ref{tab:annotations}).
  \label{tab:dataset}
  \begin{tabular}{l|cccc}
    \toprule
    Sample & Files & Modulations & Tonicizations & Labels\\
    \midrule
    ASC & 7 & 8 & 7 & 185\\
    KP & 15 & 21 & 11 & 554\\
    Reg & 117 & 220 & 40 & 768\\ 
    Rim & 37 & 44 & 107 & 257\\ 
    Tch & 25 & 60 & 38 & 238\\
    Total & 201 & 555 & 203 & 2002 \\
  \bottomrule
\end{tabular}
\end{table}

The \emph{Reg} textbook is by far the one that contributed the largest number of excerpts. 
However, the ones providing a higher ratio of labels per number of files are \emph{ASC} ($26.42$) and \emph{KP} ($36.93$). 
This may be due to the use of musical examples taken from the literature, where modulations occur within a musical context and, therefore, span longer regions.

\emph{Rim} and \emph{Tch} are the textbooks that provided the highest number of tonicizations. 
They show tonicizations in $41.63\%$ and $15.97\%$ of the onsets, respectively. 
In terms of investigating the relationship between predicted local keys and modulations/tonicizations, these textbooks contributed the most interesting examples.

\emph{Rim} and \emph{Tch} also tend to set the annotations of the \emph{destination} key of a modulation in the tonic degree, considering any preceding dominant chords as secondary dominants and, consequently, part of the \emph{departure} key (as shown on Figure~\ref{fig:example}). 
Other theorists, on the other hand, often set the \emph{destination} key already in the dominant chords that precede the tonic. 
Therefore, they do not annotate (or imply)\footnote{For the cases in which we provided the roman numeral annotations because they were not provided by the theorists.} a tonicization for the preceding dominant chords. 

\section{Experiment}~\label{sec:exp}

In our experiment, we investigate whether the predictions of three local-key-estimation computational models coincide with the modulation and tonicization annotations of the music theory textbooks.

\subsection{Evaluation Procedure}~\label{sec:evaluations}

Even if two predicted keys do not match the ground-truth label, one of the predictions may still be better than the other, due to the \emph{close} or \emph{far} relationship that a predicted key may have to the ground truth. 
For this reason, in addition to accuracy, we propose to also use a weighted score to evaluate each onset's key.

Table \ref{tab:mirexscore} shows the two sets of weights we utilized to evaluate the key predictions, based on the relationship that the predicted key has to the ground truth. 
The MIREX score has been used in the annual Music Information Retrieval Evaluation eXchange (MIREX) evaluation of global-key-estimation algorithms since 2005 \cite{downie2005}.

% \begin{table}[h]
% \begin{tabular}{l|l}
% \textbf{Key prediction's relation to the ground truth} & \textbf{Score} \\ \hline
% Same key & 1.0 \\
% Dominant / SubDominant & 0.5 \\
% Relative Major / Relative Minor & 0.3 \\
% Parallel Major / Parallel Minor & 0.2 \\
% Other & 0.0 \\
% \end{tabular}
% \caption{MIREX weighted score for key predictions.}
% \label{tab:mirexscore}
% \end{table}

\begin{table}[h]
  \caption{Evaluation weights for the key predictions.}
  \label{tab:mirexscore}
  \begin{tabular}{l|cc}
    \toprule
    Key Relationship (Reference, Predicted) & Accuracy & MIREX\\
    \midrule
    Same key & 1.0 & 1.0 \\
    Dominant / SubDominant & 0.0 & 0.5 \\
    Relative Major / Relative Minor & 0.0 & 0.3 \\
    Parallel Major / Parallel Minor & 0.0 & 0.2 \\
    Other & 0.0 & 0.0 \\
    \bottomrule
\end{tabular}
\end{table}

We apply both evaluations to the key of every onset in the score. 
The annotations are evaluated according to Equation \ref{eqn:mirex}.

\begin{equation}
    \label{eqn:mirex}
    \mathit{score} = \frac{\sum_{i=0}^{N} \mathit{w(k_i, l_i) d_i}}{\sum_{i=0}^{N} d_i}
\end{equation}

$N$ represents the number of onsets in the input score, $k$ is a vector of ground-truth key annotations for each onset, $l$ is the vector of local-key predictions provided by the model for each onset, and $d$ is a vector with the durations in quarter notes of every onset.
Note that the vector $k$ corresponds to either the labels in the \emph{Modulation} or \emph{Tonicization} columns of Table \ref{tab:annotations}, depending on the task.
 
The $w$ function is a piece-wise function that evaluates either of the weighted scores shown in Table \ref{tab:mirexscore}, given a ground-truth key and a prediction. 
The scalar value $score$ is in the range $[0, 1]$. A value of $1.0$ is obtained if and only if the model predicts the key correctly at every onset. 
A value of $0.0$ is obtained if and only if the model makes incorrect predictions (and for the MIREX weights, also without any partial value) at each onset.

Using this methodology, we evaluate four baseline models and three local-key-estimation models from the literature. 
In total, we perform four evaluations for each model: % (1) modulation with the accuracy weights, (2) tonicization with the accuracy weights, (3) modulation with the MIREX weights, and (4) tonicization with the MIREX weights.
\begin{enumerate}
    \item Modulation ($k=Modulation$) by accuracy ($w=Accuracy$).
    \item Tonicization ($k=Tonicization$) by accuracy ($w=Accuracy$).
    \item Modulation ($k=Modulation$) by MIREX ($w=MIREX$).
    \item Tonicization ($k=Tonicization$) by MIREX ($w=MIREX$).
\end{enumerate}

These evaluations coincide with the results shown in Figure~\ref{fig:plot}.

% \begin{table}[h]
%  \caption{Evaluations}
%  \label{tab:evaluations}
%  \begin{tabular}{l|ll}
%     \toprule
%      & Accuracy weights & MIREX weights \\
%     \midrule
%     Modulation Ground Truth & Evaluation 1 & Evaluation 3 \\
%     Tonicization Ground Truth & Evaluation 2 & Evaluation 4 \\
%  \bottomrule
% \end{tabular}
% \end{table}

\subsection{Baseline Models}

We describe two baseline models (\emph{B1} and \emph{B2}) that---we expect---will perform worse than existing local-key-estimation algorithms. 
Similarly, we propose two theoretical ``models'' that set the maximum performance that can be achieved when designing a modulation or tonicization model (\emph{B3} and \emph{B4}). 
These artificial models consist simply of the ground truth annotations for modulations and tonicizations, but evaluated in the opposite task (i.e., as if they were local-key predictions coming from a model). 
We expect that these baselines will set a reasonable frame for inspecting the performance of the \emph{real} local-key-estimation models.

\subsubsection{Random guess (B1)}
This model randomly chooses a key label for every onset in the piece.\footnote{
%In all of our evaluations, we collapse two enharmonic spellings of a key as the same key label (in the range [0--23]). 
The key label is generated by choosing randomly between 24 possible keys ([0--23]), collapsing all enharmonic spellings into the same class. 
This may occlude important hints given in the note spellings of music scores, however it guarantees that this method can be applied to MIDI and audio files, which lack pitch-spelling information.} 
We expect this model (\emph{B1}) to be the worst-performing model in our experiment.

\subsubsection{Global-key guess (B2)}
Given the large body of work that exists in global-key-estimation algorithms, it would be reasonable to assume that using the predictions of a global-key-estimation model in every onset would deliver reasonable results. 
We incorporate these global-key predictions as a baseline model, to compare it against the more specialized local-key-estimation models. 
The global-key-estimation model that we considered is the default key-estimation model in music21 \cite{cuthbert2010music21}.

\subsubsection{Modulation (B3) and tonicization (B4) ground truth}

Due to the overlap that exists between the modulation and tonicization key labels,\footnote{This is because we duplicate the modulation label in the tonicization column unless there is a tonicization (see Table \ref{tab:annotations}).} it is expected that a good-performing modulation model would also achieve a good performance in predicting tonicizations (and vice versa). 
In order to observe this, we consider two additional models: the ground truth of modulation employed as a ``model'' that predicts tonicization (\emph{B3}), and the ground truth of tonicization employed as a ``model'' that predicts modulation (\emph{B4}). 
For simplicity, we refer to these as baseline models, although they represent ground-truth annotations and not computational models per se.

We evaluate the performance that each of these theoretical models, \emph{B3} and \emph{B4}, achieves in its own task and the opposite one. More specifically, we expect the following: (1) these models should obtain a perfect score in their own task (no matter which weights are utilized) and (2) both models should obtain an identical performance when evaluated in the opposite task.\footnote{This is also true for the MIREX weights, because the evaluation is symmetrical. That is, $w(gt, pred) = w(pred, gt)$; when $w=MIREX$}

\subsection{Local-Key Models from the Literature}
Three recent models of local-key estimation are evaluated. 
As part of the results in this paper, we intend to investigate whether these three models are better suited for finding ``modulations'' or ``tonicizations''. 
We consider that this methodology could equally be applied to other symbolic and audio local-key-estimation models.

\subsubsection{N\'{a}poles L\'opez et al. (M1)}
This model computes two stages of output: local keys and a global key \cite{napoleslopez2019key}. Both stages are computed through an HMM. 
The main parameters of the HMM are a set of \emph{key profiles} and a table of key distances. 
We compute both stages but only evaluate the local-key predictions. 
The model is applied with its default parameters.

\subsubsection{Feisthauer et al. (M2)}
This model estimates the succession of keys and can be configured by adjusting the weights associated to three proximity measures~\cite{feisthauer2020smc}. 
Two sets of weights are used. 
The first set consists of the default weights when the model is not trained (M2a).
The second set consists of the optimal weights after training the model on Mozart's string quartets (M2b). 

\subsubsection{Micchi et al. (M3)}
This model was introduced by Micchi et al.~\cite{Micchi20:roman} and utilizes an LSTM network to provide the harmonic analysis of a musical excerpt, which is described through six features: key, degree 1, degree 2, quality, inversion, and root. 
We evaluate the key predictions of the model when it is used without any post-processing. 
A web application is also provided by Micchi et al. to facilitate the process of generating these or other annotations.\footnote{ \url{http://roman.algomus.fr/}}

All of the local-key-estimation models have been trained on different datasets (see Table \ref{tab:corpus}) and have been used with their default parameters. 
The dataset of modulations and tonicizations introduced in Section \ref{sec:dataset} has been utilized only as a \emph{test} set to these models. 
It is likely that the models would achieve better results if they were trained on a sample of the dataset. 
However, the current size of the dataset is not sufficient to provide training, validation, and test splits. 
Therefore, we decided to limit its use as a test set. With this, we investigate the generalization capabilities of these pre-trained models. 

\section{Results and discussion}~\label{sec:res}

Figure \ref{fig:plot} shows the four evaluations of the baseline and local-key-estimation models. 
The MIREX scores are generally higher because they reward a key prediction that is \emph{nearby} the correct class. 
This has increased the results of virtually all models. However, the global-key baseline model (\emph{B2}) has benefited the most from the MIREX evaluation, followed by \emph{M2b}. 
This suggests that these models predict keys that are nearby the ground truth, while other models tend to ``hit-or-miss''. 

For the reverse ground truth ``models'', \emph{B3} and \emph{B4}, the results are symmetric, as expected. 
When they are used in the opposite task, they have a quasi-perfect evaluation on \emph{ASC}, \emph{KP} and \emph{Reg}. 
Incidentally, this shows the relatively low number of tonicizations in these textbooks (see Section \ref{sec:tonicization}). 
However, in \emph{Tch} and especially \emph{Rim}, where there is a heavier use of tonicizations, the local-key-estimation models show an inclination toward the tonicization predictions, rather than the modulation ones. 
This is unexpected, as most researchers do not describe their local-key-estimation models as ``tonicization finders''.

As expected, the random-guess baseline (\emph{B1}) is the worst performing model in all evaluations. 
It also highlights the success of the global-key-estimation model (\emph{B2}) compared to a random guess. This model (\emph{B2}) achieves good performance overall; in the \emph{Reg} examples, it even achieves better performance than all the specialized local-key-estimation models (\emph{M1}, \emph{M2a-b}, and \emph{M3}). 

% Despite that this dataset is specialized on musical contexts with modulations and tonicizations, there are still many onsets that match the prediction of the global key.

The N\'apoles L\'opez et al. model \emph{(M1)} achieves a good performance overall, and does slightly better in predicting tonicizations than modulations. 
This is at least the case for \emph{Tch}, and more evidently, for \emph{Rim}.


\begin{figure*}
  \centering
  \includegraphics[width=\linewidth]{figs/plots_table}
  \caption{Evaluation scores for each model on each textbook of our dataset. The models predict modulations and tonicizations. Furthermore, they are evaluated using accuracy and MIREX weights, as described in Section \ref{sec:evaluations}. A plot is shown for each of the four evaluations. The $y$ axis shows the evaluations on different textbooks of our dataset, as the performance varies from one to another. The $x$ axis shows the mean score obtained by a model across all the files in the textbook. Bold scores indicate the best-performing model in a given textbook and task, excluding \emph{B3} and \emph{B4} (see Section 4.2.3).}
  \label{fig:plot}
  \Description{A plot of the results for both tasks according to the MIREX score.}
\end{figure*}

% \begin{table}
%  \caption{Accuracy score.}
%  \label{tab:acc_results}
%  \begin{tabular}{clccccc}
%     \toprule
%     Model & Task & ASC & KP & Reg & Rim & Tch\\
%     \midrule
%     B1 & Mod & 0.05 & 0.03 & 0.02 & 0.04 & 0.03\\
%       & Ton & 0.05 & 0.03 & 0.02 & 0.07 & 0.05\\
%     B2 & Mod & 0.61 & 0.49 & \textbf{0.53} & 0.28 & 0.25\\
%       & Ton & 0.62 & 0.48 & \textbf{0.52} & 0.52 & 0.34\\
%     \hline
%     M1 & Mod & 0.82 & 0.74 & 0.45 & 0.35 & 0.51\\
%       & Ton & \textbf{0.84} & 0.75 & 0.45 & 0.69 & 0.63\\
%     M2a & Mod & 0.78 & 0.52 & 0.36 & 0.35 & \textbf{0.70}\\
%         & Ton & 0.79 & 0.52 & 0.36 & 0.47 & \textbf{0.77}\\
%     M2b & Mod & 0.44 & 0.39 & 0.11 & 0.37 & 0.41\\
%         & Ton & 0.44 & 0.39 & 0.11 & 0.27 & 0.32\\
%     M3 & Mod & \textbf{0.83} & \textbf{0.83} & 0.48 & \textbf{0.40} & 0.58\\
%       & Ton & 0.83 & \textbf{0.83} & 0.49 & \textbf{0.75} & 0.72\\
%     \hline
%     B3 & Mod & 1.00 & 1.00 & 1.00 & 1.00 & 1.00\\
%       & Ton & 0.98 & 0.98 & 0.97 & 0.57 & 0.78\\
%     B4 & Mod & 0.98 & 0.98 & 0.97 & 0.57 & 0.78\\
%       & Ton & 1.00 & 1.00 & 1.00 & 1.00 & 1.00\\
%  \bottomrule
% \end{tabular}
% \end{table}

% \begin{table}
%  \caption{MIREX weighted score}
%  \label{tab:mirex_results}
%  \begin{tabular}{clccccc}
%     \toprule
%     Model & Task & ASC & KP & Reg & Rim & Tch\\
%     \midrule
%     B1 & Mod & 0.09 & 0.10 & 0.08 & 0.11 & 0.10\\
%       & Ton & 0.10 & 0.10 & 0.08 & 0.13 & 0.13\\
%     B2 & Mod & 0.69 & 0.60 & \textbf{0.58} & 0.46 & 0.37\\
%       & Ton & 0.69 & 0.59 & \textbf{0.57} & 0.64 & 0.47\\
%     \hline
%     M1 & Mod & \textbf{0.86} & 0.83 & 0.53 & 0.49 & 0.61\\
%       & Ton & \textbf{0.87} & 0.83 & 0.54 & 0.77 & 0.74\\
%     M2a & Mod & 0.84 & 0.58 & 0.45 & 0.51 & \textbf{0.75}\\
%         & Ton & 0.84 & 0.58 & 0.45 & 0.58 & \textbf{0.81}\\
%     M2b & Mod & 0.63 & 0.47 & 0.18 & \textbf{0.55} & 0.49\\
%         & Ton & 0.63 & 0.46 & 0.18 & 0.43 & 0.41\\
%     M3 & Mod & \textbf{0.86} & \textbf{0.88} & 0.55 & 0.53 & 0.67\\
%       & Ton & 0.86 & \textbf{0.88} & 0.56 & \textbf{ing} & 0.80\\
%     \hline
%     B3 & Mod & 1.00 & 1.00 & 1.00 & 1.00 & 1.00\\
%       & Ton & 0.99 & 0.98 & 0.98 & 0.65 & 0.81\\
%     B4 & Mod & 0.99 & 0.98 & 0.98 & 0.65 & 0.81\\
%       & Ton & 1.00 & 1.00 & 1.00 & 1.00 & 1.00\\
%  \bottomrule
% \end{tabular}
% \end{table}

The proximity measure model \emph{M2a} gets a lower average score than \emph{M1} and \emph{M3}, except in the \emph{Tch} textbook. 
It also performs better on the tonicization task than on the modulation one. 
The variant of this model, \emph{M2b}, gets, on average, the worst results of all the models (excluding \emph{B1}). It also seems to be the only model doing better in predicting modulations than tonicizations. 
%A possible explanation for the relatively low scores obtained by this model (\emph{M2b}) could be that it was trained on complete musical pieces by Mozart, where modulations are prepared for several measures that are different from the short excerpts of this dataset.
% The reason might be its training over complete musical pieces, where modulations spans over several measures, favoring the key stability over modulation.
The reason for this could be that the model was trained with complete musical pieces; the modulations in those pieces span several measures and, therefore, differ notably from the short excerpts used in this dataset.

\emph{M3} results are slightly better than those obtained by \emph{M1}. 
It is also interesting that these two models (\emph{M1} and \emph{M3}) show a similar performance ``shape'' across all of the dataset (see Figure \ref{fig:plot}), despite their disparities in design and methodology. 
For example, both do poorly predicting the modulation ground truth of \emph{Rim}, and better in predicting the tonicization ground truth. 
This is contrasting to the performance of, for example, \emph{M2b}, which did better for modulation than it did for tonicization in \emph{Rim}, and shows a different performance ``shape'' to these models (\emph{M1} and \emph{M3}). 

Lastly, even within this collection of ``cherry-picked'' examples of modulation, the diversity in the annotations by different theorists is perceivable. 
Some, such as \emph{Rim} and \emph{Tch} make heavier use of tonicizations in their annotations, while \emph{ASC}, \emph{KP}, and \emph{Reg} do not. 
This might be related to the issues of ambiguity and disagreement mentioned in Section \ref{sec:ambiguity}. 
Our evaluation methodology is not doing a great deal in compensating for these issues. Future revisions of the methods for evaluating local-key-estimation algorithms and more data could certainly be of help toward addressing these problems.

\section{Conclusion}~\label{sec:discussion}

In this paper, we discussed the need to further investigate the notion of a \emph{local key}, common in computational musicology and music information retrieval, and its relationship to the music-theoretical concepts of \emph{modulation} and \emph{tonicization}. 
We provided a small dataset of modulations and tonicizations that we collected from five music theory textbooks. 
With this dataset and a proposed methodology, we evaluated four baseline models and three local-key-estimation algorithms from the literature. 
We consider that this methodology could be applied to other algorithms in the symbolic and audio domain, and may contribute to overcome some of the semantic gaps between the terminology of MIR research and music theory. 
The dataset introduced in Section \ref{sec:dataset} has been made publicly available under a Creative Commons Attribution 4.0 International License at the following location: ~\url{https://github.com/DDMAL/key_modulation_dataset}.

% Additionally, we evaluate the \emph{overlap} between the modulation and tonicization ground truth when they are used to predict the opposite annotation, contributing our data-driven take on an old music-theoretical debate, namely, the boundary between the concepts of modulation and tonicization.

\begin{acks}
This research has been supported by the Social Sciences and Humanities Research Council of Canada (SSHRC) and the Fonds de recherche du Québec–Société et culture (FRQSC).

We would like to thank Micchi et al. for facilitating us with the predictions of their algorithm \cite{Micchi20:roman} using our dataset. Similarly, we would like to thank the anonymous reviewers of a previous version of this manuscript, who provided precious feedback for this version.
\end{acks}


%\begin{figure}
%  \centering
%  \includegraphics[width=\linewidth]{figs/index.png}
%  \caption{Mean accuracy for each model in the modulation and tonicization tasks. The $y$ axis shows the evaluations on different subsets of our test dataset, as the performance varies from one subset to another.}
%  \label{fig:mirex_results}
%  \Description{A plot of the results for both tasks according to the MIREX score.}
%\end{figure}

%\begin{figure}
%  \centering
%  \includegraphics[width=\linewidth]{figs/mirex.png}
%  \caption{Mean MIREX scores for each model in the modulation and tonicization tasks. The $y$ axis shows the evaluations on different subsets of our test dataset, as the performance varies from one subset to another.}
%  \label{fig:mirex_results}
%  \Description{A plot of the results for both tasks according to the MIREX score.}
%\end{figure}

%
% room for figure results
%

% \section{CCS Concepts and User-Defined Keywords}

% Two elements of the ``acmart'' document class provide powerful
% taxonomic tools for you to help readers find your work in an online
% search.

% The ACM Computing Classification System ---
% \url{https://www.acm.org/publications/class-2012} --- is a set of
% classifiers and concepts that describe the computing
% discipline. Authors can select entries from this classification
% system, via \url{https://dl.acm.org/ccs/ccs.cfm}, and generate the
% commands to be included in the \LaTeX\ source.

% User-defined keywords are a comma-separated list of words and phrases
% of the authors' choosing, providing a more flexible way of describing
% the research being presented.

% CCS concepts and user-defined keywords are required for for all
% articles over two pages in length, and are optional for one- and
% two-page articles (or abstracts).

% How to do tables

% \begin{table}
%   \caption{Frequency of Special Characters}
%   \label{tab:freq}
%   \begin{tabular}{ccl}
%     \toprule
%     Non-English or Math&Frequency&Comments\\
%     \midrule
%     \O & 1 in 1,000& For Swedish names\\
%     $\pi$ & 1 in 5& Common in math\\
%     \$ & 4 in 5 & Used in business\\
%     $\Psi^2_1$ & 1 in 40,000& Unexplained usage\\
%   \bottomrule
% \end{tabular}
% \end{table}

% Two-column table

% \begin{table*}
%   \caption{Some Typical Commands}
%   \label{tab:commands}
%   \begin{tabular}{ccl}
%     \toprule
%     Command &A Number & Comments\\
%     \midrule
%     \texttt{{\char'134}author} & 100& Author \\
%     \texttt{{\char'134}table}& 300 & For tables\\
%     \texttt{{\char'134}table*}& 400& For wider tables\\
%     \bottomrule
%   \end{tabular}
% \end{table*}

% Math (in-line)
% \begin{math}
%   \lim_{n\rightarrow \infty}x=0
% \end{math}

% Math (numbered equation)
% \begin{equation}
%   \lim_{n\rightarrow \infty}x=0
% \end{equation}

% Math (unnumbered equation)
% \begin{displaymath}
%   \sum_{i=0}^{\infty} x + 1
% \end{displaymath}

% Doing figures

% \begin{figure}[h]
%   \centering
%   \includegraphics[width=\linewidth]{sample-franklin}
%   \caption{1907 Franklin Model D roadster. Photograph by Harris \&
%     Ewing, Inc. [Public domain], via Wikimedia
%     Commons. (\url{https://goo.gl/VLCRBB}).}
%   \Description{A woman and a girl in white dresses sit in an open car.}
% \end{figure}

% The "teaser" figure

% \verb|\maketitle| command:
% \begin{verbatim}
%   \begin{teaserfigure}
%     \includegraphics[width=\textwidth]{sampleteaser}
%     \caption{figure caption}
%     \Description{figure description}
%   \end{teaserfigure}
% \end{verbatim}

% Citation examples

% Some examples.  A paginated journal article \cite{Abril07}, an
% enumerated journal article \cite{Cohen07}, a reference to an entire
% issue \cite{JCohen96}, a monograph (whole book) \cite{Kosiur01}, a
% monograph/whole book in a series (see 2a in spec. document)
% \cite{Harel79}, a divisible-book such as an anthology or compilation
% \cite{Editor00} followed by the same example, however we only output
% the series if the volume number is given \cite{Editor00a} (so
% Editor00a's series should NOT be present since it has no vol. no.),
% a chapter in a divisible book \cite{Spector90}, a chapter in a
% divisible book in a series \cite{Douglass98}, a multi-volume work as
% book \cite{Knuth97}, a couple of articles in a proceedings (of a
% conference, symposium, workshop for example) (paginated proceedings
% article) \cite{Andler79, Hagerup1993}, a proceedings article with
% all possible elements \cite{Smith10}, an example of an enumerated
% proceedings article \cite{VanGundy07}, an informally published work
% \cite{Harel78}, a couple of preprints \cite{Bornmann2019,
% AnzarootPBM14}, a doctoral dissertation \cite{Clarkson85}, a
% master's thesis: \cite{anisi03}, an online document / world wide web
% resource \cite{Thornburg01, Ablamowicz07, Poker06}, a video game
% (Case 1) \cite{Obama08} and (Case 2) \cite{Novak03} and \cite{Lee05}
% and (Case 3) a patent \cite{JoeScientist001}, work accepted for
% publication \cite{rous08}, 'YYYYb'-test for prolific author
% \cite{SaeediMEJ10} and \cite{SaeediJETC10}. Other cites might
% contain 'duplicate' DOI and URLs (some SIAM articles)
% \cite{Kirschmer:2010:AEI:1958016.1958018}. Boris / Barbara Beeton:
% multi-volume works as books \cite{MR781536} and \cite{MR781537}. A
% couple of citations with DOIs:
% \cite{2004:ITE:1009386.1010128,Kirschmer:2010:AEI:1958016.1958018}. Online
% citations: \cite{TUGInstmem, Thornburg01, CTANacmart}. Artifacts:
% \cite{R} and \cite{UMassCitations}.

%%
%% The next two lines define the bibliography style to be used, and
%% the bibliography file.
\bibliographystyle{ACM-Reference-Format}
\bibliography{sample-base}

%%
%% If your work has an appendix, this is the place to put it.
% \appendix

% \section{Research Methods}

% \subsection{Part One}

% Lorem ipsum dolor sit amet, consectetur adipiscing elit. Morbi
% malesuada, quam in pulvinar varius, metus nunc fermentum urna, id
% sollicitudin purus odio sit amet enim. Aliquam ullamcorper eu ipsum
% vel mollis. Curabitur quis dictum nisl. Phasellus vel semper risus, et
% lacinia dolor. Integer ultricies commodo sem nec semper.

% \subsection{Part Two}

% Etiam commodo feugiat nisl pulvinar pellentesque. Etiam auctor sodales
% ligula, non varius nibh pulvinar semper. Suspendisse nec lectus non
% ipsum convallis congue hendrerit vitae sapien. Donec at laoreet
% eros. Vivamus non purus placerat, scelerisque diam eu, cursus
% ante. Etiam aliquam tortor auctor efficitur mattis.

% \section{Online Resources}

% Nam id fermentum dui. Suspendisse sagittis tortor a nulla mollis, in
% pulvinar ex pretium. Sed interdum orci quis metus euismod, et sagittis
% enim maximus. Vestibulum gravida massa ut felis suscipit
% congue. Quisque mattis elit a risus ultrices commodo venenatis eget
% dui. Etiam sagittis eleifend elementum.

% Nam interdum magna at lectus dignissim, ac dignissim lorem
% rhoncus. Maecenas eu arcu ac neque placerat aliquam. Nunc pulvinar
% massa et mattis lacinia.

\end{document}
\endinput
%%
%% End of file `sample-sigconf.tex'.
