\chapter{Related work: Music Information Retrieval}
\label{chap:chap2}

% \begin{quote}
%     Learning from symbolic music representations using deep learning.
% \end{quote}
% \clearpage

\section{Automatic key estimation}

Key identification is a fundamental task in the analysis of tonal music. 
It is often a preliminary or concurrent step to other common musicological tasks like harmonic analysis and cadence detection. 
In particular, the knowledge of the musical key can help a music analyst to find boundaries in a musical piece, interpret the role of notes and chords, or suggest a musical form to which the analyzed piece conforms.
Due to its importance, key estimation is a well-studied research topic in Music Information Retrieval (MIR), and multiple key-analysis algorithms have emerged during the last decades. 
Broadly, there are two types of key-estimation algorithms: those that find the \emph{main key} of the piece (often called \emph{global-key-estimation} models in the context of computational musicology and MIR), and those that find the changes of key \emph{within} the piece (often called \emph{local-key-estimation} models). The annotations provided by these models have found applications in music technologies.

%%%%%%%% DLfM relevance %%%%%%%%%
In some contexts such as guitar tablatures \cite{ultimateguitar} and electronic dance music \cite{beatport}, global-key annotations are useful as one of the search parameters of a digital music library. 
Local-key annotations, however, have not yet been used for this purpose. 
It would be useful to complement key-related searches with local-key annotations, using them to search for musical pieces, based on their underlying changes of key. 
% As modulation are powerful tools to change the mood of a score, indexing local keys within the score could help the musicologist make bridges between lyrics and the tonal path. 
However, the ``interpretability'' of local-key annotations requires some attention first. 

Changes of key may belong to different categories. 
In music theory, terms like \emph{modulation} and \emph{tonicization} are helpful for interpreting the context of a change of key. 
Yet, most local-key-estimation research omits an investigation of the relationship between local-key annotations and these categories of changes of key. 
Therefore, as they stand, local-key annotations lack the characteristics that would make them useful in real applications, such as searching for the musical pieces in a large database that showcase similar modulation or tonicization patterns. 
One could think that these queries would be interesting, and quite different to, for example, searching for pieces of music that share the same global key. 

The ideas presented in this paper may be useful to improve the interpretability of the annotations provided by these models.
%%%%%%%% DLfM context %%%%%%%%%


%\cite{longuet1971tonality,  krumhansl1990cognitive, lerdahl88tps, vos96keyfinding, Temperley99:tonality, temperley2006,Zhu2003MusicSM}). 
%In this paper, however, rather than global-key estimation, we focus on the algorithms that model the changes of key \emph{within} a piece of music (often called \emph{local keys} in the context of computational musicology and music information retrieval).

\subsection{Global-Key-Estimation Models}
Researchers have designed a number of global-key-estimation algorithms throughout the years. 
The first one, to our knowledge, is the one by Longuet-Higgins~\cite{longuet1971tonality} from 1971.
Starting from the beginning of a score, the algorithm considers each pitch in order of occurrence and discards the keys that do not include that pitch within their diatonic scale degrees. 
This process is repeated until only one key remains, and some heuristics are applied afterward to help with the most difficult cases. This algorithm was able to retrieve the key of the fugues in J. S. Bach's \emph{Well-tempered Clavier}. 
It also served as a reference for later models, such as the one by Vos and van Geenen~\cite{vos96keyfinding}.

With the introduction of the \emph{probe-tone} technique and \emph{key profiles} in 1979 \cite{krumhansl_quantification_1979}, and their later application to the design of a global-key-estimation algorithm in 1990 \cite{krumhansl_cognitive_1990}, research regarding global-key-estimation models saw a shift toward more \emph{distributional} approaches \cite{temperley2008pitch}. 
Key profiles, originally introduced as listener ratings by Krumhansl et al. \cite{krumhansl_quantification_1979, krumhansl_tracing_1982}, have transitioned into probability distributions that can be used to predict the key of a musical piece.
Alternative key-profile distributions---and techniques for applying them---have been proposed over the years.
% Some of these are shown in Figure \ref{fig:ppro}. 

% and the histogram of pitches extracted from the musical score~\cite{krumhansl1990cognitive} called the \emph{probe tone method}. At about the same time, Lerdahl introduced tonal pitch space~\cite{lerdahl88tps} which can be used as a pitch profile with key finding algorithms.

% \begin{figure}[ht]
%   \includegraphics[width=\columnwidth]{figs/key_prof.png}
%   \caption{Various key profiles proposed by Krumhansl-Kessler \cite{krumhansl_tracing_1982}, Aarden-Essen \cite{aarden03:tonality}, Sapp \cite{saap11:tonality}, Bellman-Budge \cite{Bellmann06tonality}, Temperley \cite{Temperley99:tonality}, and Albrecht-Shanahan \cite{albrecht13:fugue}. Presented as probability distributions. Figure taken from~\cite{napoleslopez2019key} with permission.}
%   \label{fig:ppro}
% \end{figure}

Key profiles are the basis of many global-key-estimation models for symbolic music files and, starting from the 2000s, audio files as well. More exhaustive surveys of modern global-key-estimation techniques, with a focus on audio, are available \cite{korzeniowski_harmonic_2018, campbell_automatic_2010}. Key profiles have also been useful in the design of local-key estimation models.

\subsection{Local Keys, Modulation, and Tonicization}\label{ssec:terminology}

In MIR, it is common to describe algorithms that model \emph{changes of key} as local-key-estimation algorithms. 
The \emph{local keys} being the predictions that these models generate. Conversely, in music theory, the concepts of \emph{modulation} and \emph{tonicization} are often the manner in which changes of key are explained, and the term \emph{local key} is virtually non-existent.

Therefore, the three concepts, local keys, modulations, and tonicizations describe changes of key. 
Yet, what is the meaning of these terms? And what is the relationship between the local keys, modulations, and tonicizations of the same musical fragment?

According to the Grove Music Online dictionary, a modulation ``refers to a firmly established change of key, as opposed to a passing reference to another key, known as a `tonicization' ''~\cite{saslawgrovemodulation}. Moreover, a tonicization is ``the act of establishing a new key centre, or of giving a degree other than the first the role of tonic''~\cite{drabkintonicization}.

A formal definition of local keys is difficult to find. According to Papadopoulos et al.~\cite{papadopoulos_local_2009}, a local key is the ``key of each segment'' of a ``[segmented] musical piece [...] according to the points of modulation''. 

However, after these definitions, it is still difficult to understand the distinction between modulations and tonicizations. Kostka and Payne have suggested that such distinction is not possible: ``The line between modulation and tonicization is not clearly defined in tonal music, nor is it meant to be'' \cite{kostka2008tonal}. 

Regarding local keys, most researchers, as Papadopoulos et al. \cite{papadopoulos_local_2009}, associate them with modulations, however, this relationship has not been explored sufficiently. It would certainly benefit the computational musicology and MIR communities to engage in this exploration, in order to understand what is it that local-key-estimation algorithms predict.

For the scope of this work, we define these terms as follows:

\subsubsection{Modulation} 
Is the change from one key to another. We refer to the initial key as the \emph{departure} key, and the second key as the \emph{destination} key.

\subsubsection{Tonicization} 
Is a brief deviation to a different key, usually with the intention of emphasizing a certain scale degree or harmony. 
The tonicization often returns to the original key briefly after the deviation.

\subsubsection{Local keys}
Are the predictions of the musical key provided by a local-key-estimation algorithm. 
These predictions are given at a finer level of granularity than the entire piece (e.g., notes, onsets, fixed-duration timesteps, audio frames, etc.).
In principle, no music-theoretical meaning is inferred from them. They may coincide with modulations or tonicizations.

\subsection{Local-Key-Estimation Models}\label{ssec:localkey}

Contrary to the global-key estimation approaches, local-key estimation models have a relatively recent history.

% Audio
Purwins et al. introduced a method for tracking changes of key in audio signals %using cq-profiles, which are calculated with the constant Q filter bank
\cite{purwins_new_2000}. 
Their goal is to track the tone center and its variation during the piece. Their references annotate both modulations and tonicizations but consider that the ground truth is the one indicated by the tonicizations.

% symbolic
Chew~\cite{chew2002key} measured the distance from a sequence of pitches to a key using the \emph{spiral array} ~\cite{Chew2000TowardsAM}. 
The succession of keys is then modeled as a sequence of \emph{boundaries} dividing the score in different key areas.

% Audio
Chai and Vercoe designed a model based on a Hidden Markov Model (HMM) to detect changes of key~\cite{chai_detection_2005}. 
They describe the term \emph{modulation} as ``the change of key at some point''. 
Their model detects, at first, the tonal center, and then, the mode of the key.

% Audio 
Catteau et al.~\cite{Catteau07tonalkey} introduced a model for scale and chord recognition, assuming that there is a correspondence between a major scale and a major key, and between a harmonic minor scale and a minor key. Their model is based on the key profiles by Temperley \cite{Temperley99:tonality} and Lerdahl's \emph{tonal pitch spaces} \cite{lerdahl88tps}.

Izmirli introduced a model to find local keys from audio sources, based on non-negative matrix factorization for segmentation~\cite{izmirli_localized_2007}. 
Izmirli also attempted to disambiguate modulations and tonicizations in the following manner: ``Secondary functions and tonicizations are heard as short deviations from the well-grounded key in which they appear---although the boundary between modulation and tonicization is not clear cut. A modulation unambiguously instigates a shift in the key center''. 
% This work is also, to our knowledge, the first time that the term \emph{local keys} has been mentioned in an MIR publication.

Papadopoulos and Peeters adopted a similar approach to Izmirli for audio local-key estimation \cite{papadopoulos_local_2009}.
Their model attempts to segment the score based on the points of modulation. 
They introduced key dependencies on the harmonic and metric structures of global-key-finding methods, in order to convert them into local-key-finding ones. 
% They also discussed the need for more data in chords and local key.

Rocher et al. introduced a model that provides (chord, key) duples for each audio frame of an input excerpt. 
The model is based on a graph and the \emph{best-path} estimation method~\cite{thomas_rocher_2010_1417485}. 
For evaluating key distances, they used the key profiles by Temperley~\cite{Temperley99:tonality}. The authors alluded to the term modulation when discussing their key predictions.

Mearns et al. used an HMM to estimate modulations over audio transcriptions of Bach chorales~\cite{mearns2011automatically}. 
The HMM is trained with chord progressions. 
The emission probability distributions are obtained from two tables with the probabilities of chords existing in a given key. 
These tables are based on the work by Schoenberg and Krumhansl. 
Applied chords (i.e., tonicizations) are not described in these charts, therefore, the authors do not deal with tonicizations.

In 2014, Pauwels and Martens present a probabilistic framework for the simultaneous estimation of chords and keys from audio~\cite{pauwels_combining_2014}. 
They mention the importance of ``integrating prior musical knowledge'' into a local-key-estimation system, however, they do not allude to the terms modulation and tonicization. 
The same year, Weiss et al. proposed an audio scale estimator~\cite{weiss2014chroma}. 
They argue that this estimator can help to determine the local tonality based on G\'{a}rdonyi's scale analysis method. 
They did not use the term tonicization, however, they discussed ``short-time local modulations'', which resemble tonicizations.

Machine learning approaches, especially using neural networks, have recently gained popularity in MIR research, including key estimation. 
Independently, Chen et al. \cite{chen18harmony,chen19harmony} and Micchi et al.~\cite{Micchi20:roman} designed models that estimate local keys as well as roman numeral analysis annotations. Tonicization information is implied by the roman numeral analysis annotations. 

N\'apoles L\'opez et al. introduced a model to find changes of key (local-key estimation) as well as the main key of a piece (global-key estimation), using an HMM \cite{napoleslopez2019key}. 
The model is also capable of working with symbolic and audio data. They do not allude to the terms modulation or tonicization, always referring to their predictions as \emph{local keys}.

One of the most recent models for finding changes of key is by Feisthauer et al.~\cite{feisthauer2020smc}, which has been designed to detect modulations in Classical music. 
It uses three proximity measures established from pitch compatibility, tonality anchoring, and tonality proximity. 
The model computes the cost of being in a key on a given beat, and estimates the succession of keys using dynamic programming techniques.

% As modulations, tonicizations, and local keys all have different representations, they are difficult to compare. We propose a methodology to turn modulations and tonicizations into sequences of labels, a structure that is more compatible with local keys and facilitates the comparison between the music-theoretical concepts and the MIR annotations. 

% Most of them are audio-based ... 

%\subsection{Evaluation and datasets}
\subsection{Existing Datasets to Evaluate Local-Key-Estimation Models}

Most of the models discussed have been evaluated using different datasets, which are presented in Table~\ref{tab:corpus}.

\begin{table}
  \caption{Datasets used to evaluate local-key-estimation models.}
  \label{tab:corpus}
  \begin{tabular}{lcl}
    \toprule
    Model&Files&Dataset\\
    \midrule
    Catteau~\cite{Catteau07tonalkey} & 10 & Manually-built\\
    & & chord sequences\\
    Chai~\cite{chai_detection_2005} & 10 & Various (Classical)\\
    Chen~\cite{chen18harmony,chen19harmony}, Micchi~\cite{Micchi20:roman} & 23 & Beethoven\\
    Chew~\cite{chew2002key} & 2 & Bach\\
    Feisthauer~\cite{feisthauer2020smc} & 38 & Mozart (Classical) \\
    Izmirli~\cite{izmirli_localized_2007} & 17 & Pop songs\\
    & 152 & Naxos set (Classical)\\
    & 17 & Kostka-Payne (Classical)\\
    Mearns~\cite{mearns2011automatically} & 12 & Bach Chorales \\
    Micchi~\cite{Micchi20:roman} &  27 &  TAVERN (Classical)\\
    & 70 & ABC (Beethoven)\\ 
    & 72 & Roman Text (Classical)\\
    Papadopoulos~\cite{papadopoulos_local_2009} & 5 & Mozart\\
    Pauwels~\cite{pauwels_combining_2014} & 142 & SEMA Set (Pop)\\
    & 210 & MIREX 2009\\
    Purwins~\cite{purwins_new_2000} and & 1 & Chopin\\
    Napol\'{e}s Lop\'{e}z~\cite{napoleslopez2019key} & & \\
    Rocher~\cite{thomas_rocher_2010_1417485} & 174 & Beatles\\
    Weiss~\cite{weiss2014chroma} & 10 & Various (Classical) \\
  \bottomrule
\end{tabular}
\end{table}

The datasets used for evaluating local-key-estimation algorithms are typically small. 
Additionally, each dataset has often been used to evaluate a single model, which makes the comparison between models somewhat dubious. 
In this paper, we contribute further discussion around this topic by focusing on the following question: \emph{What is the relationship between the local keys, modulations, and tonicizations of the same musical fragment?} 
For this purpose, we describe: (1) our methodology for comparing annotations of local keys, modulations, and tonicizations, (2) a dataset that we collected from five music theory textbooks, and (3) an experiment where we evaluated three existing local-key-estimation models.

\section{Automatic chord recognition}
\section{Pitch spelling}
\section{Multi-task tonal analysis}

\bibliographystyle{plain}
\bibliography{zoterorefs}